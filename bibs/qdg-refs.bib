@STRING{aaai21 = {Proc.~Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)}}

THE NEXT THREE ENTRIES ARE DUPLICATES; TEMPORARILY SUSPENDED FOR DEBUGGING

article{heckerman2000dependency,
	title={Dependency networks for inference, collaborative filtering, and data visualization},
	author={Heckerman, David and Chickering, David Maxwell and Meek, Christopher and Rounthwaite, Robert and Kadie, Carl},
	journal={Journal of Machine Learning Research},
	volume={1},
	number={Oct},
	pages={49--75},
	year={2000}
}
book{mackay2003information,
  title={Information Theory, Inference and Learning Algorithms},
author={MacKay, David J. C.},
  year={2003},
  publisher={Cambridge University Press}
}
book{koller2009probabilistic,
	title={Probabilistic Graphical Models: Principles and Techniques},
	author={Koller, Daphne and Friedman, Nir},
	year={2009},
	publisher={MIT press}
}

@incollection{Baier_2022,
	doi = {10.1007/978-3-031-22337-2_17},
	url = {https://doi.org/10.1007%2F978-3-031-22337-2_17},
	year = 2022,
	publisher = {Springer Nature Switzerland},
	pages = {343--363},
	author = {Christel Baier and Clemens Dubslaff and Holger Hermanns and Nikolai Käfer},
	title = {On the Foundations of Cycles in Bayesian Networks},
	booktitle = {Lecture Notes in Computer Science}
}
@CONFERENCE{pdg-aaai,
  author = {Oliver E Richardson and Joseph Y Halpern},
  title = {Probabilistic Dependency Graphs},
  booktitle = aaai21,
  year = {2021},
  pages={12174-12181},
  eprint={2012.10800},
  archivePrefix={arXiv},
  primaryClass={cs.AI}
}
@article{jaynes1957information,
  title={Information Theory and Statistical Mechanics},
  author={Jaynes, Edwin T},
  journal={Physical Review},
  volume={106},
  number={4},
  pages={620},
  year={1957},
  publisher={APS}
}
@article{one-true-loss,
  title={Loss as the Inconsistency of a Probabilistic Dependency Graph: Choose Your Model, Not Your Loss Function},
  author={Oliver E Richardson},
  journal={AISTATS '22},
  year={2022},
  eprint={2202.11862},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  series = {Proceedings of Machine Learning Research},
  volume = {151},
  publisher = {PMLR},
}
@book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}
@book{abiteboul1995foundations,
  title={Foundations of databases},
  author={Abiteboul, Serge and Hull, Richard and Vianu, Victor},
  volume={8},
  year={1995},
  publisher={Addison-Wesley Reading}
}
@inproceedings{fagin1986theory,
	title={The Theory of Data Dependencies: a Survey},
	author={Fagin, Ronald and Vardi, Moshe Y},
	booktitle={Mathematics of Information Processing: Proceedings of Symposia in Applied Mathematics},
	volume={34},
	pages={19--71},
	year={1986},
	organization={Amer. Math. Soc.}
}
@inproceedings{pdg-infer,
  title={Inference for Probabilistic Dependency Graphs},
  author={Richardson, Oliver E and Halpern, Joseph Y and {De Sa}, Christopher},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1741--1751},
  year={2023},
  organization={PMLR}
}
@inproceedings{BalkePearl1994-CounterfactualProb,
author = {Balke, Alexander and Pearl, Judea},
title = {Counterfactual Probabilities: Computational Methods, Bounds and Applications},
year = {1994},
isbn = {1558603328},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {Evaluation of counterfactual queries (e.g., "If A were true, would C have been true?") is important to fault diagnosis, planning, and determination of liability. In this paper we present methods for computing the probabilities of such queries using the formulation proposed in [Balke and Pearl, 1994], where the antecedent of the query is interpreted as an external action that forces the proposition A to be true. When a prior probability is available on the causal mechanisms governing the domain, counterfactual probabilities can be evaluated precisely. However, when causal knowledge is specified as conditional probabilities on the observables, only bounds can computed. This paper develops techniques for evaluating these bounds, and demonstrates their use in two applications: (1) the determination of treatment efficacy from studies in which subjects may choose their own treatment, and (2) the determination of liability in product-safety litigation.},
booktitle = {Proceedings of the Tenth International Conference on Uncertainty in Artificial Intelligence},
pages = {46–54},
numpages = {9},
location = {Seattle, WA},
series = {UAI'94}
}
@article{rubin1974estimating,
  title={Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.},
  author={Rubin, Donald B},
  journal={Journal of educational Psychology},
  volume={66},
  number={5},
  pages={688},
  year={1974},
  publisher={American Psychological Association}
}
@article{tabak2010density,
  title={Density Estimation by Dual Ascent of the Log-Likelihood},
  author={Tabak, Esteban G and Vanden-Eijnden, Eric},
  journal={Communications in Mathematical Sciences},
  volume={8},
  number={1},
  pages={217--233},
  year={2010},
  publisher={International Press of Boston}
}
@article{Kobyzev_2021,
	doi = {10.1109/tpami.2020.2992934},   
	url = {https://doi.org/10.1109%2Ftpami.2020.2992934},   
	year = 2021,
	month = {nov},   
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},   
	volume = {43},   
	number = {11},   
	pages = {3964--3979},   
	author = {Ivan Kobyzev and Simon J.D. Prince and Marcus A. Brubaker},   
	title = {Normalizing Flows: An Introduction and Review of Current Methods},   
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
}

@Article{multivar-beyondshannon17,
AUTHOR = {James, Ryan G. and Crutchfield, James P.},
TITLE = {Multivariate Dependence beyond Shannon Information},
JOURNAL = {Entropy},
VOLUME = {19},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {531},
URL = {https://www.mdpi.com/1099-4300/19/10/531},
ISSN = {1099-4300},
ABSTRACT = {Accurately determining dependency structure is critical to understanding a complex system’s organization. We recently showed that the transfer entropy fails in a key aspect of this—measuring information flow—due to its conflation of dyadic and polyadic relationships. We extend this observation to demonstrate that Shannon information measures (entropy and mutual information, in their conditional and multivariate forms) can fail to accurately ascertain multivariate dependencies due to their conflation of qualitatively different relations among variables. This has broad implications, particularly when employing information to express the organization and mechanisms embedded in complex systems, including the burgeoning efforts to combine complex network theory with information theory. Here, we do not suggest that any aspect of information theory is wrong. Rather, the vast majority of its informational measures are simply inadequate for determining the meaningful relationships among variables within joint probability distributions. We close by demonstrating that such distributions exist across an arbitrary set of variables.},
DOI = {10.3390/e19100531}
}
@misc{beckers2023causal,
      title={Causal Models with Constraints}, 
      author={Sander Beckers and Joseph Y. Halpern and Christopher Hitchcock},
      year={2023},
      eprint={2301.06845},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@article{lauritzen-dag-indeps,
author = {Lauritzen, S. L. and Dawid, A. P. and Larsen, B. N. and Leimer, H.-G.},
title = {Independence properties of directed markov fields},
journal = {Networks},
volume = {20},
number = {5},
pages = {491-505},
doi = {https://doi.org/10.1002/net.3230200503},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/net.3230200503},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/net.3230200503},
abstract = {Abstract We investigate directed Markov fields over finite graphs without positivity assumptions on the densities involved. A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property. We give a simple proof of the fact that the directed, local Markov property and directed, global Markov property are equivalent and – in the case of absolute continuity w. r. t. a product measure – equivalent to the recursive factorization of densities. It is argued that our criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl. It follows that our criterion cannot be sharpened.},
year = {1990}
}
@article{geiger-pearl-d-separation,
author = {Geiger, Dan and Verma, Thomas and Pearl, Judea},
title = {Identifying Independence in Bayesian Networks},
journal = {Networks},
volume = {20},
number = {5},
pages = {507-534},
doi = {https://doi.org/10.1002/net.3230200504},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/net.3230200504},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/net.3230200504},
abstract = {Abstract An important feature of Bayesian networks is that they facilitate explicit encoding of information about independencies in the domain, information that is indispensable for efficient inferencing. This article characterizes all independence assertions that logically follow from the topology of a network and develops a linear time algorithm that identifies these assertions. The algorithm's correctness is based on the soundness of a graphical criterion, called d-separation, and its optimality stems from the completeness of d-separation. An enhanced version of d-separation, called D-separation, is defined, extending the algorithm to networks that encode functional dependencies. Finally, the algorithm is shown to work for a broad class of nonprobabilistic independencies.},
year = {1990}
}
@article{chickering-equiv-bns,
  author       = {David Maxwell Chickering},
  title        = {A Transformational Characterization of Equivalent Bayesian Network
                  Structures},
  journal      = {CoRR},
  volume       = {abs/1302.4938},
  year         = {2013},
  url          = {http://arxiv.org/abs/1302.4938},
  eprinttype    = {arXiv},
  eprint       = {1302.4938},
  timestamp    = {Mon, 13 Aug 2018 16:47:19 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1302-4938.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{gallo-dirhypergraphs1993,
title = {Directed Hypergraphs and Applications},
journal = {Discrete Applied Mathematics},
volume = {42},
number = {2},
pages = {177-201},
year = {1993},
issn = {0166-218X},
doi = {https://doi.org/10.1016/0166-218X(93)90045-P},
url = {https://www.sciencedirect.com/science/article/pii/0166218X9390045P},
author = {Giorgio Gallo and Giustino Longo and Stefano Pallottino and Sang Nguyen},
abstract = {We deal with directed hypergraphs as a tool to model and solve some classes of problems arising in operations research and in computer science. Concepts such as connectivity, paths and cuts are defined. An extension of the main duality results to a special class of hypergraphs is presented. Algorithms to perform visits of hypergraphs and to find optimal paths are studied in detail. Some applications arising in propositional logic, And-Or graphs, relational databases and transportation analysis are presented.}
}

@Article{e19060273,
AUTHOR = {Allen, Benjamin and Stacey, Blake C. and Bar-Yam, Yaneer},
TITLE = {Multiscale Information Theory and the Marginal Utility of Information},
JOURNAL = {Entropy},
VOLUME = {19},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {273},
URL = {https://www.mdpi.com/1099-4300/19/6/273},
ISSN = {1099-4300},
ABSTRACT = {Complex systems display behavior at a range of scales. Large-scale behaviors can emerge from the correlated or dependent behavior of individual small-scale components. To capture this observation in a rigorous and general way, we introduce a formalism for multiscale information theory. Dependent behavior among system components results in overlapping or shared information. A system’s structure is revealed in the sharing of information across the system’s dependencies, each of which has an associated scale. Counting information according to its scale yields the quantity of scale-weighted information, which is conserved when a system is reorganized. In the interest of flexibility we allow information to be quantified using any function that satisfies two basic axioms. Shannon information and vector space dimension are examples. We discuss two quantitative indices that summarize system structure: an existing index, the complexity profile, and a new index, the marginal utility of information. Using simple examples, we show how these indices capture the multiscale structure of complex systems in a quantitative way.},
DOI = {10.3390/e19060273}
}

@InCollection{sep-causal-models,
	author       =	{Hitchcock, Christopher},
	title        =	{{Causal Models}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta and Uri Nodelman},
	howpublished =	{\url{https://plato.stanford.edu/archives/sum2024/entries/causal-models/}},
	year         =	{2024},
	edition      =	{{S}ummer 2024},
	publisher    =	{Metaphysics Research Lab, Stanford University}
}
@article{halpern-2000,
  title={Axiomatizing Causal Reasoning},
  author={Halpern, Joseph Y},
  journal={Journal of Artificial Intelligence Research},
  volume={12},
  pages={317--337},
  year={2000}
}
@misc{blom2019structural,
      title={Beyond Structural Causal Models: Causal Constraints Models}, 
      author={Tineke Blom and Stephan Bongers and Joris M. Mooij},
      year={2019},
      eprint={1805.06539},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{peters-halpern-GSEMs,
      title={Causal Modeling With Infinitely Many Variables}, 
      author={Spencer Peters and Joseph Y. Halpern},
      year={2021},
      eprint={2112.09171},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
% (https://math.stackexchange.com/users/312/leonbloy)},
@MISC {1219753,
    TITLE = {conditioning reduces mutual information},
    YEAR = {2015},
    AUTHOR = {leonbloy},
    HOWPUBLISHED = {Mathematics Stack Exchange},
    NOTE = {URL:https://math.stackexchange.com/q/1219753 (version: 2015-04-04)},
    EPRINT = {https://math.stackexchange.com/q/1219753},
    URL = {https://math.stackexchange.com/q/1219753}
}
@misc {dit-stumble,
  title={(Stumbling Blocks) on the Road to Understanding Multivariate Information Theory},
  author={James, Ryan},
  year={2018},
  howpublished={Discrete Information Theory package documentation},
  url={https://dit.readthedocs.io/en/latest/stumbling.html}
}
@misc{williams2010nonnegative,
      title={Nonnegative Decomposition of Multivariate Information}, 
      author={Paul L. Williams and Randall D. Beer},
      year={2010},
      eprint={1004.2515},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}
@misc{pearl1987graphoids,
  title={Graphoids: A Graph-Based Logic for Reasoning about Relevance Relations},
  journal={Advances in Artificial Intelligence},
  vol={2},
  author={Pearl, J and Paz, A},
  year={1987},
  publisher={North-Holland}
}
@misc{naumov2013re,
      title={R.E. Axiomatization of Conditional Independence}, 
      author={Pavel Naumov and Brittany Nicholls},
      year={2013},
      eprint={1310.6430},
      archivePrefix={arXiv},
      primaryClass={cs.LO}
}
@book{probTuring,
	author={Sipser, Michael},
	year={2006},
	title={Introduction to the Theory of Computation (2nd ed.)},
	edition={Second},
	publisher={Thomson Course Technology.},
	pages={368},
	isbn={978-0-534-95097-2}
}
