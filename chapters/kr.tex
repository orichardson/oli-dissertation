% REPRESENTING THINGS WITH PDGs
PDGs are extremely expressive.
We saw in \cref{sec:bn-convert,sec:factor-graphs,sec:expfam} that PDGs
can capture graphical models such as Bayesian Networks and Factor graphs---but this is only the beginning. 
%
% This chapter, based on a collection of unpublished notes, 
In this chapter, we will see how a wide variety of other mathematical models and fragments of epistemic information can be implicitly viewed as PDGs.


\section{Probabilities and Random Variables}
    \label{sec:prob-as-pdg}

Probability is the dominant way that computer computer scientists and
microeconomics think about epistemic state.
This is due to standard betting arguments suggesting that any sufficiently rational agent (e.g., one resistant to dutch books)
must act as if it had probabilistic beliefs \cite{..,savage}.
% Nevertheless, not everything is probabilistic---at least, not 
Still, probability does have shortcomings \cite{}, and there have been many other representations of uncertainty \cite{halpern2017reasoning}.
% Many logics are based on binary truth/falsehood
Many approach are built on binary truth and falsehood, and epistemic logics dealing with possibility and necessity are built on top of them.
Possibility is one important one; others include belief/plausibility measures, which have been touted as generalizations of probability. 
Perhaps surprisingly, many of these objects can be represented with PDGs as well.

We start with an obvious construction, that is nonetheless important
to keep in mind: a joint distribution can be viewed as a very special case of a PDG. 
Let $\X$ be a set of variables, and recall that $\V\!\X$ is the set of all joint settings of the variables $\X$. 
A joint distribution $\mu \in \Delta \V\!\X$ can be implicitly regarded as that has a single hyperarc $\emptyset \to \X$. We attach $\mu$ as the (c)pd, and give it weights $\alpha=0$ (if, as is usual, the distribution represents purely observational and not causal information) and $\beta = 1$ (default confidence). 
% We will see more about these parameters later on. 

To a probability theorist, these joint distributions $\mu$ may seem to be of a very special form, because they are over product spaces. 
In probability theory, the setup is typically instead that one has a (measurable) set $\Omega$ of outcomes, and then random variables are in fact \emph{(measurable) functions} $X : \Omega \to \V\!\X$. 
Observe that this too is an immediate special case of a PDG:
%
\begin{center}
    \begin{tikzpicture}[xscale=1.6]
        % \coordinate (mergeorigin) at (3,2);
        \node[dpadded] (omega) at (3,2) {$\Omega$};
        \foreach \i in {1,...,5} {
            \node[dpadded] (X\i) at (\i,0) {$X_\i$};
            \draw[arr2, shorten <=0pt, ->>] (omega) to (X\i);
        }
        % \draw[arr2,-,shorten >=0pt,shorten <=0pt] (mergeorigin) to +(0,0.5);
        % \node[above left=0pt and 4pt of mergeorigin]{$\mu$};
        \draw[arr2,<-] (omega) to node[above]{$\mu$} +(-1.3,0);
    \end{tikzpicture}
% \]
\end{center}
%
(In fact, this PDG happens to also be a BN, if one isn't worried about calling $\Omega$, often itself a product of variables, a variable.)
It is easy to verify that these PDGs have inconsistency zero, and represent precisely the distribution $\mu$. 

The semantics of PDGs 
    make heavy use of the usual definition of a joint distribution $\mu \in \Delta \V\!\X$, and thus would be circular if one were to implicitly convert joint distributions to PDGs before developing the results of the previous chapter. 
But now that the theory of PDGs is on solid ground, we may freely regard joint distribution as a PDG. 
This will be useful to keep in mind later, but it is neither surprising, nor is this property unique to PDGs. 
Indeed, $\mu$ can also be viewed as a factor graph with only one factor. 

\section{Widgets}

PDGs may be expressive, but they are structured objects with clear and specific specific syntax.
After some brief reflection, one might even find the syntax unnecessarily restrictive. 
Recall: in specifying the data for an arc $X \to Y$, one must specify a complete probability distribution $p(Y | x)$ over the values of $Y$ for \emph{every} value $x \in \V\!X$. 
% This has some serious implications---for instance
% Consequently, 
This appears to be a serious limitation.
For instance, if $X$ and $Y$ are binary variables, one might want to 
annotate an arc $X \to Y$ with data indicating that $X \Rightarrow Y$
    (i.e., if $X=1$ then $Y=1$).
% For $X{=}1$, everything works out, 
There are no problems in supplying a probability over $Y$ when $X{=}1$,
but unfortunately we also seem to be on the hook to provide
    a distribution over $Y$ when $X{=}0$. 
One might also want to indicate not a probabilistic information, but a constraint.
For instance, one might want to specify that $Z$ must be even when $X{=}0$, 

At least---to a first approximation. 
It turns out that all of these can be captured by PDGs. 
% When adding an arc $X \to Y$, we 
% As expressive as they are, 


\subsection{Relations and Constraints}
\label{sec:relation-widget}

% Although PDGs may seem as though they can only describe 
A probability distribution $\mu \in \Delta \Omega$ over 
    a finite set $\Omega$ encodes in particular a constraint
    on the possible values of $\Omega$ that can be observed---namely, that
they must be among $\Supp \mu = \{ \omega \in \Omega : \mu(\omega) > 0 \}$. 
\unskip\footnote{An analogous statement may be made when $\Omega$ is infinite, 
    but we defer this discussion until \cref{sec:continuous-pdgs}.}


% A relation $R(X_1, \ldots, )$
A constraint on a set $\Omega$ of possible worlds is a subset $C \subseteq \Omega$
of values that satisfy the constraint, or equivalntly, 
a function $\Omega \to \{\mathtt{true}, \mathtt{false}\}$ assigning to each $\omega \in \Omega$ a Boolean that indicates whether or not it is allowed by the constraint. 
    
In a PDG, the sample space $\Omega$ consists of joint settings of
variables;
% variables $\V\!\X$,
a constraint on joint settings of variables is known more familiarly as a
\emph{relation} (see \cref{primer:relations}).
We have already seen how PDGs can encode certain relations, such as
in compiling a directed hypergraph to a graph (\cref{constr:hyperedge-reducton}),
where we managed to enforce a constraint on the triple of variables $(\var A, \var B, \var A\times \var B)$ ensuring that the value of $\var A \times \var B$ is always the pair consisting of the value of $\var A$ and the value of $\var B$.
But this is a very special kind or relation---an equality relationship between variables that already appear to have a clear structional relationship.
Can we encode arbitrary relational constraints with a PDG? 
It turns out we can.

% To a relation 
Consider a relation $R = R(\var{A}_1, \ldots, \var{A}_n)$ between the
    (values of) variables $\var A_1, \ldots, \var A_n$.
We associate $R$  with a PDG
% $\PDGof{R}$
\[
\PDGof{R} := ~~
    \begin{tikzpicture}[center base, scale=1.2]
        \node[dpadded] (A1) at (-1,0) {$\var A_1$};
        \node at (0,0) {$\cdots$};
        \node[dpadded] (An) at (1,0) {$\var A_n$};
        \node[dpadded] (T) at (0, -1.4) {$\Tru$};
        \mergearr[arr1,->>] {A1}{An}{T}
        \node [%
            below left=0pt and 3pt 
            % above= 1pt
            of center-A1AnT]{R};
		\draw[arr0, <<-] (T) to
			node[above, inner sep=2pt, pos=0.6]
				{\trut}
			+(-1.2,0);
    \end{tikzpicture},
\]
where $\Tru$ is a variable that intuitively represents ``truth'';
    it technically can take on two possible values $\V\Tru := \{\trut, \truf\}$,
    but it always takes on $\truf$. 
      % the event $\Tru \!\!=\! \trut$,
Note that the arc labeled ``$R$'' is attached to the obvious way of regarding $R$ as a conditional probability distribution, i.e., the cpd $\delta R(\Tru \mid \var A_1, \ldots, \var A_n)$. 


% Just as we have simplified our notation by dropping the special variable 
We simplify notation by implicitly converting $R$ to the PDG $\PDGof{R}$ 
whenever it would be helpful to regard it as one, thereby identifying $R$ and $\PDGof{R}$. 
Furthermore, we also adopt the graphical notation 
that leaves $\Tru$ implicit, so that the binary relation $R(\var X,\var Y)$ and the
    constraint $C \subseteq \V \var W$ can be depicted graphically as
\begin{center}
    \begin{tikzpicture}[center base, scale=1]
        \node[dpad1] (X) at (-1,0) {$\var X$};
        \node[dpad1] (Y) at (1,0) {$\var Y$};
            
        \coordinate (crash1-pool) at (0,-0.35);
        \coordinate (crash1) at (0,-0.5);
        \draw[arr2,shorten >=0pt,-] (X) to[out=0,in=90] (crash1-pool);
        \draw[arr2,shorten >=0pt,-] (Y) to[out=180,in=90] (crash1-pool);
        \draw[arr2,shorten >=0pt,shorten <=0pt,->>] (crash1-pool) to (crash1);
        \draw[arr2,<<-,shorten <=0pt] (crash1) to +(0,-0.2);
            % \coordinate (crash2) at (3, 0);
            % \draw[arr2,->>,shorten >=0pt] (W) to (crash2);
            % \draw[arr2,<<-,shorten <=0pt] (crash2) to +(0.2,0);
    %
        \node[above=2ex of crash1] {$R$};
    \end{tikzpicture}
    \hspace{2em}\text{ and }\hspace{2em}
    \begin{tikzpicture}
        \node[dpad1] (W) at (0,0) {$\var W$};
        \coordinate (crash2) at (1, 0);
        \draw[arr2,->>,shorten >=0pt] (W) to (crash2);
        \draw[arr2,<<-,shorten <=0pt] (crash2) to +(0.2,0);
        \node[above=2pt of crash2]{$C$};
    \end{tikzpicture}~,
\end{center}
respectively, in PDG notation.
Correspondingly, we will typically identify a distribution $\mu(\X)$ with 
the ``extended'' distribution $\mu(\X) \delta(\Tru{=}\trut)$, except
in the following theorem statement, where we treat it carefully.
% Observe that, as far as finite PDGs are concerned, 
% relations, events, and constraints are essentially the same.


While it is not surprising that this construction encodes a relation
    as far as PDG semantics are concerned, it is still worth verifying.
\begin{prop}
    If $R = R(\var A_1, \ldots, \var A_n) = R(\mat X)$ is a relational constraint
    on the variables $\mat X = \{\var A_1, \ldots, \var A_n\}$, then,
    writing $R$ for both the PDG $\dg M_R$ and the event $R \subseteq \V\mat X$, we have:
    \begin{enumerate}[topsep=0pt]
        \item $\SD{R\,} 
        % (= \SD{\dg M_R})
            = \{ \mu(\mat X, \Tru) : \Supp \mu \subseteq R \times \{\trut\} \}
            = \{ \mu(\mat X, \Tru) : \mu(R) = \mu(\Tru{=}\trut) = 1 \}
            $.
        \item  
        Moreover, for all PDGs $\dg M$ 
            % with variables $\X$,
            % containing the variables $\mat X$:
            with variables $\X \supseteq \mat X$, 
        \begin{enumerate}
            \item 
            % $\SD{\dg M + R} 
            % \cong
            %     % =
            %     % \SD{\dg M} \cap \{ \mu(\X) : \Supp \mu \subseteq R\}
            %     % \SD{\dg M} \cap \{ \mu(\X) : \mu(R) = 1\}
            %     \big\{ \mu \in \SD{\dg M} ~\big|~ \mu(R) = 1 \big\}
            %     $
            $\mu \in \SD{\dg M + R}$ 
            iff $\mu(\X) \in \SD{\dg M}$ and $\mu(R) = 1$ 
                ~(and also $\mu(\Tru{=}\trut)=1$).
            % where $\cong$ identifies 
            
            
            \item provided $\aar{\dg M}_\gamma < \infty$, $\bbr{\dg M + R}^*_\gamma$ consists entirely of $\mu$ satisfying $\mu(R) = 1$. 
            
            \item for all $\gamma \ge 0$, $\aar{\dg M + R}_\gamma \ge \aar{\dg M}_\gamma$ with equality if and only if
            there exists some $\mu \in \bbr{\dg M}^*_\gamma$ for which $\mu(R) = 1$. 
        
        \end{enumerate}
    \end{enumerate}
\end{prop}
\begin{proof}
    1.
    If $\mu \in \SD{R\,}$, then $\mu(\Tru{=}\trut) = 1$, so if $\mu(\mat X{=}\mat x) > 0$, then $\mu(\Tru{=}\trut \mid \mat X{=}\mat x) = 1$ for all joint settings $\mat x \in \V(\mat X)$. But $\mu(\Tru{=}\trut \mid \mat X{=}\mat x) = R(\mat x)$, and thus $R(\mat x) = 1$.
    Conversely, if $\mu(\mat X, \Tru) = \mu(\mat X)\delta(\Tru{=}\trut)$ and $\mu(R) = 1$, then 
    \[
        \mu(\Tru \mid \mat X)
        = (\mu(\mat X) \delta(\Tru {=} \trut)) / \mu(\mat X)
        = \delta R(\Tru \mid \mat X).
    \]
    Thus $\mu$ is consistent with all conditional probabilities in the widget $\PDGof R$,
    and so $\mu \in \SD{\dg M_R} = \SD{R\,}$.
    
    2. 
    (a)
    If $\mu \in \SD{\dg M + R}$, then by definition $\mu(\Tru{=}\trut) = 1$. By the same reasoning as in part 1, we also find that $\mu(R) = 1$. We also know that $\mu$ satisfies the cpds of $\dg M$, so $\mu(\X) \in \SD{\dg M}$. 
    Conversely, if $\mu(\X) \in \SD{\dg M}$, and $\mu(\Tru{=}\trut) = \mu(R) = 1$, 
    then, again by the logic in part 1, $\mu(\Tru \mid \mat X) = \delta R$.
    Therefore $\mu$ satisfies all cpds of $\dg M$, and all cpds of the widget $\PDGof{R}$, and thus $\mu \in \SD{\dg M + R}$.
    
    (b) 
    % In search of a contradiction, suppose that there is some 
    For all 
    $\mu \in \bbr{\dg M}^*_\gamma$, we have
     % with $\mu(R) < 1$. 
    % Then there is some setting $\mat x$
    % If $\mu(\Tru{=}\trut) < 1$, then $$
    \begin{align*}
        \aar{\dg M}_\gamma 
        &= \bbr{\dg M}_\gamma^*(\mu) 
        \\&\ge \Ex_{\mu} \Big[
            \log \frac{\mu(\Tru)}{\mathbbm1[\Tru=\trut]}
            + \log \frac{\mu(\Tru \mid \mat X)}{\delta R(\Tru \mid \mat x)}
        \Big]
        \\&= \infty \cdot \mathbbm1[\mu(\Tru{=}\trut)=1] + 
            \infty \cdot \Ex_{\mat x \sim \mu}\big[ \mat x \notin R \Rightarrow \mu(\Tru{=}\trut\mid\mat x)=0 \big]
        .
    \end{align*} 
    Now, suppose that $\mu(R) < 1$, meaning there is some mass on joint settings $\mat x \notin R$.
    If $\mu(\Tru{=}\trut \mid \mat x) \ne 0$, then the score is infinite, by the second term. 
    Yet if $\mu(\Tru{=}\trut \mid \mat x) = 0$ and there is some mass on $\mat x$, then 
    $\mu(\Tru{=}\trut) < 1$, and so again the score is infinite, by the first term.
    Thus, if the score is finite, then $\mu(R) = 1$. 
    
    (c) The inequality is monotonicity (\cref{lemma!}). 
    % For the remainder of this proof, identify distrib
    Suppose there is some $\mu \in \bbr{\dg M}^*_\gamma$ with $\mu(R) = 1$.
    % Define 
    % If $\Tru \notin \X$, then d
    Define $\bar\mu(\X, \Tru) := \mu(\X)\delta(\Tru{=}\trut)$.
    By the same logic as in the proof of part 1 of the proposition, 
    $\mu$ satisfies all of the cpds of the widget $\PDGof R$; and thus 
    $\bbr{\dg M + R}(\bar\mu) = \bbr{\dg M}_\gamma(\mu)$.
    Chaining together some inequalities, we find:
    \[
     \aar{\dg M + R}_\gamma \le 
     \bbr{\dg M + R}(\bar\mu) 
     = \bbr{\dg M}_\gamma(\mu)
     = \aar{\dg M}_\gamma
     \le \aar{\dg M + R}_\gamma, 
     \]
    and thus all of these quantities are equal.
    % The same logic works by taking $\bar\mu = \mu$, if $\Tru \in \X$ and $\mu(\Tru{=}\trut)=1$. 
    % Finally, if $\Tru \in \X$ and $\mu(\Tru{=}\trut) < 1$, then 
    % \[
    %     \aar{\dg M}_\gamma^* = \bbr{\dg M}^*_\gamma(\mu)
    % \]
    
    Conversely, suppose
    that $\aar{\dg M + R}_\gamma = \aar{\dg M}_\gamma$.
    % \[
    %     \bbr{\dg M + R}_\gamma \subseteq = \bbr{\dg M}^*_\gamma
    % \]
    If $\bbr{\dg M} = \infty$, then $\bbr{\dg M}_\gamma^*$ consists of 
        all distributions, and so the statement is vacuous. 
    On the other hand, 
    select some $\bar\mu \in \bbr{\dg M + R}_\gamma^*$.
    By applying part (b), we find that $\bar\mu(R) = 1$. 
    And, because $\aar{\dg M + R}_\gamma = \aar{\dg M}_\gamma$
    and $\bar\mu$ is an optimal distribution for $\dg M + R$, 
    we find that its marginal $\mu(\X) := \bar\mu(\X)$
    is optimal for $\dg M$:
    \[
        \bbr{\dg M}_\gamma(\mu(\X))
        % = \Ex_{\omega \sim \mu}[ \sum_{a \in \Ar} ]
        = \aar{\dg M + R}_\gamma 
        = \aar{\dg M}_\gamma
        \le \bbr{\dg M}_\gamma(\mu(\X))
    \]
    Thus, we have constructed $\mu \in \bbr{\dg M}^*_\gamma$ satisfying $\mu(R) =1$. 
\end{proof}


\subsection{Costs: ``Soft Relations''}

TODO: Comparisons between factors and costs. 

TODO: move in and split material from loss chapter.

% Now that we can describe relational constraints, one might
% naturally wonder about databases.

% \subsection{Graph-Hypergraph Equivalence}
\subsection{Incomplete CPDs and Individual (Conditional) Probabilities}
    \label{sec:prob-widget}
    
A cpd between discrete variables can be represented by
    a stochastic matrix (i.e., a matrix whose rows sum to one).
It turns out that it is possible to use the machinery of PDGs
    to, effectively, give only one value of that matrix.
That is, for any $p \in [0,1]$, we can construct a PDG
    that represents the belief that $\Pr(Y{=}y|X={x}) = p$, but say nothing about
    how the probability splits between other values of $y$, and also says nothing
    about the probability of $Y$ if $X \ne x$.
We now describe that construction.

\def\XxYy{{X{=}x\Vert Y{=}y}}
\def\XxYyshort{{X_x Y_y}}
\def\Yy{{Y{=}y}}
\def\Yyshort{{Y_y}}

First, we introduce two new auxiliary variables.
The first variable, which we might like to call ``$\Yy$'', but
    mostly refer to as $\Yyshort$ to prevent confusion with the synonymous
    event, is a binary variable, with $\V(\Yyshort) = \{y, \lnot y\}$,
    and takes the value $y$ if $Y=y$, and $\lnot y$ if $Y \ne y$.
The second variable, which we would like to call ``$\XxYy$'',
    but instead mostly refer to as $\XxYyshort$ to prevent notational confusion,
    can take three values: $\V(\XxYyshort):= \{ x, y, \lnot y \}$.
The value $x$ is meant to correspond exactly to the event $X{=}x$,
    much like before, so that $\XxYyshort = x$ if and only if $X = x$.
The values $y$ and $\lnot y$ also correspond to their respective
    events, but more loosely; the variable $\XxYyshort$ only takes one of these
    values when $X \ne x$.
Note that both variables can be determined from $X$ and $Y$
(although we will need to enforce this with additional arcs), and
therefore there is a unique way to extend a
distribution over $X$ and $Y$ to also include the variables $\Yyshort$ and $\XxYyshort$.

% Now, supposing that $\XxY$ takes its special value $X{=}x$ if and only if $X=x$, and otherwise takes the value of $Y$, then there's a clear choice of distribution on $B$ given $X$: if $X$ takes its special value, we $\Pr(B) = p$. Otherwise, $\Pr(B)$ is a point mass on the value $b$. And this value of $X$ an be calculated from joint values of $B$ and $A$.
With these definitions in place, there is
    now an obvious way to add an arc from the variable $(\XxYyshort)$
    to the variable $\Yyshort$, together with a cpd asserting that $\Pr(Y{=}y|X{=}x)=p$.
This cpd is written as a stochastic matrix $\hat p$
    defined on the right of \cref{fig:pyx-widget}.
The PDG we have just constructed is illustrated on the left of \cref{fig:pyx-widget}.
In addition to $\hat p$ and the new variables, this PDG
    includes the structural constraints $s_1$ and $s_2$ needed to define the variables
    $\XxYyshort$ and $\Yyshort$ in terms of $X$ and $Y$; they are deterministic functions,
    drawn in double-headed gray arrows.
% are illustrated below.

% \begin{center}
\begin{figure}
    \centering
% $\dg M^{y|x=p}:=$
    \colorlet{proofmatt}{white}
    \begin{tikzpicture}[center base]
        \node[dpadded] (X) at (0,-0.5){$X$};
        \node[dpadded, right=1.6 of X](Y){$Y$};

        \node[tpt={astar|$x$}] at (0.0,1.5) {};
        \node[tpt={b1|$y$},right=0.55 of astar]{};
        \node[tpt={b2|$\lnot y$},right=0.4 of b1]{};
        % \node[right=0.2 of b2] (bdots){$\cdots$};
        % \node[tpt={bn|$y_n$},right=0.2 of bdots]{};

        \node[Dom={$\XxYyshort$[label distance=-1.5em, xshift=1.2em] (XxYy)
            around {\lab{astar}\lab{b1}\lab{b2}(1.6,1.85)}} ] {};

        \node[tpt={y1|$y$}] at (3.7, 1.5){};
        \node[tpt={y2|$\lnot y$},right=0.5 of y1]{};
        \node[Dom={%
            %$Y{=}y\,$%
            $\Yyshort$%
            [label distance=-1.4em, xshift=1.3em] (Yy)
            around {\lab{y1}\lab{y2}(3.7,1.75)}} ] {};

        %% structural arrows
        \mergearr[black!35!proofmatt,arr2,->>]{X}{Y}{XxYy}
        \node[black!35!proofmatt,below=2pt of center-XYXxYy]{$s_1$};

        %%
        \draw[black!35!proofmatt, arr2, ->>] (Y) to node[below right]{$s_2$} (Yy);

        \draw[arr2] (XxYy) to node[above]{$\hat p$} (Yy);
    \end{tikzpicture}
    % \hspace{0.6cm}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \begin{align*}
            \hat p(\Yyshort|\XxYyshort) &= \begin{matrix}
                &  \begin{matrix} y & \lnot y \end{matrix} \\
                \begin{matrix} x \!\! \\ y \!\! \\ \lnot y \!\! \end{matrix} &
                    \begin{bmatrix}
                        \;p & 1-p \; \\
                        \;1 & 0  \;\\
                        \;0 & 1 \;
                    \end{bmatrix}
            \end{matrix}\\[2ex]
            s_1(\XxYyshort|X,Y) &:= \delta{\singlespacing\begin{cases}
                x & \text{if $X = x$} \\
                y & \text{if $X \ne x$ and $Y=y$} \\
                \lnot y & \text{if $X \ne x$ and $Y\ne y$} \\
            \end{cases}}\\
            s_2(\Yyshort|Y) &:= \delta{\singlespacing\begin{cases}
                y & \text{if $Y=y$} \\
                \lnot y & \text{if $Y\ne y$} \\
            \end{cases}}
            % p \mathrm{~or~} b~(X) &:= \begin{cases}
            % 	p(B) & \text{if $X = a^*$} \\
            % 	\delta_{B=b} & \text{if $X = b$}
            % \end{cases}
        \end{align*}
    \end{minipage}
% \end{center}
    % \medskip
    \caption{A widget PDG for capturing a single conditional probability, a statement of the form $\Pr(Y{=}y\mid X{=}x) = p$, for $p \in [0,1]$.}
    \label{fig:pyx-widget}
\end{figure}

So, when we add $\Pr(Y=y|X=x) = p$ to a PDG $\dg M$, what we really mean is:
first convert construct a widget as above, and add that structure (i.e., the new variables
$X_xY_y$ and $Y_y$, their definitions $s_1$ and $s_2$, and the cpd $\hat p$) to $\dg M$.

In what sense does this ``work''?
The first order of business
is to prove that it behaves as we should expect,
semantically.
This means showing that the widget contains precisely the information
    that $\Pr(Y{=}y|X{=}x) = p$, and nothing more. 
We now explore two ways of making this precise with the semanics of PDGs.
% , in the case we're interested in.

\begin{prop}
    If $\dg M$ is a PDG, then 
    % \[
    $
    \mu \in \SD[\big]{\dg M} 
    % \text{~~and~~}
    $ with $
    \mu(Y{=}y|X{=}x) = p
    $
    if and only if
    % \quad\iff\quad
    $
    \mu 
    % \text { extends to }
    $ extends (via $s_1,s_2$) to $
    % \SD[\Big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}
         % = \Big\{ \mu \in \SD[\Big]{\dg M}  ~\Big|~
         %        \mu(y|x) = p
         %    \Big\}
         % =  \SD[\Big]{\dg M} \cap  \Big\{ \mu : 
         %        \mu(y|x) = p
         %    \Big\}
    \bar\mu \in \SD[\big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}.
    % \]
    $
\end{prop}
\begin{proof}
    ($\implies$.)
    Suppose $\mu \in \SD{\dg M}$ has $\mu(y|x) = p$, and let $\bar\mu$ be its extenson via the functions $s_1$ and $s_2$ to the variables $\XxYyshort$ and $\Yyshort$. 
    % Since $\mu(y|x) = p$, 
    $s_1$ ensures that $\XxYyshort = x$ precisely when $X = x$. 
    By assumption, the probability (according to $\mu$) that $Y{=}y$
    when $X{=}x$ is $p$. But $s_2$ ensures that $Y{=}y$ precisely when $\Yyshort{=}y$. 
    Thus,
    $\bar\mu(\Yyshort {=} y \mid \XxYyshort {=} x) = \mu(Y{=}y \mid X{=}x) = p$.
    Thus the first row of $\hat p$
    When $\XxYyshort \ne x$, on the other hand, then $s_1$ and $s_2$ ensure
    that $\XxYyshort = \Yyshort = Y$, thereby satisfying the other rows 
    of the cpd $\hat p$. 
    Thus, $\bar \mu$ satisfies all cpds of $\dg M$, in addition to $s_1, s_2$, and $\hat p$, and therefore $\bar\mu \in \SD[\big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}$.
    
    ($\impliedby$.)
    Choose some $\bar\mu \in \SD[\big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}$,
    and let $\mu$ be its marginal on the variables of $\dg M$. 
    By the logic above, $\bar\mu(\Yyshort {=} y \mid \XxYyshort {=} x) = \mu(Y{=}y \mid X{=}x)$.
    Since $\bar\mu$ satisfies the cpd $\hat p$, we know that $\bar\mu(\Yyshort {=} y \mid \XxYyshort {=} x) = \mu(Y{=}y \mid X{=}x) = p$ as desired.
    Since $\bar\mu$ also satisfies all the cpds of $\dg M$, we also have $\mu \in \SD{\dg M}$.
\end{proof}

We have shown that the effect of our widget on a PDG's set-of-distributions semantics is precisely to restrict to distributions $\mu$ in which $\mu(y|x) = p$. 
But this result is vacuous for inconsistent PDGs, whose set-of-distributions semantics is empty. 
We now give a result of similar character for the inconsistency semantics of a PDG, 
which shows our construction behaves appropriately for all PDGs. 

\begin{prop}%\label{lem:inc-inc-eq}
    % For all PDGs $\dg M$ with $\bbeta \ge \mat 0$ and all $\gamma > 0$, we have that
    Suppose $\dg M$ is a PDG with variables $\X$ and $\bbeta \ge \mat 0$.
    Then, for all $X,Y \subseteq \X$, $x \in \V X$, $y \in \V Y$, $p \in [0,1]$ and $\gamma \ge 0$,
    we have that:
    \[
        \aar[\Big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}_\gamma \ge \aar{\dg M}_\gamma,
    \]
    with equality if and only if there exists $\mu \in \bbr{\dg M}^*_\gamma$
    such that $\mu(Y{=}y|X{=}x) = p$.
    (Note that this condition is trivially satisfied when $\mu(X{=}x) =0$.)
\end{prop}
\begin{lproof}
    The inequality is immediate; it is an instance of monotonicity of inconsistency
    \cite[Lemma 1]{one-true-loss}, which we will discuss in depth in \cref{sec:monotone}. Intuitively: believing more cannot make you any less
    inconsistent.  We now prove that equality holds iff there is a minimizer with the appropriate conditional probability.

    $(\impliedby)$. Suppose there is some $\mu \in \bbr{\dg M}^*_\gamma$ with $\mu(Y{=}y|X{=}x) = p$.
    Because $\mu \in \bbr{\dg M}^*_\gamma$, we know that
    $\bbr{\dg M}_\gamma(\mu) = \aar{\dg M}$.
    Let $\hat \mu$ be the extension of $\mu$ to the new variables ``$\XxYy$'' and $``\Yy$'',
        whose values are functions of $X$ and $Y$ according to $s_1$ and $s_2$. Then,
    {\allowdisplaybreaks
    \begin{align*}
        &\aar[\Big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}_{\!\gamma}
            \\&\le \bbr[\Big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}_\gamma(\hat \mu) 
            \\&= \bbr{\dg M}_\gamma(\mu) + \Ex_{\mu}\left[
                \log \frac{\hat\mu(\Yyshort | \XxYyshort)}{ \hat p(\Yyshort | \XxYyshort)} \right]
            \\&= \bbr{\dg M}_\gamma(\mu) +
                \mu(X{=}x,Y{=}y) \log \frac{\mu(Y{=}y|X{=}x)}{p} \\
                &\hphantom{=\bbr{\dg M}_\gamma(\mu)}
                + \mu(X{=}x,Y{\ne} y) \log \frac{\mu(Y{\ne} y|X{=}x)}{1-p} 
            \\&= \bbr{\dg M}_\gamma(\mu) +
                \mu(X{=}x,Y{=}y) \log(1)
                + \mu(X{=}x,Y{\ne} y) \log(1) 
            \\&= \bbr{\dg M}_\gamma(\mu)
            % \\&
            = \aar{\dg M}_\gamma.
    \end{align*}}
    The equality between the third and fourth lines
    is perhaps the trickiest to see, but follows
    because for joint settings in which $X{\ne}x$,
    one can easily see that $\hat\mu(\Yyshort|\XxYyshort)$
    equals 1 with probability 1, as does $\hat p(\Yyshort|\XxYyshort)$.
    So, after dividing one by the other and taking a logarithm,
        these cases contribute nothing to the expectation.
    What remains are the two possibilities where $X{=}x$, which are shown in the second line.
    %
    To complete this direction of the proof, it suffices to observe
    that we already knew the inequality held in the opposite direction
    (by monotonicity), so the two terms are equal.

    $(\implies)$.  Suppose the two inconsistencies are equal, i.e.,
    \[
    \aar[\Big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}_\gamma = \aar{\dg M}_\gamma.
    \]
    This time, choose $\hat\mu \in \bbr{\dg M+ ~\Pr(Y{=}y|X{=}x) = p}^*_\gamma$,
        and define $\mu$ to be its marginal on the variables of $\dg M$
        (which contains the same information as $\hat \mu$ itself).
    %
    Let $q := \mu(Y{=}y|X{=}x)$. Then,

    \begin{align*}
        \aar{\dg M}_\gamma &= \aar[\Big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}_{\!\gamma} \\
         &= \bbr[\Big]{\dg M + ~\Pr(Y{=}y|X{=}x) = p}_\gamma(\hat \mu) \\
         &= \bbr{\dg M}_\gamma(\mu) +
             \mu(X{=}x,Y{=}y) \log \frac{\mu(Y{=}y|X{=}x)}{p}
             + \mu(X{=}x,Y{\ne} y) \log \frac{\mu(Y{\ne} y|X{=}x)}{1-p} \\
        &= \bbr{\dg M}_\gamma(\mu) +
            \mu(X {=} x) \left[ q \log \frac qp + (1-q) \log \frac{1-q}{1-p} \right] \\
        &= \bbr{\dg M}_\gamma(\mu) + \mu(X{=}x) \kldiv qp \\
        &\ge \aar{\dg M}_\gamma + \mu(X{=}x) \kldiv qp
    \end{align*}
    Therefore $0 \ge \mu(X{=}x) \kldiv qp$. But relative entropy is non-negative,
    by Gibbs inequality. This shows $\mu(X{=}x) \kldiv qp = 0$.
    So either $\mu(X{=}x)$, or $p = \mu(Y{=}y|X{=}x)$, and the first case is just
    a special case of the second one.
    In addition, the algebra above shows that $\mu \in \bbr{\dg M}^*_\gamma$, as its
        score is $\aar{\dg M}_\gamma$.
    Thus, we have found $\mu \in \bbr{\dg M}^*_\gamma$ such that $\mu(Y{=}y|X{=}x) = p$, completing the proof.
\end{lproof}
    

\subsection{Couplings}
    \label{sec:coupling-widget}
% The set of couplings $\
Suppose that $p(X)$ and $q(Y)$ are probability distribuitons.
A \emph{coupling} between $p$ and $q$ is a joint distribution over $X$ and $Y$ whose marginal on $X$ is $p$ and whose marginal on $Y$ is $q$. 
Couplings are an important tool for probabilistic reasoning, and are the basis of optimal transport theory \cite{optimal-transport}, 
a wide range of programming logics \cite{Kaminski_Katoen_Matheja_2020}.

% Let $\Pi(p,q)$ be the set of couplings of $p$ and $q$, i.e.,
% the set of joint distributions that have respective marginals $p$ and $q$.
Formaly, the set of couplings between $p$ and $q$ is defined as
\[
    \Pi(p(X), q(Y)) := \Big\{ \mu \in \Delta\V(X,Y) :\quad
        \mu(X) = p, ~\mu(Y) = q \Big\};
\]
Observe that this
% Observe that this 
is exactly the set of distributions
consistent with a PDG containing $p$ and $q$, i.e., 
\[
    \Pi(p, q) = 
    \SD*{\begin{tikzpicture}[center base]
        \node[dpad0] (X) at (-0,0) {$X$};
        \node[dpad0] (Y) at (1,0) {$Y$};

        \draw[arr2, <-] (X) to
            node[left]{$p$}
            +(0,1);
        \draw[arr2, <-] (Y) to
            node[left]{$q$}
            +(0,1);
    \end{tikzpicture}~~}.
\]

But the couplings themselves are not all that a PDG can capture. 
Suppose we have a distance metric $d$ on a space $X$.
For $k \in [1,\infty)$, 
the $k$-Wasserstein distance between $p,q \in \Delta X$ is given by
\[  
    W_k(p,q) := \inf_{\mu \in \Pi(p,q)} \Ex_{\mu} \Big[d(X,Y)^k\Big]^{\frac1k}.
\]


This definition effectively takes $p(X)$ and $q(X)$ with
    high confidence, by constraining to $\mu \in \Pi(p,q)$.
But, in order to represent this as a PDG, we need to represent 
the $d$ in probabilistic terms.
A distance is not a probability. But we can encode the belief
that the values of $X$ and $Y$ are close, according to $d$.

Let $\Tru$ be a variable that in principle can be
either $\trut$ or $\truf$, but happens to always be $\trut$.
% to convert it  to a Gibbs distribution. 
To place more probability in $\truf$ as $d(X,Y)$ increases.
\[
    \hat d(\Tru=\trut | X,Y) \propto \exp(- d(X,Y)).
\]

We then have:
\begin{prop}
    \[
        \aar**{\begin{tikzpicture}[center base]
            \node[dpad0] (X) at (-1,0) {$X$};
            \node[dpad0] (Y) at (1,0) {$Y$};
            \node[dpad0] (T) at (0,-1) {$\Tru$};
            \draw[arr2, <<-] (T) to node[above]{$\trut$} +(-1,0);

            \draw[arr2, <-] (X) to
                node[left]{$p!$}
                +(0,1);
            \draw[arr2, <-] (Y) to
                node[left]{$q!$}
                +(0,1);

            \mergearr XYT
            \node[above=0pt of center-XYT] {$\hat d$};

        \end{tikzpicture}}
        = \inf_{\mu \in \Pi(p,q)} \Ex_{\mu} \Big[d(X,Y)\Big] = W_1(p,q),
    \]
\end{prop}


{\color{gray}
We also have:
\begin{prop}
    \begin{align*}
        \aar**{\begin{tikzpicture}[center base]
            \node[dpad0] (X) at (-1,0) {$X$};
            \node[dpad0] (Y) at (1,0) {$Y$};
            %
            \draw[arr2, <-] (X) to
                node[left]{$p!$}
                +(0,1);
            \draw[arr2, <-] (Y) to
                node[left]{$q!$}
                +(0,1);
            %
            \draw[arr2] (X) to
                node[above]{$\mathrm G d$}
                (Y);
            %
        \end{tikzpicture}}
        &=
        \inf_{\mu \in \Pi(p,q)} \Ex_{\mu} \Big[d(X,Y) + \log\sum_{y}\exp(-d(X,y)) - \H_\mu(Y|X)\Big] \\
        % &=
        % \inf_{\mu \in \Pi(p,q)} \Ex_{\mu} \Big[d(X,Y) + \mathrm{softmax}_y \big[ - d(X,y) \big] \Big] - \H(\mu) + \H(p)
    \end{align*}
\end{prop}

\begin{prop}
    \begin{align*}
        \lim_{t \to \infty} \frac1t \aar**{\begin{tikzpicture}[center base]
            \node[dpad0] (X) at (-1,0) {$X$};
            \node[dpad0] (Y) at (1,0) {$Y$};
            %
            \draw[arr2, <-] (X) to
                node[left]{$p!$}
                +(0,1);
            \draw[arr2, <-] (Y) to
                node[left]{$q!$}
                +(0,1);
            %
            \draw[arr2] (X) to
                node[above]{$\mathrm G d$}
                node[below]{${\color{gray}\scriptstyle(t)}$}
                (Y);
            %
        \end{tikzpicture}}
        &=
        \inf_{\mu \in \Pi(p,q)} \Ex_{\mu} \Big[d(X,Y) \Big]
    \end{align*}
\end{prop}
}

% \subsection{}



\section{Other Representations of Knowledge and Uncertainty}
\subsection{Belief and Plausibility Functions}
    \label{sec:belplaus-as-pdg}
We now move on to another representation of uncertainty, which generalizes the notion of a probability distribution over a (for simplicity, finite) set $\Omega$, called a \emph{belief function} \cite{shafer1990probability}. 
Like a probability measure,
a belief function $\Bel$ assigns a degree of belief in $[0,1]$ to subsets $U \subseteq \Omega$.  
Belief functions must satisfy certain axioms ensuring that $\Bel(U) + \Bel(\bar U) \le 1$, and thus $\Plaus(U) := 1 - \Bel(\bar U) \ge \Bel(U)$. 
It can be shown that a probability distribution is the special case when these two relationships hold with equality, so that $\Bel = \Plaus$.  

Belief functions admit an alternate representation in terms of a \emph{mass function} $m : 2^\Omega \to [0,1]$, which yields a belief function according to $\Bel(U) := \sum_{V \subseteq U} m(V)$. 
In fact, there is a bijection between belief functions $\Bel$ and mass functions $m$. 
The only requirements on $m$ are that:
\[
m(\emptyset) = 0
\qquad\text{and}\qquad
\sum_{A \subseteq \Omega} m(V) = 1.
\]
So, in other words, $m$ is a probability over non-empty subsets $V \subseteq \Omega$. 
There is also a natural relation between values of $V$ (i.e., subsets of $\Omega$) and values of $W$ (i.e., elements of $\Omega$): containment ($\ni$). 
% As we have seen, both of these 
Both $m$ and $\ni$ can be modeled with a PDG. What happens if we put them together?
Intuitively, this PDG describes a situation in which a subset $V \subseteq \Omega$ is drawn according to $m$, and then $\omega \in V$ is picked non-deterministically.

\begin{defn}
    If $m$ is the mass function representing the belief function $\Bel$ and the plausibility function $\Plaus$, then we associate 
    all of these objects with the same PDG,
    \[
    \dg M_{m}, \dg M_{\Bel}, \dg M_{\Plaus} := \quad
    \begin{tikzpicture}[center base]
        \node[dpad1] (V) at (0,0) {$V$};
        \node[dpad1] (W) at (2,0) {$W$};
        \draw[arr2,<-] (V) to node[above]{$m$} +(-1.2,0);
        \coordinate (crash1-pool) at (1,-0.35);
        \coordinate (crash1) at (1,-0.5);
        \draw[arr2,shorten >=0pt,-] (V) to[out=0,in=90] (crash1-pool);
        \draw[arr2,shorten >=0pt,-] (W) to[out=180,in=90] (crash1-pool);
        \draw[arr2,shorten >=0pt,shorten <=0pt,->>] (crash1-pool) to (crash1);
        \draw[arr2,<<-,shorten <=0pt] (crash1) to +(0,-0.2);
        % \coordinate (crash2) at (3, 0);
        % \draw[arr2,->>,shorten >=0pt] (W) to (crash2);
        % \draw[arr2,<<-,shorten <=0pt] (crash2) to +(0.2,0);
%
        \node[above=2ex of crash1] {$\ni$};
        % \node[above=1pt of crash2] {$ {\in} U$};
    \end{tikzpicture}~,
    \]
    where $W$ is a variable taking values in $\V W := \Omega$,
    and $V$ is a variable whose possible values $\V(V) := 2^\Omega$
        are subsets of $\Omega$. 
\end{defn}


\begin{theorem}
    If $m$ is the mass function the belief function $\Bel$ and the plausibility
    function $\Plaus$, and $\dg M := \dg M_{\Bel} = \dg M_{\Plaus}$, then:
    \begin{enumerate}[wide,label={(\alph*)},topsep=0pt]
    \item 
        a distribution $\mu \in \Delta \Omega$ is the marginal
        of an extended distribution
        $\bar\mu \in \SD[\big]{\dg M} \subseteq \Delta(2^\Omega \times \Omega)$ 
        if and only if
        $\Bel(U) \le \mu(U) \le \Plaus(U)$ for all
        $U \subseteq \Omega$. 
    
    \item 
        For all $U \subseteq \Omega$, 
        $\displaystyle
        \aar*{\begin{tikzpicture}[center base]
            \node[dpad1] (V) at (0,0) {$V$};
            \node[dpad1] (W) at (2,0) {$W$};
            \draw[arr2,<-] (V) to node[above]{$m$} +(-1.2,0);
            \coordinate (crash1) at (1,-0.5);
            \draw[arr2,->>,shorten >=0pt] (V) to[out=0,in=90] (crash1);
            \draw[arr2,->>,shorten >=0pt] (W) to[out=180,in=90] (crash1);
            \draw[arr2,<<-,shorten <=0pt] (crash1) to +(0,-0.2);
            \coordinate (crash2) at (3, 0);
            \draw[arr2,->>,shorten >=0pt] (W) to (crash2);
            \draw[arr2,<<-,shorten <=0pt] (crash2) to +(0.2,0);
%
            \node[above=2ex of crash1] {$\ni$};
            \node[above=1pt of crash2] {$ {\in} U$};
        \end{tikzpicture}}
         = - \log \Plaus ( U ).
        $
    % \item 
    
    \end{enumerate}
\end{theorem}

% A few remarks before we prove the theorem. 
This theorem, which we shall prove momentarily, 
shows that PDGs of this form coincide semantically with Dempster-Shafer belief functions. 
Part (a) states that the set-of-distribution semantics is precisely the set-of-distribution semantics for $\Bel$.
Indeed, if we follow the conventions of \citet[Theorem 2.6.1]{halpern-RAU} and define $\mathcal P_\Bel := \{ \mu \in \Delta \Omega : \Bel(U) \le \mu(U) \le \Plaus(U)$ for all $U \subseteq \Omega \}$, 
\unskip\footnote{For observant readers who followed the reference: it is not hard to see that the upper and lower bounds are equivalent; \citet{halpern-RAU} uses only the lower bound, but we give both for symmetry.}
then we have shown that $\mu$ is compatible with $\dg M_{\Bel}$ if and only if is an element of $\mathcal P_{\Bel}$. 

Meanwhile, part (b) states that something quite intuitive: after adding a constraint
that event $U$ occurs, the resulting degree of inconsistency is a direct function of the (im)plausibility of $U$ to begin with---if $U$ was completely plausible, there is no inconsistency in learning $U$. 

Now for the proof of the theorem.

\begin{lproof}
    \textbf{(a)}~
    The forwards direction is easy. 
    Fix some $\bar\mu \in \SD{\dg M}$, let $\mu \in \Delta \Omega$ be its marginal on $W$. 
    Select an arbitrary $U \subseteq \Omega$. 
    % In an outcome $()$
    Keep in mind that $\bar\mu$ is a joint distribution over pairs $(A, \omega)$ that satisfy $\omega \in A \subseteq \Omega$, whose marginal on $A$ is distributed according to $m$. 
    For every such pair $(A, \omega) \in \Supp \bar\mu$, 
    if $A \subseteq U$ then clearly $\omega \in U$. 
    Thus, $\Bel(U) = \sum_{A \subseteq U} m(A) \le \sum_{\omega \in U} \mu(W{=}\omega) = \mu(U)$.
    Similarly, if $\omega \in U$, then it must be that $A \cap U \ne \emptyset$, 
    so $\mu(U) \le  \sum_{A : A \cap U \ne \emptyset} m(A) = \Plaus(U)$.

    % For the reverse direction, 
    The reverse direction is far more subtle than it appears;
        here we present a relatively compact proof of it based on Hall's
        Mariage Theorem \cite{Hall1935}. 
    Suppose that $\mu \in \Delta \Omega$ satisfies
        $\Bel(U) \le \mu(U) \le \Plaus(U)$ for all $U \subseteq \Omega$.
    Assume for simplicity that the possible outputs of $m$ and $\mu$ are rational numbers, and let $N$ be their common denominator. 
    We now construct a bipartite graph $G = (L, R, \mathcal E)$ be a bitartite graph with $|L| = |R| = N$ vertices in each part.
    The left part $L = \sqcup_{\omega \in \Omega} L_\omega$ 
    is partitioned to be in bijection with the elements of $\Omega$, with
        $|L_\omega| = \mu(\omega)\cdot N$. 
    % (This is made possible by our assumption that $\mu$ is )
    Symmetrically, $R = \sqcup_{A \in \Omega} R_A$, where each $R_A$
        consists of $|R_A| = m(A) \cdot N$ vertices.
    For notational convenience, for $u \in L$, let $\omega_u$ be the element of $\Omega$ corresponding to the partition containing $u$; symmetrically,  let $A_v$ be the subset associated with the partition of $v \in R$. 
    Finally, let $\mathcal E := \{ (u,v) \in L \times R : \omega_u \in A_v\}.$
    Observe that a perfect matching $E \subseteq \mathcal E$ in the graph $G$ amounts to a coupling between the marginal distributions $\mu \in \Delta\Omega$ and $m \in \Delta(2^\Omega)$, supported only on $(\omega, A)$ such that $\omega \in A$.
    To be fully precise, that coupling would be a joint distribution $\bar\mu_E(\omega, A) := \frac1N |\{ (u,v) \in E : \omega_u \in A_v \}|$ that is both an element of $\SD{\dg M_\Bel}$ and an extension of $\mu$. 
    What remains is only to show that there exists such a perfect matching, for which we turn to Hall's Mariage criterion.     
    
    Hall's Mariage Theorem states that there exists a perfect matching
    for $G$ if and only if, $|T| \le  |\partial_G(T)|$ for all $T \subseteq L$,
    where $\partial_G(T) = \{ v \in R : \exists u \in T.~\omega_u \in A_v\}$ is the set of vertices connected to $T$ by an edge. 
    We now prove that this is the case.
    Choose any subset $T \subseteq L$ of vertices, and define $U_T := \{ \omega \in \Omega : T \cap L_\omega \ne \emptyset \}$ to be the elements of $\Omega$ represented by some vertex in $T$. 
    On one hand,
    \[ 
        |T| \le | \bigcup_{u \in T} L_{\omega_u} | 
            =  \sum_{\substack{\omega \in \Omega \\ L_\omega \cap T \ne\emptyset }}
            = \mu(U_T).
    \]
    On the other hand, 
    \begin{align*}
        |\partial_G(T)] &=  |\{ v \in R : \exists u \in T.~\omega_u \in A_v \}| \\
            &= \sum_{\substack{A \subseteq \Omega \\ \exists u \in T.~ \omega_u \in A}} m(A)
            = \sum_{\substack{A \subseteq \Omega \\ U_T \cap A = \emptyset}} m(A)
            = \Plaus(A).  
    \end{align*}
    But recall that, by assumption, $\mu(U_T) \le \Plaus(U_T)$. 
    This allows us to 
    chain together the previous seven (in)equalities, thereby proving that $|T| \le |\partial_G(T)|$ as desired.
    By Hall's criterion, this means there must exist a perfect matching, and we have already seen this means $\mu$ can be extended to some $\bar\mu \in \SD{\dg M_{\Bel}}$, as desired.
    % \begin{align*}
    %     \mu(U_T) &\le \Plaus(U_T)
    %         &= \sum_{\substack{A \subseteq \Omega \\ A \cap U_T \ne \emptyset}} m(A)
    %         &= |\{ v \in R : \exists u \in T :  \}
    % \end{align*}
    % $\mathcal A_T := \{ A \subseteq \Omega : \exists u \in T : \omega_u \in A\}$.
    % \begin{align*}
    %     \sum_{\substack{A \subseteq \Omega \\ A \cap U \ne \emptyset}}
    % \end{align*}
    % For the reverse direction, we first need to build up a few concepts first.  
    % According to that theorem, for every $U \subseteq \Omega$, we know that $\Bel(U) = \inf_{\mu' \in \mathcal P_\Bel} \mu'(U)$, and $\Plaus(U) = \sup_{\mu' \in \mathcal P_\Bel} \mu'(U)$.  Since $\mathcal P_\Bel$ is closed and bounded, the infimum and supremum are achieved. For a given $U$, let $\mu_*^{U}$ and $\mu^*_{U}$ denote the minimizing and maximizing distributions, respectively, so that $\Bel(U) = \mu_*^{U}(U)$ and $\Plaus(U) = \mu^*_{U}(U)$.  
    %
    % We can now address the reverse direction directly. Suppose that $\mu$ satisfies
    % $\Bel(U) \le \mu(U) \le \Plaus(U)$ for all $U \subseteq \Omega$---that is, $\mu \in \mathcal P$. We now construct a cpd $q(W \mid V)$ according to 
    % \[
    %     q(\omega \mid A) := \mu_*^{A}(\omega) 
    %         + \frac{\mu(A) - \Bel(A)}{\Plaus(A) - \Bel(A)} (\mu^*_{A}(\omega) - \mu_*^{A}(\omega) ).
    % \]
    % $q(W|A)$ is a probability distribution for every fixed $A$, since it is a convex combination of two probability measures.
    % \begin{align*}
    %     % \Big(\text{ e.g., })
    %     \sum_{\omega \in \Omega} q(\omega \mid A)
    %     &= \sum_{\omega \in \Omega} \mu_*^{(A)}(\omega) 
    %     + \frac{\mu(U) - \Bel(U)}{\Plaus(U) - \Bel(U)} \sum_{\omega \in \Omega} (\mu^*_{(A)}(\omega) - \mu_*^{(A)}(\omega) ) 
    %     = 1 + 0. 
    % \end{align*}
    % We claim that the distribution $\bar\mu(V, W) := m(V) q(W | V)$ is an extension of $\mu$ and an element of $\SD{\dg M_{\Bel}}$. 
    % \begin{itemize}
    %     \item We start by showing that $\bar\mu(W) = \mu(W)$. 
    %     \begin{align*}
    %         &\sum_{A \subseteq \Omega} \bar\mu(A, \omega)  \\
    %         &= \sum_{A \subseteq \Omega} m(A)  
    %         \mu_*^{(A)}(\omega) 
    %         + 
    %         \sum_{A \subseteq \Omega} m(A) \frac{\mu(A) - \Bel(A)}{\Plaus(A) - \Bel(A)} (\mu^*_{A}(\omega) - \mu_*^{A}(\omega) )\\
    %         &=
    %     \end{align*}
    %     \item 
    % Clearly its marginal on $V$ is $m$, as required. 
    % \end{itemize}
    


    
    \textbf{(b)}~
    Let $\mathcal P := \{ \bar\mu \in \Delta(2^\Omega \times \Omega) : \bar\mu(W \in U) = \bar\mu(W \in V) = 1\}$ be the set of all distributions satisfying the hard constraints
    of the PDG in question. 
    Let $\mathcal A_U := \{ A \subseteq \Omega : A \cap U \ne \emptyset\}$
    be the collection of subsets of $\Omega$ with non-empty intersection with $\Omega$.
    It is not not too difficult to see that the marginal projection of $\mathcal P$
        onto the variable $V$ 
        is the same as the set
    $\Delta \mathcal A_U$ of distributions supported on sets with non-empty intersection with $U$. 
    With these facts in mind, we calculate
    \begin{align*}
    \aar*{\begin{tikzpicture}[center base]
        \node[dpad1] (V) at (0,0) {$V$};
        \node[dpad1] (W) at (2,0) {$W$};
        \draw[arr2,<-] (V) to node[above]{$m$} +(-1.2,0);
        \coordinate (crash1) at (1,-0.5);
        \draw[arr2,->>,shorten >=0pt] (V) to[out=0,in=90] (crash1);
        \draw[arr2,->>,shorten >=0pt] (W) to[out=180,in=90] (crash1);
        \draw[arr2,<<-,shorten <=0pt] (crash1) to +(0,-0.2);
        \coordinate (crash2) at (3, 0);
        \draw[arr2,->>,shorten >=0pt] (W) to (crash2);
        \draw[arr2,<<-,shorten <=0pt] (crash2) to +(0.2,0);
%
        \node[above=2ex of crash1] {$\ni$};
        \node[above=1pt of crash2] {$ {\in} U$};
    \end{tikzpicture}}
    &= \inf_{\bar \mu \in \mathcal P} \kldiv{ \mu(V) }{ m }\\
    &= \inf_{\nu \in \Delta\{ A \subseteq \Omega : A \cap U \ne \emptyset\}}
            \Ex_{A \sim \nu} \Big[ \log \frac{\nu(A)}{m(A)} \Big]
    \intertext{(since the objective on first line does not depend on the marginal on $W$, except through the constraint)}
    &=  \inf_{\nu \in \Delta \mathcal A_U}
            \sum_{A \in \mathcal A_U}
                \nu(A) \log \frac{\nu(A)}{m(A)} \\
    &\ge \Big({\textstyle\sum_{A \in \mathcal A_U} \nu(A)} \Big)
        \log \frac{\textstyle\sum_{A \in \mathcal A_U} \nu(A)}{{\textstyle\sum_{A \in \mathcal A_U} m(A)}},
    \end{align*}
    by the log-sum inequality \cite{CoverThomas}.
    Moreover, the log-sum inequality states that this holds 
    with equality if and only if there is some constant $k$ so that
        $\nu(A) = k m(A)$ for all $A \in \mathcal A_U$. 
    By definition, $\Supp \nu \subseteq \mathcal A_U$, and thus
    $\sum_{A \in \mathcal A_U} \nu(A) = 1$. Therefore, the inconsistency we have been calculating is equal to
    \[
        - \log \sum_{A \in \mathcal A_U} m(A) = - \log \Plaus(U).
        \qedhere
    \]
\end{lproof}

\subsection{Causal Models}
    \label{ssec:capture-causal-models}


PDGs can also capture causal models. 


%%% MATERIAL LIFTED FROM CAUSAL MODEL PAPER
\begin{defn}[\citet{pearl2009causality}]
        \label{defn:SEM}
    A \emph{structural equations model} (SEM) is a tuple
    %oli15: being more consistent about reserving \cal M for PSEMs
    % $\mathcal M = (\U, \enV, \mathcal F)$,
    $M = (\U, \enV, \mathcal F)$,
    % $\mathcal M = (\U, \X, \mathcal F, \V)$,
    % $M = (\U, \enV, \mathcal F, \mathcal I)$,
    where
    % $\V$ is as before,
    \begin{itemize}[left=0pt,itemsep=0pt,topsep=0pt,parsep=0.3ex]
    \item $\U$ is a set of exogenous variables;
    \item $\enV$ is a set of endogenous variables (disjoint from $\U$);
    % \item $\mathcal F$ is an indexed set of functions consisting of an equation $f_Y : \V (\U \cup \enV - Y ) \to \V(Y)$ that determines is value as a function of the values of the other variables.
    \item $\mathcal F = \{ f_Y \}_{Y \in \enV}$ associates to each endogenous variable $Y$ an \emph{equation}
    $f_Y : \V (\U \cup \enV - Y) \to \V(Y)$
     that determines its value as a function of the other variables. 
        \qedhere
    \end{itemize}
\end{defn}

% %oli3: the definition in this sentence may not be necessary; graying out for now
% %joe4: I would prefer to cut the definition.
% %oli5: as you wish
% \commentout{
Given a SEM $M = (\U, \enV, \mathcal F)$, and a joint setting $\mat u \in \V(\U)$ of exogenous variables, let
\[
    % M(\mat u) :=
    \mathcal F(\mat u)
    := \Big\{
        \mat x \in \V\! \enV ~\Big|~
            \forall Y \,{\in}\, \enV.~
            f_{Y}\big(\mat u,~ \mat x[ \enV {-} Y ]\big) = \mat x[Y]
    \Big\}
        % \quad \subseteq \V\! \enV
\]
be the set of joint endogenous variable settings that are consistent with $\mat u$, according to the equations $\mathcal F$.
% }
%
% A SEM is called \emph{acyclic}
% if for every $\mat u \in \V \U$, there is a total order $\prec_{\mat u}$ on $\enV$ such that, $f_{X}(\mat u, \mat z)$ does not depend on $\mat z[Y]$  when $X \prec_{\mat u} Y$,
% and \emph{structurally acylic}%
%     %
%     \footnote{for Joe: this is important because structural acyclicity,
%         which is standard in some settings, is the qualitative proeprty, and
%         the one that leads to a correspondence with BNs.}
%     %
% if $\prec_{\mat u}$ can be chosen
% so that it does not depend on $\mat u$.
%oli6: taking your approach even further:
In a SEM $M$, a variable $X \in \enV$ \emph{does not depend} on $Y \in \enV\cup\U$ if $f_X(\ldots, y, \ldots) =
f_X(\ldots, y', \ldots)$ for all $y, y' \in \V(Y)$.
%oli6: moving up from next section, and significantly compressing; it belongs here.
Let the parents $\Pa_{M}(X)
 % \subseteq \V(\enV \cup \U - X)
$
%joe7
%of $X$ to be the set of variables on which it depends.
of $X$ be the set of variables on which $X$ depends.
%joe4
%A SEM is called \emph{acyclic}
% A SEM is \emph{acyclic}
%oli6:
$M$ is \emph{acyclic}
%oli6: 
% if there is a total order $\prec$ on $\enV$ such that
%joe4: Why do f_X need arguments?  What is their role in the
%definition.  What is z[Y]?
%$f_{X}(\mat u, \mat z)$ does not depend on $\mat z[Y]$  when $X \prec Y$.
%oli5: z[Y] is the value of Y in joint setting z. We'll need this notation
% eventually, either way.  I prefer my version, but let's go with yours. 
%oli5: fixing up your version so it compiles (and removing duplicate parens):
% $f_{X}$ does not depend on $Y$ (i.e., $f_X(\ldots, y, \ldots) =
% f_X(\ldots, y', \ldots)$ for all $y, y' \in \V(Y)$) when $X \prec Y$.
%oli6: a few possibilities:
% if $X \prec Y$ implies $X$ does not depend on $Y$. 
% if this is the case whenever $X \prec Y$. 
% if $X$ does not depend on $Y$ whenever $X \prec Y$. 
%oli16*: this is an ambiguous definition, and arguably wrong, because of how it treats exogenous variables
% if $\Pa_M = \Pa_G$ for a directed acyclic graph $G$. 
% iff there is a total order $\prec$ on $\enV$ such that $X$ does not depend on $Y$ when $X \prec Y$. 
iff $\Pa_M(X) \cap \enV = \Pa_G(X)$ for some dag $G$ with vertices $\enV$. 
% iff there is a total order $\prec$ on $\enV$ such that $X$ does not depend on $Y$ when $X \prec Y$. 
% if the negation of this relation is a directed acyclic graph. 
%joe4: I on't know what it means to determine the value of each
%exogenous variable according to this order.  
%oli5: I thought it was obvious that this means you go one by one through the variables in this order, and determine them by applying their corresponding functions.  If this is not obvious, I don't see how your replacement statement is obvious.
%joe4: Moving up a level, it
%seems ot me that you're making things too complicated here.
%oli5: I disagree that what I wrote is more complicated (I think it
% gives more intuition, yet is shorter). We also still need to bind
% f $f_\enV$ for several purposes (e.g., the next sentence). But this is
% not the hill I want to die on, so I'll start from your version.
% (I've consolidated my version for reference below.)
\commentout{
    It is easy to see that,
    by determining the value of each exogenous variable according to this order,
    $\mathcal F(\mat u)$ is a singleton for acyclic models, in which case
    $\U$ determine $\enV$ via a function $f_{\enV} : \V (\U) \to \V(\enV)$.
}
% It is easy to see that,
% in an acyclic SEM, 
In an acyclic SEM, it is easy to see that 
a setting of the exogneous variables determines the
values of the endogenous variables
%oli14: reminding of this notation, because it will come in handy to refer to this property more briefly than the English above. 
(symbolically: $M \models \U \tto \enV$).
%oli5: adding this, because we use the notation below. (I still like my approch better, but I can live with this once we define $f_{\enV}$.)
%oli5.2: the extra bit I added was clunky and long. Making it shorter, but like I had before.
% ; let $f_{\enV} : \V (\U) \to \V(\enV)$ be a function capturing this determination.
%oli6:
% by a function $f_{\enV} : \V (\U) \to \V(\enV)$.
%oli8: no longer used; I know you dislike it; we can now safely delete.
% let  $f_{\enV} : \V (\U) \to \V(\enV)$ capture this relationship.
% \begin{remark}
%     This definition depends heavily on variable identity.
%         This is an artificial limitation, and due to the fact that there is precisely
%         one equation per variable.
%     We illustrate with an example construction.
%     Given a SEM $(\U, \enV, \mathcal F)$,
%     let's construct a new SEM $(\U, \enV \sqcup \enV, \mathcal F')$, with two copies of each endogenous variable $X \in X$: one which we call $X.0$, and one which we call $X.1$.
%     How shall we set the equations?
%     \[
%         F'_{X.0}(\mat u, \mat x.0, \mat x.1) = F_X(\mat u, \mat x.0)
%     \]
%     Intuitively, all of these should be true.
%
%     \TODO
% \end{remark}
%oli8: merging paragraphs.
%
A \emph{probabilistic SEM} (PSEM)
%oli2: compressing and changing \nu to P to avoid confusion. (\nu
% changed to P later on silently without marking.)
% $\mathcal M = (\U, \enV, \mathcal F, \nu)$ is a SEM in which
%oli8: shortened
% $\mathcal M = (\U, \enV, \mathcal F, P)$ 
$\mathcal M = (M, P)$ 
is a SEM,
%joe8: As I've said repeatedly, yoyr quest for precision will (a)
%confuse the reader and (b) is misguided.  If you can explain to
%Spencer why you need this and he's convinced, then I'd be willing to
%diss it further.  If your goal is to snow the reader, you're doing well.
%oli19: I've convinced Spencer that it creates a big technical problem if we don't assume variables are measurable.  However, I'm willing not to say it out loud here if we leave in the parenthteical early on when we defined a variable as taking on a value from "a (measurable) set of possible values"
%joe14*: One author convincing a second author of something when the
%third author is still unconvinced is absolutely, positively not the
%basis for adding it to a paper.  Do you really not see how absurd
%your coment below is?  Since it seems you're reoved "measurable", it
%seems that we've converged.
%oli20: I've removed "measurable" here, and put "(finite)" earlier in section 2 (because it will make the discussion about entropy a thousand times simpler).  I mentioned Spencer here not as a basis for forcefully changing the paper, but rather because above you say "If you can convince Spencer, I'd be willing to discuss it further". 
% in which $\V(Z)$ is measurable for all $Z \in \U \cup \enV$,
% (in which all variables have measurable domains)
together with a probability 
%oli21: shaving
% measure
$P$ over the exogenous variables.
%
% If $M = (\U, \enV, \mathcal F, \nu)$ is an acyclic PSEM,
\commentout{
If $\cal M$ is acyclic, then it
    determines a 
    distribution over the endogenous variables $\enV$,
    by the pushforward of $P(\U)$ through
    the function $f_{\enV}$.
    % $f_{\enV}$.
}%
%joe4*: I don't understand your notation, and find it *far* too complicated.
%oli5: I fixed a typo that should help you understand the notation. I don't think the notation is at all complicated here, and for people like me, the notation is better than the words.  But I'm trying to cut things, so and what you wrote is shorter, so I'll write something based on your version.
\commentout{
    In this case, $P$ extends uniquely to a joint distribution
    $\nu(\U, \enV) = P(\U) \delta\! f_{\enV}(\enV \mid \U)$, where the notation $\delta g(B|A)$ describes the (deterministic) cpd
    %oli1:
    % that corresponds to the function $f : \V \! A \to \V \! B$.
    %oli5: here's one reason for confusion: a typo in which I replaced f with g.
    % that corresponds to the function $f : \V (A) \to \V (B)$.
    that corresponds to the function $g : \V (A) \to \V (B)$.
}%
%oli5: your version, which I've improved
%oli6: and then later merged with the previous setnence
{%
    %oli5: What is the point of "easily"?  Also, this distribution over the exogenous variables has a name. 
    % It easily follows that a distribution on the exogenous variables $\U$ can be
    %oli14: previously broken sentence. Adding a sensible first part. 
    When $\mathcal M \models \U \tto \enV$ 
    %oli21: can't afford the extra reminder; we just defined this
    \vfull{%
    (such as when $M$ is acyclic)%
    },
    the distribution
    %oli6:
    % It follows that $P(\U)$  
    $P(\U)$
    %oli5:
    % extended uniquely to a distribution on $\U \times \enV$.    
    extends uniquely to a distribution over $\V(\enV \cup \U)$.    
}%
%joe4*: what does "correspond" mean?  You haven't defined it.  (I know
%what you mean, of course, but a reader can't read your mind.  Rewrote
%oli5: I don't understand why you're asking such questions. I define it immediately below. Also, there's an easy fix here: replace "correspond" with "extend". Or, as you do, below, with "induce".
% A cylic PSEM, however, may correspond to more than one such distribution, or none at all.
A cyclic PSEM, however, may induce more than one such distribution, or none at all.
In general, a PSEM $\cal M$
induces a (possibly empty) convex set of distributions over $\V(\U \cup \enV)$.
This set is defined by two (linear) constraints:
the equations $\mathcal F$ must hold with probability 1, and
\unskip, in the case of a PSEM,
the marginal probability over $\U$ must equal $P$. 
% Formally, for a PSEM $\mathcal M = (\U, \enV, \mathcal F, P)$, define
%joe4*: this notation will only confuse th rader.  If you're going to
%keep it (and I see no reason to), you have to explain it better.
%oli5: I can run with your replacement explanation in English, but I find the symbolic version far more satisfying and precise. There is value to having both.  English is full of ambiguities, and I don't want definitions like this one to rest on interpretation. I've already compiled it to math, for the reader who would rather read math than English.  
\vfull{
Formally, for a PSEM $\mathcal M = (M, P)$, define
%oli2: slight notational change that might better suit our uses
% $\SD[\big]{\mathcal F, \nu} := $\\[-0.2ex]
$\SD{\mathcal M} := $
% \\[-0.2ex]
% \\
% \vspace{-1.5ex}
% $\displaystyle
\[
    \bigg\{
    %joe3
       \nu {\,\in\,} \Delta\!\V(\enV \cup \, \U)
    %oli3: I agreed to give you your parens for the arguments of \V,
    % but I still object to putting parens around the arguments to 
    % \Delta.  In this particular case, the spacing only barely works as is, and the parens make the left half twice as difficult to parse.  The \Delta also fits very nicely well next to the \V.  I suggest we dont think of \Delta$ as being meaningful on its own; define "\Delta\V" together as meaning distributions over values.
    %oli3: reverting to above
        % \nu {\,\in\,} \Delta(\V(\enV \cup \, \U))
            \,\bigg|\!
        \begin{array}{l}
            %oli2: swapped order of two equations to match English
            \forall Y \!\in\! \enV.~~
            % \text{ and }
            % \forall Y \in \enV.
            % \\
            \nu\Big( f_Y(\mathcal U,
                % \enV {\setminus}\{Y\}
                \enV {-} Y
            ) \,{=}\, Y\Big) \,{=}\, 1
            % \\ ~\text{for all $Y \in \enV$}
            ,
            \\[0.2ex]
            % \qquad
            \nu(\U) = P(\U)
        \end{array}\!\!
        \bigg\}
% $
% \vspace{-1ex}
\]
and define $\SD{M}$ for an ``ordinary'' SEM $M$ in the same way,
    except without the constraint involving $P$.
% This definition might be clarified if we unpack it slightly
% The final line may be difficult to read;
% To unpack the last line:
%oli2: expanding
% To unpack the first constraint:
%oli3: essentially reverting
% The other constraint may be harder to parse. Unpacking it, 
To unpack the other constraint,
observe that
% $f_{Y}(\U, \enV \setminus \{Y\})$
$f_{Y}(\U, \enV - Y)$
is a random variable
%oli2: should we hide this, because it's the only sample space in sight?
%joe3: I don't feel strongly about it
on the outcome space $\V(\enV,\U)$,
and that it
%joe3*: I find this really confusing.  I have never thought of Y as a
%random variable that takes inputs from \U and X-\{Y\}.  I can't
%imagine that anyone other than you has either.   If I were to think of it
%as a function all, it would be a function of the context.  At a bare
%minimum, this needs much more comment.
%oli3: What else is there to say?  You're also making it more complicated than it needs to be.  Every function f_Y is a function of \U and \enV, and so all of these functions are variable for the same sample space \V(\U,\enV) which is the same as the sample space of the distribution \nu.  It's not that each function is a special random variable with a restricted sample space. In any case, your way of thinking about it is totally compatible with this one. As a function of the context, f_Y is a function \U -> (\enV -> Y). But we still need to say that, according to the distribution $\nu$, the equation always holds.  But now you need to specify "always" with respect to the marginal on \enV.  I think this approach to thinking of what's going on is not just clunkier, but also less standard. It's far cleaner just to use the sample space \V(\U,\enV) throughout. 
has the same value as $Y$ is an event
 % of interest that must always occur
which, according to the equation $f_Y$,
must always occur.
}%
% In a probabilistic context such as this one, a (set of) variable(s) $\mat X \subseteq \U \cup \enV$ is also a \emph{random variable}, i.e., a function from the sample space $\Omega = \V(\enV \cup \U)$ to the range $\V \mat X$, by projection.
% This makes $F_X(\mathcal U, \enV - \{ X \}) = X$,
% an event $\{ (\mat u, \mat x) :  \mat u \in \V\U, \mat x \in \mathcal F(\mat u) \} \subseteq \Omega$, and hence we can require that it has probability 1, which is the second condition above.
%%% END MATERIAL LIFTED FROM CAUSAL MODEL INTRO %%%
Given a 
%oli21: we don't use the generality anymore for ordinary SEMs, I think
% (P)SEM 
PSEM
 $\mathcal M$, let $\SD{\mathcal M}$ consist of all 
joint distributions $\nu(\U, \enV)$ that satisfy the two constraints above
%cutting down
\vfull{%
%oli21: this is clearly implied,  not helping the reader, and long (and unused, I think)
(or just the first of them, in the case of a non-probabilistic SEM).
%oli21: this is not as useful as the next sentence, which subsumes it; cutting for space. 
$\SD{\cal M}$ can be thought of as the set of distributions compatible
wth $\cal M$. It
}%
%oli21: merging sentences
\unskip; this set
captures the behavior of $\cal M$ in
the absence of interventions.  
%oli14: defining what it means to "arise", because it will be easier and shorter this way.
A joint distribution $\mu(\mat X)$ over $\mat X \subseteq \enV \cup \U$ \emph{can arise from} a (P)SEM $\mathcal M$ iff there 
is
% exists
some $\nu \in \SD{\mathcal M}$ whose marginal on $\mat X$ is $\mu$.
%oli16: some extra words, for clarity, brought on by Spencer's comment
%joe8*: This is a distraction.  Readers won't havea clue what youy
%eabn y "set-of-distribution semantics".  You should have to explain
%it.  I cut this
%oli19: OK; I'll leave it cut, but we may want to revisit it depending on how much we talk about PDGs.
\commentout{
We remark that a (P)SEMs $\cal M$ is naturally a special case of a PDG, and that $\SD{\mathcal M}$ is the set-of-distributions semantics of that PDG. 
}
% Keep in mind that $\SD{\cal M}$ captures the behavior of $\cal M$ in the absence of intervention. 
% While much of causality is about the effects of intervention, .
%oli5: this is not an efficient use of space; moved the critical part above.
\commentout{
    For a SEM $M$, we take $\SD{M}$ to consist of all 
    %oli5:
    % distributions in $\SD(M,P)$ for some distribution $P$ on the exogenous variables of $M$; 
    distributions $\nu \in \SD{M,P}$ for some distribution $P$ on the exogenous variables of $M$; 
    equivalently
    %oli5:
    % SDM $M$ consists of all
    $\SD{M}$ consists of all
    distributions that satisfy
    the first of the two constraints above.
}
% \TODO[TODO: Move Causality Intro Here]


\begin{prop}
    
\end{prop}

\subsection{Pseudomarginals and Clique Trees}

\subsection{Implicit Neural Representations}
