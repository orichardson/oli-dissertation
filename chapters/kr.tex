
PDGs are extremely expressive.
We saw in \cref{sec:bn-convert,sec:factor-graphs,sec:expfam} that PDGs
can capture graphical models such as Bayesian Networks and Factor graphs. 
But far more is true. In this 

\section{Capturing other Representations of Knowledge and Uncertainty, with PDGs}

Probability is the dominant way that computer computer scientists and
microeconomists think about an epistemic state.  Standard arguments \cite{morgenstern-von-neuman,savage}, 

\subsection{Probabilities}

We start with a rather obvious construction, that is nonetheless important
to keep in mind: a joint distribution can be viewed as a very special case of a PDG. 
Concretely, let $\X$ be a set of variables, and recall that $\V\!\X$ is the set of all joint settings of the variables $\X$. 
A joint distribution $\mu \in \Delta \V\!\X$ can be viewed as a PDG
that has 


Of course, the development and semantics of PDGs 
    makes heavy use of the notion of a joint distribution $\mu \in \Delta \V\!\X$ over
    a set of variables $\X$. 
    
\subsection{Pseudomarginals and Clique Trees}


\subsection{Belief and Plausibility Functions}

\begin{theorem}
    
\end{theorem}

\subsection{Implicit Neural Representations}
\subsection{Causal Models}
    \label{ssec:capture-causal-models}

\TODO[TODO: Move Causality Intro Here]

\section{Widgets}
\subsection{Incomplete CPDs and Individual (Conditional) Probabilities}
\subsection{Relations and Constraints}
\subsection{Couplings}
% \subsection{}
