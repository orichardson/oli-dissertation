\label{chap:infer}

\newif\ifvfull
    \vfulltrue %


So far, we have seen that PDGs are a flexible modeling tool that
    plays two seemingly very different roles.
On one hand, PDGs specify a joint distribution; in this capacity, they are an especially modular and interpretable generalization of standard probabilistic graphical models.
On the other hand, PDGs have a natural inconsistency measure; in this capacity, they are a principled model-based way to specify a loss function.
% Yet, even several years after their introduction, 
% Yet, up until this point, there 
Yet our discussion so far leaves a burning question: how can we compute with PDGs? Is it even possible? 
So far, we have seen no reason that there should be any practical way to compute with PDGs in either role: no inference algorithm, and no (provably correct) way to calculate the degree of inconsistency.
% In this chapter, we address both issues.
% This chapter is based on a paper that resolves both issues \cite{pdg-infer}.
In this chapter, we solve both problems. 

\section{Introduction}

As we have seen,
% \emph{Probabilistic dependency graphs (PDGs)} \parencite{pdg-aaai},
% Probabilistic Dependency Graphs (PDGs) 
PDGs (\cref{def:model})
form a very general class of probabilistic graphical models,
that includes not only
Bayesian Networks (BNs) and
Factor Graphs (FGs),
but also more recent statistical models built out of neural networks,
such as Variational AutoEncoders (VAEs) \parencite{kingma2013autoencoding}.
% \expandafter\discard\vjoe{
%  They can also capture inconsistent beliefs; moreover, we can measure how
%  inconsistent a probability distribution is with a PDG.  This allows us
%  to define the dgree of inconsistent of a PDG to essentially be that of the
%  probability measure that is least inconsistent with it.}%
% \expandafter\discard\voli{They can also capture inconsistent beliefs, and moreover provide a natural measurement of the degree of this inconsistency. }%
% \expandafter\discard\vjoe{They can also capture inconsistent beliefs; moreover, we can measure how inconsistent a probability distribution is with a PDG. This allows us to define the degree of inconsistenty of a PDG to essentially be that of the probability measure that is least inconsistent with it.}%
% \expandafter\discard\voli{%
%     They can also contain inconsistent beliefs, such as two different probabilities over the same variable. Moreover, there is a natural way to measure the degree of this inconsistency: starting with a measure of how incompatible a joint distribution is with a PDG, the inconsistency of the PDG is the smallest incompatibility with any joint distribution.  }%
% \discard{%
%     They can also capture inconsistent beliefs,
%     Moreover, there is a useful way to quantify the degree of this inconsistency:
%     the discrepancy between the PDG, and the 
%         probability measure that 
%         best represents it.
%      }%
PDGs can also capture inconsistent 
beliefs, and provide a useful way to measure the degree of this inconsistency;
for a VAE, this is the loss function used in training
    % \parencite{one-true-loss}.
    (\cref{sec:variational}).
% PDGs have some
% significant advantages over other representations of probabilistic information. 
%     Their flexibility allows them to model beliefs that BNs cannot, 
% such as information from independent studies of the same variable
% (perhaps with different controls, yielding probabilistic observations $p(Y|X)$ and $q(Y|Z)$).
% PDGs
% can deal gracefully with conflicting information from multiple sources.
% Every subcomponent of a PDG has probabilistic
%     meaning, independent of the other components;
% compared to FGs, this makes PDGs more interpretable.
But up to now, there has been no practical way to do inference for
PDGs---that is,
to answer questions of the form
``what is the probability of $Y$ given $X$?''
This chapter presents the first algorithm to do so.



Before discussing our algorithm, 
we must discuss what it even means to do inference for a PDG.  
A BN or FG represents 
a unique joint distribution. 
Thus, for example, when we ask ``what is the probability of $Y$ given that $X{=}x$?''
\def\BNPr{\mu}
in a BN, we mean ``what is $\BNPr(Y | X{=}x)$?'' for the probability 
measure $\BNPr$ that the BN represents.
But a PDG might, in general, represent more than just one distribution.

Like a BN, a PDG encodes
two types of information: ``structural'' 
information about the independence of causal mechanisms,
and ``observational'' information
about conditional probabilities.
Unlike in a BN, the two can conflict in a PDG.
Corresponding to these two types of information,
a PDG has two loss functions,
which quantify how far a distribution $\mu$ is from
modeling the information of each type.
Given a number $\zogamma
\in [0,1]
$
indicating the importance of structure relative to observation,
the \emph{$\zogamma$-semantics} of a PDG is the
set of distributions that minimize 
the appropriate convex combination of
losses.
We also consider the \emph{$0^+$\!-semantics}: the limiting case that
arises as $\zogamma$ goes to zero
(which focuses
 on observation, using structure only to break ties).
This set
can be shown to contain precisely one distribution
for PDGs satisfying a mild regularity condition,
% (required by definition by \citeauthor{pdg-aaai}); we call such PDGs \emph{proper}.
which we call \emph{proper}. 
Thus, we have
 a parameterized family of inference notions:
to do $\zogamma$-inference, for $\zogamma \in [0,1] \cup \{0^+\}$,
is to answer queries in a way that is true of all distributions in the $\zogamma$-semantics.

If there are distributions
fully
consistent with
both the observational and the structural information
in a PDG $\dg M$, 
then for $\zogamma \in (0,1) \cup \{0^+\}$, all
notions of $\zogamma$-inference 
coincide.
\def\PrM{\mu_{\dg M}}%
If $\dg M$ is also proper,
    this means there is
    a single distribution $\PrM$
    that minimizes both loss functions, 
    in which case we want to answer queries with respect to $\PrM$
    no matter how we weight observational and structural information. 
Moreover, if $\dg M$ represents a BN,
then $\PrM$ is the distribution represented by the BN.  
However, if there is no distribution that is consistent with both types of information, then the choice of $\zogamma$ matters.  

Since PDGs subsume BNs, and inference for BNs is already NP-hard, the same must be true of PDGs.
At a high level, the best we could hope for would be tractability on the restricted
class of models on which inference has traditionally been tractable---that is, a polynomial algorithm for models whose
underlying structure has \emph{bounded treewidth} (see
\Cref{sec:tw} for formal definitions).
That is indeed what we have.  
More precisely, we show that
$0^+$\!-inference
and $\zogamma$-inference for small $\zogamma$ 
can be done 
for discrete PDGs of bounded treewidth containing $N$ variables in
$\tilde O(N^4)$ 
time.
 
Our algorithm
is based on a line of recent work in 
convex programming
that establishes
polynomial-time
for a class of optimization problems called \emph{exponential conic programs}
\parencite{badenbroek2021algorithm,skajaa2015homogeneous,nesterov1996infeasible}.
Our contribution is to show that the problem of inference in a PDG
of bounded treewidth
can be efficiently converted to a (sequence of) exponential conic program(s), at which point it can be solved with a commercial solver
(e.g., \textcite{mosek}) in polynomial time. 
The direct appeal to a solver allows us
to benefit from the speed and reliability of such highly optimized solvers, and also from future improvements in exponential conic optimization.
Thus, our result is not only a theoretical one, but practical as well.



Beyond its role as a probabilistic model,
a PDG is also of interest for its degree of inconsistency---%
that is, the minimum value of its loss function. 
As shown 
% by 
% \textcite{one-true-loss},
in \cref{chap:one-true-loss}
many loss functions and statistical divergences
can be viewed as measuring 
the inconsistency
of a PDG that models the context appropriately.
This makes calculating this minimum value of interest%
---but up to now, 
there has been no way to do so.
%
There is a deep connection between this problem and PDG inference
    (which we develop in \cref{chap:inc-infer-connection});
for now, we remark that this number is a byproduct of our techniques.
    
 
% \expandafter\discard\voli{
% Beyond its role as a probabilsitic model,
% a PDG is also of interest for its \emph{degree of inconsistency};
% As shown by \textcite{one-true-loss},
%     many loss functions and statistical divergences
%     can be viewed as measuring the inconsistency
%     of a PDG that models the appropriate context.
% It follows that the training process in machine learning can
%     be conceptualized as
%     adjusting parameters of cpds so as to minimize the inconsistency of a PDG.
%         But how {does} one \emph{calculate} this degree of inconsistency?
% This problem turns out to be closely related to that of
%     inference in PDGs, and our approach addresses both.
% }



\textbf{Chapter Contributions.}
We provide the first algorithm for inference in a PDG;
in addition, it calculates a PDG's degree of inconsistency. 
We prove that 
our algorithm
is correct, and also
fixed-parameter tractable: for PDGs of bounded treewidth,
it runs in polynomial time.
We also prove that PDG inference and inconsistency 
    calculation are equivalent problems.
Our algorithm reduces inference in PDGs to exponential conic programming
in a way that can be offloaded to powerful existing solvers.
We provide an implementation of this reduction in a
standard convex optimization framework, giving users an
interface between such solvers and the standard PDG Python library.
Finally, we evaluate our implementation. The
    results suggest our method is faster and 
    significantly more reliable than simple baseline approaches.

\section{Preliminaries \& Related Work}

\commentout{%
\textbf{Vector Notation.}
For us, a vector is a map from a finite set $S$, called its 
\emph{shape},
to the extended reals $\Rext := \mathbb R \cup \{\infty\}$.
We write $\mat u := [u_i]_{i \in S}$ to define a vector $\mat u$ by its components.
% \discard{\color{gray!30!white}
%     We will sometimes use superscripts as well, especially when indices depend on one another. For example, if $\dg S$ is a finite set of finite sets, then
%     $[u^S_s]^{S \in \dg S}_{s \in S}$ denotes a vector which has an element
%     for each pair $(S,s)$, satisfying $s \in S \in \dg S$.
%     By supplying just the upper index of such a vector, as in $\mat u^{S_0}$,
%     we mean $[u^{S_0}_s]_{s \in {S_0}}$, the projection of $\mat u$ onto the subspace whose upper index is $S_0$.
% }
Vectors of the same shape
can be added (+), partially ordered ($\le$), or multiplied ($\odot$) pointwise as usual.
$\mat 1$ denotes an all-ones vector, of a shape implied by context.
\discard{\vfull{
$\mat u^{\sf T}$ denotes the transpose of $\mat u$, and is used to
express the inner product $\mat u^{\sf T} \mat v$ of vectors $\mat u$ and
$\mat v$ of the same shape.}}

\discard{
    \color{gray!30!white} If $\mat u = [u_a]_{a \in A}$ is a vector over $A$ and $\mat v = [v_b]_{b \in B}$ is a vector over $B$, then $\mat u \mathbin{\otimes} \mat v := [ u_a \cdot v_b ]_{a \in A, b \in B}$ is a vector over $A \times B$. }

\textbf{Probabilities.}
We write $\Delta S$ to denote the set of probability distributions over a finite set $S$.
Every variable $X$ can take on values from a finite set
$\V\mskip-1.5mu X$
of possible values.
We can regard sets of variables $\mat X$ as variables themselves, with
$\V \mat X = \Pi_{X \in \mat X} \V X$.
A conditional probability distribution (cpd) $p(Y|X)$ is a map
\ifvfull
$p : \V\mskip-1.5mu  X \to \Delta \V Y$ assigning to each $x \in \V\mskip-1.5mu X$ a
probability distribution 
$p(Y|x) \in \Delta \V Y$, which is shorthand for $p(Y|X{=}x)$.
\else
$p$ that assigns each $x \in \V\mskip-1.5mu X$ a probability distribution
$p(Y|X{=}x) \in \Delta \V Y$.
\fi
\ifvfull
Given a distribution $\mu$ over (the values of) a set of variables including $X$ and $Y$,
\else
Given a joint distribution $\mu$,
\fi
we write $\mu(X)$ for its marginal 
on $X$,
and $\mu(Y|X)$ for the cpd obtained by 
\ifvfull
conditioning on $X$ and marginalizing to $Y$.
We also refer to $\mu$'s entropy
    $\H(\mu) := \Ex_{\mu} [\log \frac1\mu]$ and 
    conditional entropy $\H_\mu(Y|X) := \Ex_\mu[\log\nicefrac1{\mu(Y|X)}]$
    of $Y$ given $X$.
\else
conditioning on $X$ and marginalizing to $Y$.
We also refer to $\mu$'s entropy $\H(\mu) := \Ex_{\mu} [\log \frac1\mu]$ and conditional entropy $\H_\mu(Y|X) := \Ex_\mu[\log\nicefrac1{\mu(Y|X)}]$.
\fi
}% endcommentout



\paragraph{Treewidth.}
    \label{sec:tw}
%
% New material
Recall that 
%
an undirected hypergraph 
$
(V, \Ed)$ is a set $V$ of vertices and a
set
 $\Ed$ of subsets of $V$.
%
% 
% 
% 
% \begin{defn}
%     A \emph{directed hypergraph}
%     $(N, \mathcal A)$ is a set of nodes $N$, and
%     a set
%     of \emph{(hyper)arcs} $\mathcal A$,
%     each $a \in \mathcal A$ of which
%     is associated with 
%     a set of source nodes $\Src a \subseteq N$,
%     and target nodes $\Tgt a \subseteq N$.
%     We also write $\ed {a}{S}{T} \in \Ar$ to specify an
%     arc $a$ together with its sources $S = \Src a$ and targets $T = \Tgt a$.
% \end{defn}
Thus, a directed hypergraph 
$(N, \{ \ed a{\Src a}{\Tgt a} \}_{a \in \Ar})$
can be viewed as  a hypergraph
by joining the source and target set of each hyperarc
(i.e., taking $\Ed = \{ \Src a \cup \Tgt a : a \in \Ar \}$),
thereby ``forgetting'' the direction of the arrow.
Thus, notions defined for undirected hypergraphs (like that of
treewidth, which we now review), can be 
    applied to directed hypergraphs as well.

Many problems that are intractable for general graphs
are tractable for trees, and
some graphs are closer to being trees than others.
A tree decomposition of a (hyper)graph $G = (V, \Ed)$ is a tree $(\C, \mathcal T)$ whose vertices $C \in \C$, called
\emph{clusters}, are subsets of $V$ such that:
%
\begin{enumerate}[nosep]
    \item every vertex $v \in V$ and every hyperedge $E \in \Ed$ is contained in at least one cluster, and
    \item every cluster $D$ along the unique path from $C_1$ to $C_2$ in $\cal T$,
         contains $C_1 \cap C_2$.
\end{enumerate}

The \emph{width} of a tree decomposition is one less than the size of its largest cluster,
and the \emph{treewidth} of a (hyper)graph $G$ is the smallest possible width of any tree decomposition of $G$.
It is NP-hard to determine the tree-width of a graph, but
if the tree-width is known to be bounded above, a tree decomposition may be constructed in linear time \parencite{bodlaender1993linear}.
For graphs of bounded tree-width, many problems 
(indeed, any problem expressible in a certain second-order logic \parencite{courcelle1990})
can be solved in
linear time.
This is also true of inference in 
standard graphical models.


\textbf{Inference for Traditional Graphical Models.}
Semantically, a traditional graphical model $\cal M$ (such as a Bayesian Network or a factor graph) typically represents a joint probability distribution $\Pr_{\!\cal M}
 \in \Delta \V\!\X$ over its variables.
% \discard{
%     Although there is often more to the story,
%     it can typically be
%     expressed as a product
%     $\Pr_{\!\cal M}(\X) \propto \prod_{E \in \Ed} \phi_{E}(E)$
%     of factors $\boldsymbol   \phi = 
%     \{ \phi_E : \V E \to \mathbb R_{\ge 0} \}_{E \in \Ed}$
%     over a hypergraph $(\X, \Ed)$ closely related to the structure of $\cal M$.
%     For this reason, some authors use the term ``graphical model'' to refer to a tuple $(\X ,\Ed, \boldsymbol\phi)$,
%     i.e., a factor graph.
%     PDGs, however, do not represent probabilities this way.}
Inference for $\cal M$ is then the ability to calculate conditional probabilities
 $\Pr_{\!\cal M}(Y|X{=}x)$,
where $X,Y \subset \X$ and $x \in \V\! X$. 

There are several different approaches to inference in graphical models.
% and factor graphs (henceforth, \emph{standard graphical models}).  
%
Many of them (such as belief propagation; see \cref{chap:LIR}),
when applied to tree-like graphical models,
run in linear time and are provably correct.
If the same algorithms are na{\"i}vely applied to graphs with cycles (as in loopy belief propagation),
then they may not converge, and even if they do,
may give incorrect (or even inconsistent) answers
\parencite{wainwright2008graphical}.
Nearly all \emph{exact} inference algorithms
(including variable elimination  \parencite{bertele1972nonserial},
 message-passing with \parencite{lauritzen1988local}
    and without division \parencite{shafer1990probability},
    among others \parencite{wainwright2003tree})
effectively construct a tree decomposition, and can be
viewed as running on a tree \parencite[\S9-11]{KF09}.
Indeed,
under widely believed assumptions,
every class of graphical models
for which (exact) inference is \emph{not} NP-hard
has bounded treewidth
\parencite{chandrasekaran2012complexity}.

Given a tree decomposition $(\C, \mathcal T)$ of the 
underlying model structure,
many of these algorithms
use a 
standard
data structure
that we will call a \emph{\actree},
which
is a collection
$\bmu = \{\mu_C(C)\}_{ C \in \C}$ 
of probabilities over the clusters \parencite[\S10]{KF09}.
A \actree\
$\bmu$ 
is said to be \emph{calibrated} if neighboring clusters' distributions agree on the variables 
they share.
In this case, 
$\bmu$ determines a joint distribution 
\begin{equation}
    \Pr\nolimits_{\bmu}
    (\X)
        = \quad 
        {\prod_{\mathclap{C \in \C}} \mu_C(C)~\,}\Big/
        {~~\prod_{\mathclap{(C{-}D) \mathrlap{\in \cal T}}} \mu_{C}(C \cap D)\,,}
    \label{eq:cliquedist}
\end{equation}
which has the property that $\Pr_{\bmu}(C) = \mu_C$ for 
all
$C \in \C$.
A \cactree\ summarizes the answers to
many queries about $\Pr_{\bmu}$
\parencite[see][\S 10.3.3]{KF09}.
    \unskip\footnote{To see why
    in a simple case, note that 
    for an unconditional query about $Y$ contained within a single cluster $C$, we have
    $\Pr_{\bmu}(Y) = \mu_C(Y)$.
    With some care, the general idea can be extended to arbitrary queries 
        \parencite[see][\S 10.3.3]{KF09};
        those conditional on evidence $X{=}x$ can be handled
        by conditioning the clusters that contain $X$,
        and then recalibrating $\bmu$ with 
        a standard algorithm like belief propagation.
    }
Therefore, to answer probabilistic queries with respect to a distribution $\mu$, it suffices to find a \cactree\ $\bmu$ that represents $\mu$, and appeal to standard algorithms.

For the reader's convenience, we now repeat a (more compact) version of the definition of a PDG.
% \begin{defn*}
    A PDG $\dg M \!=\! (\X\mskip-2mu, \Ar,
        \mathbb P, 
        \balpha, \bbeta )
    $
    is a directed hypergraph $(\X\mskip-2mu, \Ar)$ 
    whose nodes are variables, together with probabilities $\mathbb P$
    and confidence vectors
    $\balpha \!=\! [\alpha_a]_{a \in \Ar}$ 
    and $\bbeta \!=\! [\beta_a]_{a \in \Ar}$,
    so that each $\ed aST \! \in\! \Ar$ is associated with:
    
    \begin{itemize}[nosep,itemsep=2pt]
    \item
    a conditional probability distribution {\subafalse $\p_a(\Tgt a | \Src a)$}
    on the target variables given values of the source variables,
    \item a weight $\beta_a \in \smash{\Rext}$ 
    indicating the modeler's confidence in the cpd {\subafalse $\p_a(\Tgt a | \Src a)$},
    % \discard{(as measured by the number of independent observations that support $\p_a$), }
    and
    \item 
    a weight $\smash{\alpha_a \in \mathbb R}$ indicating
    the modeler's confidence in the functional dependence of 
    {\subafalse$\Tgt a\mskip-2mu$ on $\Src a\mskip-2mu$}
    expressed by $a$.
    % \discard{
    % (as measured by the expected number of independent causal mechanisms corresponding to $a$,
    % that determine $\Tgt a$ given $\Src a$).%
    % }
    \end{itemize}
% \expandafter\discard\voli{In aggregate, $\balpha = [\alpha_a]_{a \in \Ar} \in \Rext^\Ar$ and $\bbeta = [\beta_a]_{a \in \Ar} \in \Rext^\Ar$ are the vector forms of the weights, and
%     $\mathcal P$ is the set of cpds indexed by $\Ar$.}
If $\bbeta \ge \mat 0$ and $\alpha_a\! > 0$ implies $\beta_a\! > 0$, we
write $\bbeta \gg \balpha$ and
call $\dg M$ \emph{proper}.
Note that  $\bbeta \gg \balpha$ if $\bbeta > \mat 0$.
% \end{defn*}
% \temphide{%
% One significant advantage of PDGs is their modularity:
% we can combine the information in $\dg M_1$ and $\dg M_2$ 
% by taking the union of their variables and the disjoint union of their arcs (and associated data) to get a new PDG, denoted $\dg M_1 + \dg M_2$.
% }%
% \expandafter\discard\voli{%
%     Like other graphical models,
%     PDGs encode two types of information: ``structural'' information 
%     through the graphical structure $\Ar$ and weights $\balpha$,
%     as well as ``observational'' information, 
%     through the conditional probability distributions
%     $\mathcal P$ and weights $\bbeta$. 
%     Corresponding to these two types of information, 
%     PDG semantics are based on two scoring functions 
%     which quantify the discrepancy between 
%     a joint distribution $\mu(\X)$ over all variables,
%     and each of the two types of information.
% }%
% \expandafter\discard\vjoe{%
%     As we mentioned in the introduction,
%     PDGs encode two types of information: ``structural'' information 
%     through the graphical structure $\Ar$, and
%     ``observational'' information, 
%     through the conditional probability distributions.
%     The weight vectors $\alpha$ and $\beta$ encode our confidence in these
%     two types of information.
%     The semantics of PDGs are based on two scoring functions
%     that quantify the discrepancy between 
%     a joint distribution $\mu$ over (the possible values of) the variables
%     in $\X$, and each of the two types of information. }%
% %
Recall that  PDG contains two types of information:
``structural'' information, in the hypergraph $\Ar$ and
weights $\balpha$, and ``observational'' data,
in the cpds  $\mathbb P$ and weights $\bbeta$.
PDG semantics are based on two scoring functions 
that quantify discrepancy between 
each type of information and a distribution
$\mu \in \Delta \V \!\X$ over its variables.
(See \cref{sec:scoring-semantics} for details.)
Given a value of $\gamma > 0$, a trade-off parameter that controls the strength of the structural information, 
recall that the overall scoring function is given by
\begin{align*}
    \bbr{\dg M}_\gamma&(\mu) 
        := \OInc_{\dg M}(\mu) + \gamma \, \SDef_{\dg M}(\mu)
            % \numberthis\label{eqn:scoring-fn}
            \tag{\ref{eqn:scoring-fn}}
            \\[-0.2ex]
        &= \Ex\nolimits_{\mu}\bigg[
            \,
            \sum_{\ed aST \mathrlap{\, \in \Ar}} \subafalse
            \log \frac
            {\mu(\Tgt a| \Src a)^{\beta_a - \gamma \alpha_a}}
            {\p_a(\Tgt a | \Src a)^{\beta_a}}
        \bigg] - \gamma \H(\mu)
        .
\end{align*}
Recall that $\bbr{\dg M}^*_\gamma = \argmin_\mu \bbr{\dg M}_\gamma(\mu)$ denote
the set of optimal distributions at a particular value $\gamma$.
One natural conception of inference in PDGs is then parameterized by
$\zogamma$:
to do $\zogamma$-inference
in $\dg M$ is to respond to probabilistic queries in a way that is sound with respect to every $\mu \in \bbr{\dg M}^*_\gamma$.
It is not too difficult to see that when $\bbeta \ge \gamma\balpha$, 
 \eqref{eqn:scoring-fn} is strictly convex, which ensures that
 $\bbr{\dg M}^*_\gamma$ is a singleton.
This chapter demonstrates that
$\zogamma$-inference
is tractable 
% for such PDGs.
under this condition.

The limiting behavior of the $\zogamma$-semantics as $\zogamma \to 0$,
which we denote $\bbr{\dg M}^*_{0^+}$ and call the \emph{$0^+$\!-semantics},
has some special properties (e.g., \cref{theorem:limit-uniq}).
% If $\dg M$ is proper, then        
% $\bbr{\dg M}^*_{0^+}$ contains precisely one distribution.
This distribution intuitively
reflects an extreme empirical
view: observational data trumps causal structure.
% Note that in the absence of a causal picture
% ($\balpha = \mat0$), this
% corresponds to the well-established 
% practice of selecting
% the maximum entropy distribution consistent with some observational constraints \parencite{jaynes1957information}.
One should be careful to distinguish 
$\bbr{\dg M}^*_{0^+}$
from $\bbr{\dg M}^*_0$,
the set of distributions that minimize
$\OInc_{\dg M}$; the latter  set
includes
 $\bbr{\dg M}^*_{0^+}$
% \parencite[Prop 3.4]{pdg-aaai},
(\cref{prop:consist})
but may also contain other distributions.
This chapter also shows how to efficiently answer queries with respect 
to the unique distribution in $\bbr{\dg M}^*_{0^+}$, which we call
\emph{$0^+$\!-inference}.

% Given a PDG $\dg M$, the smallest possible value of its scoring function,
% $
%     \aar{\dg M}_\gamma := \inf_{\mu}\, \bbr{\dg M}_\gamma(\mu),
% $
% is known as its $\gamma$-inconsistency
% and is interesting in its own right:
% $\aar{\,\cdot\,}_\gamma$ 
% is arguably a ``universal'' loss
% function \parencite{one-true-loss}.



\textbf{Interior-Point Methods and Convex Optimization.}
Interior-point methods provide an iterative way of approximately solving linear programs in polynomial time \parencite{karmarkar1984new}.
With the theory of ``symmetric cones'', these methods were extended in the 1990s to handle second-order cone programs (SOCPs) and semidefinite programs (SDPs), which allow more expressive constraints.
But the constraints that these methods can handle are insufficient for
our purposes. We need what have been called \emph{exponential cone constraints}.
The \emph{exponential cone} is the convex set
\begin{align*}
        \begin{aligned}
        K_{\mskip-1mu\exp} :=
        \big\{ (x_1, x_2, x_3) &:
                x_1 \ge x_2 e^{x_3 / x_2}\!,\, x_2 > 0 \big\}
            \\[-0.6ex]\quad \mathbin{\cup}\,
        \big\{ (x_1, 0, x_3&) : x_1 \ge 0,\, x_3 \le 0 \big\}
        \qquad \subset \mathbb \Rext^3.
    \end{aligned}
\end{align*}
It is also sometimes called the ``relative entropy cone'', for reasons we will see in \cref{sec:minimize-inc}.
% \discard{\voli{It is also sometimes called the ``relative entropy'' cone, because if $\mat m, \mat p \in \Delta^{n-1} \subset \mathbb R^n$ are points on a probability simplex, then $(-\mat u, \mat m, \mat p) \in K_{\exp}^n$ if and only if $\mat u$ is an upper bound on $\mat m \log (\nicefrac{\mat m}{\mat p})$, the pointwise contribution to relative entropy at each outcome.}}
Suppose $K  =  K_{\exp}^p  \times [0, \infty]^q 
\subset \smash\Rext^n$ is a product of $p$ exponential cones and $q = n - 3k$ non-negative orthants.
An \emph{exponential conic program} is then an optimization problem of the form
\begin{equation}
    \minimize
        _{\mat x}
        ~~ \mat c^{\sf T} \mat x
    \quad\subjto
    ~~ A \mat x = \mat b,~~\mat x \in 
        K,
        \label{eq:exp-conic-program}
\end{equation}
where $\mat c \in \Rext^{n}$ is some cost vector,
the function $\mat x \mapsto \mat c^{\sf T} \mat x$ is called the \emph{objective},
and $\mat b \in \Rext^m$, $\mat A \in \Rext^{m \times n}$ encode linear constraints.
\textcite*{nesterov1996infeasible} first established that such problems can be solved in polynomial time, but incur double the memory and eight times the time, compared to the symmetric counterparts. These drawbacks were eliminated in \cite{skajaa2015homogeneous}.
The algorithm that seems to display the best empirical performance \parencite{dahl2022primal}, however, was only recently shown to
run in polynomial time \parencite{badenbroek2021algorithm}.

Disciplined Convex Programming \parencite{dcp-thesis} is a
compositional approach to convex optimization that 
imposes certain restrictions on how problems can be specified.
A problem conforming to those rules is said to be \emph{dcp},
and can be efficiently compiled to a standard form
\parencite{agrawal2018rewriting},
which in our case is an exponential conic program.
Only two rules are relevant to us: a constraint of the form
$(x,y,z) \in K_{\exp}$ is
    dcp iff $x$, $y$, and $z$ are affine transformations of the
    optimization variables, 
and a linear program
augmented
with dcp 
constraints is dcp.
Because all the optimization problems that we give are
of this form,
we can easily compile them
to exponential conic programs even if they do not exactly conform to \eqref{eq:exp-conic-program}.


\section{Inference as a Convex Program}
    \label{sec:inf-as-cvx-program}

Here is an obvious, if inefficient,
way
of calculating
$\Pr_{\!\cal M}(Y|X{=}x)$ in a
probabilistic model $\cal M$. 
First compute an explicit representation of the joint distribution 
$\Pr_{\!\cal M} \in \Delta\mskip-2mu\V\!\X$, 
then marginalize to 
$\Pr_{\!\cal M}(X,Y)$ and condition on $X{=}x$.
For a factor graph or BN,
each step is
straightforward;
the problem is the exponential time and space required to represent $\Pr_{\!\cal M}(\X)$ explicitly.
A key feature of inference algorithms for BNs and FGs is that they
do not represent joint distributions in this way.
For PDGs, though, it is not
obvious that
we can calculate the $\zogamma$-semantics,
even if
we know it is unique, and
we ignore the space required to represent it (as we do in this section).
Note that $\zogamma$-inference is already an optimization problem by definition:
\[
    \minimize_\mu\quad
        \bbr{\dg M}_\gamma(\mu)
    \quad \subjto\quad \mu \in \Delta\mskip-2mu\V\mskip-2mu\X.
\]
For small enough 
 $\gamma$,
it is even convex.
But can we solve it efficiently?
With exponential cone constraints,
the answer is yes, as we show in \Cref{sec:small-gamma}.
Moreover, we can compute the $0^+$\!-semantics with a sequence of two exponential conic programs (\Cref{sec:empirical-limit}).
To give a flavor of our constructions and ease into
the more complicated ones, we begin by 
minimizing
 $\OInc$, the simpler of the two scoring functions.



\subsection{%
    Minimizing Incompatibility
    (\texorpdfstring{$\boldsymbol\gamma\boldsymbol=\mat0$}{gamma=0})%
} \label{sec:minimize-inc}

When $\gamma = 0$, we want to find minimizers of $\OInc$,
which is a
weighted sum of conditional relative entropies.
There is a straightforward connection between the exponential cone and
relative entropy:
if $\mat m, \mat p \in
\Delta \{1, \ldots, n\}
\subset \mathbb R^n$ are points on
a probability simplex,
then $(-\mat u, \mat m, \mat p) \in K_{\exp}^n$ if and only if
$\mat u$ is an upper bound on $\mat m \log \frac{\mat m}{\mat p}$,
the pointwise contribution to relative entropy at each outcome.
Thus, perhaps unsurprisingly, we can use an exponential conic program to
find minimizers of $\OInc$.
If all beliefs are unconditional and over the same space,
the construction is standard;
we review it here, so that we can build upon it.

\textbf{Warm-up.}
\begingroup
Consider a PDG with
only one variable $X$
with
$\V\mskip-2mu X = \{1, \ldots, n\}$.
Suppose further that every arc $j \in \Ar = \{1, \ldots, k\}$
has $\Tgt j = \{ X \}$ and $\Src j = \emptyset$.
Then each $\p_j(X)$ can be identified with a vector $\mat p_j \in [0,1]^n$, and all $k$ of them can conjoined to form a matrix $\mat P = [\,p_{ij}] \in [0,1]^{n \times k}$.
Similarly, a candidate distribution $\mu$ can be identified with $\mat m \in [0,1]^n$. 
Now consider a matrix $\mat U = [u_{i,j}] \in \Rext^{n \times k}$
that, intuitively, gives an upper bound on
the contribution to $\OInc$ due to each edge and value of $X$.
Observe that
\begin{align*}
    &&(- \mat U,~
        [\mat m,\,...\,, \mat m]
        ,~ \mat P) &\in K_{\exp}^{n \times k} \\
    &\iff& \forall  i,j.~~
            u_{ij} &\ge m_i \log (\nicefrac{m_i}{p_{ij}}) \\
    &\implies& \forall j.~~
        {\textstyle\sum_i} u_{ij}  &\ge \kldiv{\mu}{p_j} \\
    &\implies& {\textstyle\sum_{i,j}} \beta_j u_{ij}  &\ge {\textstyle\sum_j} \beta_j \kldiv{\mu}{p_j} \\
    &\iff& \mat 1^{\sf T} \mat U \bbeta &\ge \OInc(\mu) .
        \numberthis\label{eqn:warmup-logic}
\end{align*}

So now, if $(\mat U, \mat m)$ is a solution to the convex program
\begin{align*}
    \minimize_{\mat m, \mat U}~~
        \mat 1^{\sf T} \mat U \bbeta
    \quad\subjto\quad &
        \mat 1^{\sf T} \mat m  = 1, \\[-2ex]
        (-\mat U,\;&
            [\mat m,\,...\,, \mat m]
            ,\; \mat P
        )
            \in K_{\exp}^{n \times k},
\end{align*}
then (a) 
the
objective value $\mat 1^{\sf T} \mat U \bbeta$
equals
the inconsistency $\aar{\dg M}_0$, and (b) $\mu \in \bbr{\dg M}^*_0$,
meaning $\mu$ minimizes $\OInc_{\dg M}$.

\endgroup

\textbf{The General Case.}
We now show how the same construction can be used to find
 a distribution $\mu \in \bbr{\dg M}^*_0$
for an arbitrary PDG $\dg M = (\X, \Ar, \mathcal P, \balpha, \bbeta)$.
To further simplify the presentation,
for each arc $a \in \Ar$, let
$\V a := \V(\Src a, \Tgt a)$
denote all joint settings of $a$'s source and target variables, and
write
$
\V\!\Ar :%
    = \sqcup_{a \in A} \V a
    = \{ (a, s, t) : a \in \Ar,\, (s,t) \in \V(\Src a,\Tgt a) \}
$
for the set of all choices of an arc together with values of its source and target.
For each $a \in \Ar$, 
we can regard $\mu(\Tgt a, \Src a)$ and $\mu(\Src a)\p_a(\Tgt a | \Src a)$, both distributions over $\{\Src a,\Tgt a\}$, 
as vectors of shape $\V a$.
As before, we introduce an optimization variable $\mat u$ that packages together
    all of the relevant pointwise upper bounds.
To that end, consider a vector
$\mat u = [u_{a,s,t}] \in \Rext^{\V\!\Ar}$
in the optimization problem
{\begin{align*}
    \minimize_{\mu, \mat u} &\quad
        \sum_{\mathrlap{(a,s,t) \in \V\!\Ar}} \beta_a \, u_{a,s,t}
    \numberthis\label{prob:joint-inc}\\
    \subjto&\quad \mu \in \Delta\V\!\X, \\[-0.4ex]
        \forall a \in \Ar.~&\big(-{\mat u}_a,\, \mu( \Tgt a,\Src a),\, \p_a(\Tgt a | \Src a)  \mu(\Src a) \big) \in K_{\exp}^{\V a}
        ,
\end{align*}}%
where $\mat u_a = [u_{a,s,t}]_{(s,t) \in \V a}$ consists of those
components of $\mat u$ associated with arc $a$.
Note that
the marginals
 $\mu(\Src a, \Tgt a)$ and $\mu(\Src a)$ 
are affine transformations of $\mu$, so \eqref{prob:joint-inc} is dcp.
A straightforward generalization of the logic in \eqref{eqn:warmup-logic} gives us:

\begin{linked}{prop}{joint-inc-correct}
    If $(\mu, \mat u)$ is a solution to \eqref{prob:joint-inc}, then
    $\mu \in \bbr{\dg M}_0^*$,
    and
    $%
        \sum_{(a,s,t) \in \V\!\Ar} \beta_a u_{a,s,t} = \aar{\dg M}_0$.
\end{linked}

Thus, a solution to \eqref{prob:joint-inc}
encodes a distribution that minimizes $\OInc$, and
the (0-)inconsistency
of $\dg M$.
This is a start, but to do 
$0^+$\!-inference,
among the minimizers of $\OInc$
we must find the unique distribution in $\bbr{\dg M}^*_{0^+}$, 
while for $\zogamma$-inference ($\zogamma > 0$), we need to find the optimizers of
$\bbr{\dg M}^*_\gamma$.
Either way, we must consider 
$\SDef$
in addition to $\OInc$. 

\subsection{%
    \texorpdfstring{$\boldsymbol\gamma$}%
    {gamma}-Inference
    for small
    \texorpdfstring{$%
    \boldsymbol\gamma%
    \boldsymbol>\mat0$}{gamma}%
} \label{sec:small-gamma}

When $\gamma > 0$ is small enough,
the scoring function \eqref{eqn:scoring-fn} is not only convex,
but admits a straightforward representation as an exponential conic program.
To see this, note that \eqref{eqn:scoring-fn} can be rewritten
% \parencite[Prop 4.6]{pdg-aaai}
\cref{prop:nice-score}
as:
\begin{equation}
    \begin{aligned}
        \bbr{\dg M}_\gamma(\mu) = &-\gamma\H(\mu) -
            \sum_{a \in \Ar}
                \beta_a\, \Ex_\mu
                    \log {\p_a(\Tgt a | \Src a)}
                \\[-0.6ex]
            &~~+ \sum_{a \in \Ar}
            (\gamma \alpha_a - \beta_a)
                \H_\mu (\Tgt a | \Src a).
    \end{aligned}
    \label{eq:altscore}
\end{equation}
The first term,
$-\gamma\H(\mu)$,
is strictly convex and has a well-known
translation into an exponential cone constraint;
the second one linear in $\mu$.
If $0 < \gamma \le \min_{a} \frac{\beta_a}{\alpha_a}$, then
every summand of the last term is a negative conditional entropy, and 
can be captured by an exponential cone constraint.
The only wrinkle is that it is possible for a user to specify that some $\p_a(t\mid s) = 0$, in which case the linear term 
is undefined.
The result is a requirement that $\mu(s,t) = 0$ at such points,
which we can instead encode directly with linear constraints.
To do this formally,
divide $\V\!\Ar$ into two parts:
$\V\!\Ar^+ := \{ (a,s,t) \in\V\!\Ar : \p_a(t |s) > 0\}$ and
$\V\!\Ar^0 := \{ (a,s,t) \in\V\!\Ar : \p_a(t |s) = 0\}$.
Armed with this notation, consider upper bound vectors
$\mat u = [ u_{a,s,t}]_{(a,s,t) \in \V\!\Ar}$ and $\mat v = [v_w]_{w \in \V\!\X}$,
in the following optimization problem:
{%
\begin{align*}
\minimize_{\mu, \mat u, \mat v} & ~~
    \sum_{\mathrlap{\!\!\!(a,s,t) \in \V\!\Ar}}
        (\beta_a \!- \alpha_a \gamma) u_{a,s,t}
        \,+
        \gamma
        \sum_{\mathclap{w \in \V\!\X}} v_w
    \numberthis\label{prob:joint-small-gamma}
    \\[-0.2ex]
    &\qquad
    - \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}} 
        \alpha_a \gamma \, 
        \mu(\Src a{=}s,\Tgt a {=} t) \log \p_a (t|s)
\\[0.2ex]
\subjto&\quad \mu \in \Delta\V\!\X, 
        \quad ( -\mat v,  \mu,  \mat 1) \in K_{\exp}^{\V\!\X},
    \\[-0.4ex]
    \forall a \in \Ar.~
        &\big(-\mat u_a, \mu( \Tgt a,\Src a),\p_a(\Tgt a | \Src a)  \mu(\Src a) \big)
            \in K_{\exp}^{\V a}, \\[-0.1ex]
    \forall (a,s,t) &\in \V\!\Ar^0\!.~
    \mu(\Src a{=}\mskip2mus, \Tgt a{=}\mskip2mut) = 0.
\end{align*}}

This optimization problem may look complex, but it 
falls out of
\eqref{eq:altscore} 
fairly
directly,
and gives us what we wanted.

\begin{linked}{prop}{joint-small-gamma-correct}
    If $(\mu, \mat u, \mat v)$ is a solution to \eqref{prob:joint-small-gamma},
    and $\bbeta \ge \gamma \balpha$,
    then
    $\mu$ is the unique element of
    $\bbr{\dg M}^*_\gamma$, and $\aar{\dg M}_\gamma$
    equals the objective of \eqref{prob:joint-small-gamma} evaluated at $(\mu, \mat u, \mat v)$.
\end{linked}

\subsection{
    Calculating the \texorpdfstring{$\mat 0^{\boldsymbol+}$\!}{0+}-semantics
    (\texorpdfstring{$\boldsymbol\gamma\boldsymbol\to\mat 0$}{gamma->0})}
    \label{sec:empirical-limit}
\cref{sec:minimize-inc} shows how to find a distribution $\nu$ that minimizes
$\OInc$%
---but to do
$0^+$\!-inference,
we need to find the minimizer
that, uniquely among them, best minimizes
$\SDef$.
It turns out this can be done by
    using $\nu$ to construct a second optimization problem.
The justification requires two more results;
we start by characterizing the minimizers of $\OInc$.


\begin{linked}{prop}{marginonly}
    If $\dg M$ has arcs $\Ar$ and $\bbeta \ge 0$,
    the minimizers of $\OInc_{\dg M}$ all have the same conditional
        marginals along $\Ar$.
    That is, for all $\mu_1, \mu_2 \in \bbr{\dg M}_0^*$
    and all $\ed aST \in \Ar$ 
    with $\beta_a > 0$, we have
    {\subafalse
    $\mu_1(\Tgt a, \Src a)\mu_2(\Src a) = \mu_2(\Tgt a, \Src a) \mu_1(\Src a)$.%
    \onlyfirsttime{\footnotemark}
    }
\end{linked}
\footnotetext{Intuitively, this asserts 
$\mu_1(\Tgt a | \Src a) = \mu_2(\Tgt a | \Src a)$,
but also handles cases where some
$\mu_1(\Src a {=} s)$ or $\mu_2(\Src a {=} s)$ 
equals zero.}

As a result, once we find one minimizer $\nu$ of $\OInc_{\dg M}$
(e.g., via \eqref{prob:joint-inc}),
it suffices to optimize $\SDef$ among distributions that have the same
conditional marginals along $\Ar$ that $\nu$ does.
This presents another problem: $\SDef$
is typically not convex.
Fortunately, if we constrain to distributions that minimize $\OInc$, then it is.
Moreover, on this restricted domain, it can be represented 
with dcp exponential cone constraints.

\begin{linked}{prop}{idef-frozen}
If $\mu \in \bbr{\dg M}_0^*$\,,
then
\begin{equation}
    \SDef_{\dg M}(\mu) =
        \sum_{\mathclap{ \omega \in \V\!\X } }
            \mu(\omega )
            \log \bigg(
                \faktor{\mu(\omega)\,}{\,\prod_{\mathclap{a \in \Ar}} 
                \nu\big(\Tgt a ( \omega ) \big|  \Src a (\omega)\big)^
                {\!\alpha\ssub a}
                }
            \bigg)\mskip-2mu
        ,\!
        \label{eq:idef-alt-constr}
\end{equation}
where $\{ \nu(\Tgt a | \Src a ) \}_{a \in \Ar}$ are the
cpds along the arcs $\Ar$
shared by all distributions in $\bbr{\dg M}^*_0$\
(per \cref{prop:marginonly}),
and $\Src a ( \omega ), \Tgt a ( \omega )$ are the respective values of variables $\Src a$ and $\Tgt a$ in the joint setting $\omega \in \V\!\X$.
\end{linked}

If we already know a distribution $\nu \in \bbr{\dg M}_0^*$,
perhaps by solving \eqref{prob:joint-inc}, then
the denominator of \eqref{eq:idef-alt-constr} does not depend on $\mu$ 
and so is constant in our search for minimizers of
$\SDef_{}$.
For ease of exposition, aggregate these values into a vector
\begin{equation}
    \mat k :=
        \Big[
        ~\prod_{\smash{a \in \Ar}} \nu(\Tgt a (w) | \Src a (w))^{\alpha\ssub a}
        \Big]%
        _{w \in \V\!\X}~\raisebox{-1ex}.
        \label{eq:cm-product}
\end{equation}
We can now capture $\bbr{\dg M}^*_{0^+}$ with a convex program.

\begin{linked}{prop}{joint+idef-correct}
If $\nu \in \bbr{\dg M}_0^*$
and $(\mu, \mat u)$ 
solves the problem
\begin{align*}
    \minimize_{\mu, \mat u} & \quad
        \smash{\mat 1^{\sf T} \mat u}
        \numberthis\label{prob:joint+idef}\\[-0.5ex]
    \subjto &\quad
        (-\mat u,  \mu, \mat k ) \in K_{\exp}^{\V\!\X},~~\quad \mu \in \Delta\V\!\X, \\[-0.4ex]
            \forall& \ed aST \subafalse \in \Ar.~~\mu(\Src a, \Tgt a)\, \nu(\Src a) = \mu(\Src a)\, \nu(\Src a, \Tgt a),
\end{align*}
then $\bbr{\dg M}^*_{0^+} = \{ \mu \}$
and $\mat 1^{\sf T} \mat u = \SDef_{\dg M}(\mu)$.
\end{linked}
Running \eqref{prob:joint+idef} through a convex solver gives rise to the 
first algorithm
that can reliably find $\bbr{\dg M}^*_{0^+}$.




\section{Polynomial-Time Inference Under Bounded Treewidth}
    \label{sec:clique-tree-expcone}
We have now seen how $\zogamma$-inference
(for small $\zogamma$) can be reduced to convex optimization
over joint distributions $\mu$---%
but $\mu$ grows exponentially with the number of variables in the PDG,
so we do not yet have a tractable inference algorithm.
We now show how $\mu$ can be replaced with a \actree\ over the PDG's structure. 
What makes this possible is a key independence property of traditional graphical models,
which we now prove
holds for PDGs as well.



\begin{linked}[Markov Property for PDGs]{theorem}{markov-property}
  If\, $\dg M_1$ and $\dg M_2$ are PDGs
    over sets $\X_1$ and $\X_2$ of variables, respectively,
    then for all $\gamma > 0$ and $\gamma=0^+$,
% \discard{
%     Then for all $\gamma > 0$, we have that
    \[  \bbr{\dg M_1 \bundle \dg M_2}^*_\gamma
			~\models~
		\X_1 \CI \X_2 \mid \X_1 \cap \X_2. 
    \] 
    That is: for every distribution $\mu \in \bbr{\dg M_1 \bundle \dg M_2}^*_\gamma$,
    the variables of $\dg M_1$ and of $\dg M_2$ are conditionally independent given the variables they have in common.
% }
% then $\X_1$ and $\X_2$ are conditionally independent given $\X_1 \cap \X_2$ in every
%  $\mu \in \bbr{\dg M_1 \bundle \dg M_2}^*_\gamma$\,,
% for all $\gamma > 0$ and $\gamma=0^+$.
\end{linked}

For the remainder of this section, fix a PDG $\dg M$ and a tree decomposition $(\C, \mathcal T)$ of $\dg M$'s hypergraph.
One significant consequence of \cref{theorem:markov-property} is that, in the
search for optimizers of \eqref{eqn:scoring-fn}, we
need consider only distributions that satisfy those independencies,
all of which can be represented as a \actree\ 
$\bmu = \{\mu_C \in \Delta\V(C) \}_{C \in \C}$
over $(\C, \mathcal T)$.

\begin{linked}{coro}{can-use-cliquetree}
    If $\dg M$ is a PDG with arcs $\Ar$, 
    $(\C, \mathcal T)$ is a tree decomposition of $\Ar$,
    $\gamma > 0$, and
    $\mu \in \bbr{\dg M}^*_\gamma$, then there exists a \actree\ 
    $\bmu$ over $(\C, \mathcal T)$ such that $\Pr_{\bmu} = \mu$.
\end{linked}

For convenience, let
$\V\C := \{(C,c) : C \in \C, c \in \V(C)\}$ 
be
the set of all choices of a cluster together with a setting of its variables. 
Like before, we start by optimizing $\OInc$, this time
over \cactree s $\bmu$,
which we identify with vectors
$
 \bmu
    \cong [\mu_C(C{=}c)]_{(C,c)\in\V\C} 
$.
We need the conditional marginals $\Pr_{\bmu}(\Tgt a | \Src a)$ of $\bmu$ along every arc $a$ in order
to calculate $\OInc_{\dg M}(\Pr_{\bmu})$; fortunately, they are readily available.
Since $(\C, \mathcal T)$ is a tree decomposition,
we know $\Src a$ and $\Tgt a$ lie entirely within some cluster $C_{\!a} \in \C$,
and $\Pr_{\!\bmu}(\Tgt a | \Src a) = \mu_{C_{\!a}}\!(\Tgt a | \Src a)$ if $\bmu$ is calibrated.
For $\mat u \in \Rext^{\V\!\Ar}$, consider the problem
\begin{align*}
    \minimize_{\bmu, \mat u} &\quad
        \sum_{\mathrlap{(a,s,t) \in \V\!\Ar}}\beta_a \,  u_{a,s,t}
    \numberthis\label{prob:cluster-inc}\\
    \subjto&\quad
        \forall C \in \C.~\mu_C \in \Delta\V(C), \\[-0.3ex]
        \forall a \in \Ar.~
            \big(&\!- \! \mat u_a,\, \mu_{C\!_a}\!(\Src a,\mskip-2mu \Tgt a),\, \mu_{C\!_a}\!(\Src a) \p_a(\Tgt a | \Src a)\big) \in K_{\exp}^{\V a} \\[-0.2ex]
        \forall (C,D) &\in \mathcal T.~~ \mu_{C}(C \cap D) = \mu_{D}(C \cap D),
\end{align*}
where again $\mat u_a$ is the restriction of $\mat u$ to components associated with $a$.
Problem \eqref{prob:cluster-inc} is similar to \eqref{prob:joint-inc}, except
that it requires local marginal constraints to restrict our search to \cactree s.
It is analogous to problem 
\textsc{CTree-Optimize-KL}
of \textcite[pg. 384]{KF09}.

\begin{linked}{prop}{cluster-inc-correct}
    If $(\bmu, \mat u)$ is a solution to \eqref{prob:cluster-inc}, then
    \begin{enumerate}[label={(\alph*)},nosep]
    \item $\bmu$ is a calibrated, with $\Pr_{\bmu} \in \bbr{\dg M}^*_0$, and
    \item the objective of \eqref{prob:cluster-inc} evaluated at $\mat u$ equals $\aar{\dg M}_0$.
    \end{enumerate}
\end{linked}
We can now find a minimizer of $\OInc$ and
compute $\aar{\dg M}_0$ without storing a joint distribution.
But to do anything else, we must deviate from the template laid out in \cref{sec:inf-as-cvx-program}.

\textbf{Dealing with Joint Entropy.}
In the construction of \eqref{prob:cluster-inc},
we rely heavily on the fact that each term of $\OInc_{\dg M}$
depends only on local marginal distributions $\mu_{C_{\mskip-2mu a}}\!(\Tgt a,  \Src a)$
and $\mu_{C_{\mskip-2mu a}}\!(\Src a)$.
The same is not true of $\SDef_{}$, which depends on the joint entropy $\H(\Pr_{\bmu})$ of the entire distribution.
At this point we should point out an important 
reason to restrict our focus to trees:
it allows the joint entropy to be expressed
in terms of the cluster marginals \parencite{wainwright2008graphical},
by
\begin{equation}\label{eq:bethe-entropy}
    -\H(\Pr\nolimits_{\bmu})
        = -\sum_{C \in \C} \H(\mu_C)
        ~+~ \sum_{\mathclap{(C,D) \in \mathcal T}} \H_{\bmu}(C \cap D).
\end{equation}
Even so,
it is not obvious that
\eqref{eq:bethe-entropy} can be
captured with dcp exponential cone constraints.
(Exponential conic programs can minimize negative entropy,
but not positive entropy, which is concave.)
We now describe how this can be done.

\def\Par#1{\mathrm{Par}(#1)}
\def\Pash{\mathit{V\mskip-5muC\mskip-3.5muP\!}}

Choose a root node $C_0$ of the tree decomposition, and orient each edge of $\mathcal T$ so that it points away from $C_0$.
Each cluster $C \in \cal C$, except for $C_0$, then has a parent cluster $\Par C$;
define $\Par{C_0} := \emptyset$ to be an empty cluster, since $C_0$ has no parent.
Finally, for each $C \in \C$, let $\Pash_C := C \mathbin{\cap} \Par C$ denote the
the set of $\mathbf v$ariables that cluster $C$ has in $\mathbf c$ommon with its $\mathbf p$arent cluster.
\unskip\footnotemark 
As $\cal T$ is now a directed tree, this definition allow us to express
\eqref{eq:bethe-entropy} in a more useful form:
\begin{align*}
    - \H(&\Pr\nolimits_{\bmu}) =
        - \H(\mu_{C_0}) - \!
        \sum_{(C \to D)\mathrlap{ \in \mathcal T}}
        \H_{\Pr_{\bmu}}(D \mid C)\\[-1ex]
    &= 
        \sum_{C \in \cal C} \sum_{c \in \V(C)}
        \mu_C(C{=}c)
        \log \frac
            { \mu_C(C{=}c)}
            { \mu_C(\Pash_C(c)) }
        ,
            \numberthis\label{eq:cluster-ent-decomp}
\end{align*}
where $\Pash_C(c)$ is the restriction of the 
joint value $c \in \V(C)$
to the variables $\Pash_C \subseteq C$
\unskip.
Crucially, the denominator of \eqref{eq:cluster-ent-decomp} is an affine transformation of $\mu_C$.
The upshot: we have rewritten the joint entropy
as a sum of functions of the clusters, each of which can be captured with a dcp exponential cone constraint.
This gives us analogues of the problems
in \cref{sec:small-gamma,%
sec:empirical-limit} that 
operate on \actree s.

\textbf{Finding \actree s for $\zogamma$-inference.}
The ability to decompose the joint entropy as in \eqref{eq:cluster-ent-decomp} allows us to adapt 
\eqref{prob:joint-small-gamma} 
to operate on \cactree s, rather than joint distributions. 
Beyond the changes already present in \eqref{prob:cluster-inc},
the key
is to replace 
the exponential cone constraint
$( -\mat v,  \mu,  \mat 1) \in K_{\exp}^{\V\!\X}$,
which captures the entropy
of $\mu$,
with
\[
\big(-\mat v,\;\bmu,\, [\,\mu_{C}(\Pash_C(c))\,]_{(C,c)\in\V\C}\big) \in K_{\exp}^{\V\C},
\]
which captures the entropy of $\bmu$, by
\eqref{eq:cluster-ent-decomp}.
\ifvfull %
Over vectors
$\mat v, \bmu \in \Rext^{\V\C}$ and
$\mat u \in \Rext^{\V\!\Ar}$,
the problem becomes: 
{\allowdisplaybreaks
\begin{align*}
    \minimize_{\bmu, \mat u, \mat v} & ~~
    \sum_{\mathrlap{\!\!\!(a,s,t) \in \V\!\Ar}} (\beta_a \!- \alpha_a \gamma) u_{a,s,t}
    + \gamma \sum_{\mathclap{(C,c) \in \V\C}}  v_{C,c}
    \numberthis\label{prob:cluster-small-gamma}
    \\[-0.2ex]
    - \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}}&
        \alpha_a\gamma\,
        \mu_{C\!_a}\!(\Src a{=}s,\Tgt a {=} t)
        \log \p_a (\Tgt a{=}t\mid s)
\\[0.2ex]
\subjto&\quad
    \forall C \in \C.~\mu_C \in \Delta\V(C), \\[-0.2ex]
    \forall a \in \Ar.~
        \big(&\!- \! \mat u_a,\, \mu_{C\!_a}\!(\Src a,\mskip-2mu \Tgt a),\, \mu_{C\!_a}\!(\Src a) \p_a(\Tgt a | \Src a)\big) \in K_{\exp}^{\V a}, \\
    \forall (a,s,t) &\in \V\!\Ar^0\!.~
    \mu_{C\!_a}\!(\Src a{=}\mskip2mus, \Tgt a{=}\mskip2mut) = 0, \\[-0.2ex]
    \forall (C,D) &\in \mathcal T.~~ \mu_{C}(C \cap D) = \mu_{D}(C \cap D),\\[-0.3ex]
    \big(-\mat v,\;&\bmu,\, [\,\mu_{C}(\Pash_C(c))\,]_{(C,c)\in\V\C}\big) \in K_{\exp}^{\V\C}
    .\\[-5ex]
\end{align*}%
}%
\else%
This gives rise to an optimization problem 
over
$\mat v, \bmu \in \Rext^{\V\C}$ and
$\mat u \in \Rext^{\V\!\Ar}$,
that we call \eqref{prob:cluster-small-gamma}.
The rest of the details are less instructive, so we defer
them to \cref{appendix:prob-details} for brevity. 
\fi%

\footnotetext{
    Different choices of $C_0$ 
    yield
    different definitions of $\Pash$, 
    and ultimately optimization problems of different sizes;
    the optimal choice
    can be found with Edmund's Algorithm \parencite{chu1965shortest},
    which computes a directed analogue of the minimum spanning tree.}

\begin{linked}{prop}{cluster-small-gamma-correct}
    If $(\bmu, \mat u, \mat v)$ is a solution to \eqref{prob:cluster-small-gamma}
    and $\bbeta \ge \gamma \balpha$, then
    $\Pr_{\bmu}$ is the unique element of $\bbr{\dg M}^*_\gamma$,
    and the objective of \eqref{prob:cluster-small-gamma} at $(\bmu, \mat u, \mat v)$ equals $\aar{\dg M}_\gamma$.
\end{linked}%

A related use of \eqref{eq:cluster-ent-decomp} is
to enable an analogue of
\ifvfull%
\eqref{prob:joint+idef} that searches over \actree s (rather than joint distributions),
to find
a compact representation of $\bbr{\dg M}^*_{0^+}$.
We begin with a straightforward adaptation of
    the relevant machinery in \Cref{sec:empirical-limit}.
Suppose that $\boldsymbol\nu {=} \{\nu_C : C \in \C\}$ is a \cactree\ over the tree decomposition $(\C, \mathcal T)$ representing a distribution $\Pr_{\boldsymbol\nu} \in \bbr{\dg M}^*_0$, say obtained by solving \eqref{prob:cluster-inc}.
For $C \in \C$, let $\Ar_C:= \{ a \in \Ar : C_a = C\}$ be the set of
arcs assigned to cluster $C$, and let
\[
    \mat k := \smash{\bigg[} \prod_{\smash{\mathrlap{a \in \Ar_C}}} \nu_C (\Tgt a (c) | \Src a (c))^{\alpha_a} \smash{\bigg]\mathclose{\vphantom{\Big|}}_{(C,c) \in \V \C}} ~~\in \Rext^{\V\C}
\]
be the analogue of \eqref{eq:cm-product} for a cluster tree.
Once again, consider
$\mat u := [ u_{(C,c)} ]_{(C,c) \in \V\C}$
in the optimization problem
{\allowdisplaybreaks%
\begin{align*}
\minimize_{\bmu, \mat u} & \quad
    \mat 1^{\sf T} \mat u
    \numberthis\label{prob:cluster+idef}\\
\subjto &\quad
    \forall C \in \C.~\mu_C \in \Delta\V(C), \\[-0.2ex]
     \big({-}\mat u,\,  \bmu,\,\, &
            \mat k \odot
            \big[\;\mu_C(\Pash_C(c))\;\big]_{(C,c) \in \V\C}
            \big) \in K_{\exp}^{\V\C}, \\[-0.2ex]
    \forall a \in \Ar.&~~\mu_{C_{\!a}}\!(\Src a, \Tgt a) \nu_{C_{\!a}}\!(\Src a) = \mu_{C_{\!a}}\!(\Src a) \nu_{C_{\!a}}\!(\Src a, \Tgt a)\\
    \forall (C,D) &\in \mathcal T.~~ \mu_{C}(C \cap D) = \mu_{D}(C \cap D).
\end{align*}}%
The biggest change is in the second constraint: 
the upper bounds $[u_{(C,c)}]_{c \in \V C}$ for cluster $C$ now account only
for the additional entropy not already modeled by 
$C$'s
ancestors.
\else %
\eqref{prob:joint+idef} for clique s,
resulting in an optimization problem that we call \eqref{prob:cluster+idef},
whose details we defer to \cref{appendix:prob-details} as well.
\fi


\begin{linked}{prop}{cluster-idef-correct}
    If $(\bmu, \mat u)$ is a solution to \eqref{prob:cluster+idef},
    then $\bmu$ is a \cactree\
    and $\bbr{\dg M}^*_{0^+} = \{ \Pr_{\!\bmu} \}$.
\end{linked}



At this point, standard algorithms can use $\bmu$
to answer probabilistic queries about $\Pr_{\!\bmu}$ in polynomial time \parencite[\S 10.3.3]{KF09}.
\unskip\footnote{%
    Concretely: marginal probabilities can essentially be read off of a calibrated a \actree,
    and evidence $X{=}x$ may be incorporated by
    setting $\mu_C(c) := 0$ for every $C{=}c$ that conflicts with $X{=}x$
    and recalibrating the \actree\ (e.g., with belief propagation). }
From \cref{prop:cluster-idef-correct,prop:cluster-small-gamma-correct}, it follows that
$\zogamma$-inference
(for small $\zogamma$, and for $0^+$)
can be reduced to a (pair of) convex optimization problem(s) with
a polynomial number of variables and constraints.
All that remains 
is to show that such a problem can be solved in polynomial time.
For this, we turn to interior-point methods.
As
\eqref{prob:cluster-small-gamma} and \eqref{prob:cluster+idef} are dcp, they
can be transformed via established methods \parencite{agrawal2018rewriting} into
a standard form
that can be solved in polynomial time by commercial solvers \parencite{mosek,ECOS}.
Threading the details of our constructions through
the analyses of \textcite{dahl2022primal}
and \textcite{nesterov1996infeasible}
results in
our main theorem.


\begin{linked}{theorem}{main}
Let $\dg M = (\X, \Ar, \mathbb P, \balpha, \bbeta)$
be a proper discrete PDG with $N = |\X|$ variables each taking at most $V$ values
and $A = |\Ar|$ arcs,
in which each component of 
$\bbeta \in 
    \mathbb R^{\Ar}$
and $\mathbb P \in
    \mathbb R^{\V\!\Ar}$
is specified in binary with
at most
$k$ bits.
Suppose that $\gamma \in \{0^+\}\cup (0,\,  \min_{a \in \Ar} \frac{ \beta_a}{\alpha_a}]$.
If $(\C, \mathcal T)$ is a tree decomposition of $(\X,\Ar)$ of width $T$
and $\bmu^* \in \mathbb R^{\V\C}$ 
is the unique \cactree\ over $(\C, \mathcal T)$ 
that represents the $\zogamma$-semantics of $\dg M$,
then
\begin{enumerate}[wide, label={\rm{(\alph*)}}]
\item 
Given $\dg M$, $\gamma$, and $\epsilon > 0$, 
we can find a \cactree\ $\epsilon$ close in $\ell_2$ norm to 
$\bmu^*$
in time
\onlyfirsttime{%
\unskip$^\text{\ref{note:<4possible}}$%
}
\begin{align*}
    O\pqty[\bigg]{&|\V\!\Ar + \V\C|^{4}
        \pqty[\Big]{ \log |\V\!\Ar + \V\C| + \log \frac1\epsilon} k^2 \log k 
    }
    \\
    &\subseteq
    \tilde O\pqty[\Big]{k^2 |\V\!\Ar + \V\C|^{4}
        \log \nf 1\epsilon 
    }
    \\
    &\subseteq
    \tilde O\pqty[\Big]{k^2 (N+A)^4\,V^{4(T+1)}
         \log \nf 1\epsilon }
.
\end{align*}
\item
The unique \actree\ closest to $\bmu^*$ 
in which every component is represented with a $k$-bit binary number,
can be calculated in time 
\unskip$^\text{\ref{note:<4possible}}$%
\[
    \tilde O\pqty[\Big]{k^2 |\V\!\Ar + \V\C|^{4}}
    \subseteq
    \tilde O\pqty[\Big]{k^2 (N\!+\!A)^{4}\, V^{4(T+1
    )}}.
\]
\end{enumerate}
\end{linked}

Observe that the dependence on the precision is $\log (\nf1\epsilon)$, which is optimal in the sense that, in general, it takes time $\Omega(\log \nf 1\epsilon)$ to write down the binary representation of any number within $\epsilon$ of a given value.
\unskip\footnote{
    More precisely: if a value $x$ is chosen uniformly from $[0,1]$, then
    with probability $1-\sqrt\epsilon$ the binary representation of every $y \in [x-\epsilon, x+\epsilon]$ 
    has at least $\lfloor \frac12 \log_2 \nf1\epsilon \rfloor -1$ bits.
    }
In practice, this procedure can be used as if it were an exact algorithm,
with no more overhead than that incurred by floating point arithmetic. 





% \section{APPROXIMATION, HARDNESS, AND A DEEP CONNECTION BETWEEN INCONSISTENCY AND INFERENCE}



\section{Experiments} \label{sec:expts}


\begin{figure*}
    \centering
        \includegraphics[width=0.67\linewidth]{figs/rand-joint/joint-gap-vs-time-relabeled}
        \includegraphics[width=0.32\linewidth]{figs/rand-joint/time-diff}
    \caption[Empirical results: accuracy and resource costs for the inference algorithm and baselines]{
        Accuracy and resource costs for the methods in \cref{sec:inf-as-cvx-program}.  
        Left: a scatter plot of several algorithms on random PDGs of $\approx 10$ variables. The x-axis is 
            the difference in scores
            $\bbr{\dg M}_\gamma(\mu) - \bbr{\dg M}_{\gamma}(\mu^*) + 10^{-15}$,
        where $\mu$ is the method's output,
        and $\mu^*$ achieves best (smallest) known value of $\bbr{\dg M}_{\gamma}$.
         (Thus, the best solutions lie on the far left.)
        The $y$ axis is the time required to compute $\mu$. 
        Our methods are in gold $(0^+$\!-inference) and violet ($\zogamma$-inference, for $\zogamma>0$); the baselines (black-box optimizers applied directly to \eqref{eqn:scoring-fn}) are in green.
        The area of each circle is proportional to the size of the optimization problem, as measured by
        {\small\texttt{n\_worlds}}$:=$
        $|\V\!\X|$.
        Right: how the same methods scale in run time, as $|\V\!\X|$ increases.
     }\label{fig:joint-gap-time}
\end{figure*}

We have given the first algorithm to provably do inference in polynomial
time, but that does not mean that it is the best way of answering queries in practice;
it also makes sense to use black-box optimization tools such as
    Adam \parencite{kingma2014adam} or L-BFGS \parencite{fletcher2013practical}
    to find minimizers of $\bbr{\dg M}_\gamma$.
Indeed, this scoring function has several properties
    that make it highly amenable to such methods: it is
    infinitely differentiable, $\gamma$-strongly convex, and its
    derivatives have simple closed-form expressions.
So it may seem surprising that $\bbr{\dg M}_\gamma$ poses
a challenge to standard optimization tools---%
but it does, 
even when we optimize directly over joint distributions.



\textbf{Synthetic Experiment 1 ({\normalfont over joint distributions}).~~} 
Repeatedly do the following.
First, randomly generate a small PDG $\dg M$ containing 
at most 10 variables and 15 arcs. 
Then for various values of
$\gamma \in \{0, 0^+, 
    10^{-8}, 
     \ldots, \min_a \frac{\beta_a}{\alpha_a} \}$,
optimize $\bbr{\dg M}_\gamma(\mu)$ over joint distributions $\mu$, 
in one of two ways. 
\begin{enumerate}[wide,label=(\alph*),nosep,itemsep=0.2ex]
\item Use \verb|cvxpy| \parencite{diamond2016cvxpy}
to feed  
one of problems (\ref{prob:joint-inc},\ref{prob:joint-small-gamma},\ref{prob:joint+idef})
    to the MOSEK solver \parencite{mosek}, or
\item Choose a learning rate and a representation of $\mu$ in terms of optimization variables $\theta \in \mathbb R^n$.
    Then run a standard optimizer (Adam or L-BFGS) built into \verb|pytorch| \parencite{pytorch}
    to optimize $\theta$
    until $\mu_\theta$ converges to a minimizer of $\bbr{\dg M}_\gamma$ 
        (or a time limit is reached).
    Keep only the best result across all learning rates. 
\end{enumerate}

\begin{figure*}
    \centering
    \includegraphics[width=0.34\linewidth]{figs/rand-joint/mem-costs.png}
    \includegraphics[width=0.65\linewidth]{figs/rand-clus/gap-vs-time-agg9.png}
    \caption[Comparison of convex solver and black-box optimization baselines. Memory footprints, and accuracy/time costs for the cluster setting.]
    {%
    Left: Memory footprint.
    The convex solver (violet, gold)
     requires more memory than baselines (green).
    Right: Analogue of \cref{fig:joint-gap-time} for the cluster setting.
     Here there is even more separation between exponential conic optimization
         (gold, violet) and black-box optimization (greens).
     The grey points represent belief propagation, which is fastest and most accurate---%
         but only applies in the special case when $\bbeta=\gamma\balpha$.}
    \label{fig:joint-mem}
    \label{fig:clus-gap-vs-time}
\end{figure*}


The results are shown in \cref{fig:joint-gap-time}.
Observe that the convex solver (gold, violet) is significantly more accurate than the baselines,
and also much faster for small PDGs.
Our implementation of $0^+\!$-inference (gold) also appears to scale better than L-BFGS
    in this regime, although
    that of $\zogamma$-inference (purple) seems to scale much worse. 
We suspect that the difference comes from \verb|cvxpy|'s compilation process,
    because the two use similar amounts of memory (\cref{fig:joint-mem}),
    and so are problems of similar sizes.



\textbf{Synthetic Experiment 2 ({\normalfont over \actree s}).~~} 
For PDGs of bounded treewidth, \Cref{coro:can-use-cliquetree} allows us to express these optimization problems compactly not just for the convex solver, but for the black-box baseline approaches as well.
We adapt the previous experiment for \actree s as follows.
First randomly sample a maximal graph $G$ of tree-width $k$, called a 
    $k$-tree \parencite{patil1986structure}; 
then generate a PDG $\dg M$ whose hyperarcs lie within cliques of $G$.
This ensures that the maximal cliques of $G$ form a tree-decomposition $(\C, \mathcal T)$ of $\dg M$'s underlying
    hypergraph.
We can now proceed as before: 
    either encode
    (\ref{prob:cluster-inc},\ref{prob:cluster-small-gamma},\ref{prob:cluster+idef})
    as disciplined convex programs in \verb|cvxpy|,
or use \verb|torch| to directly minimize $\bbr{\dg M}_\gamma(\Pr_{\!\bmu})$
    amongst \actree s $\bmu$ over $(\C, \mathcal T)$.
    

In the latter case, however, there is now an additional difficulty:
    it is not easy to strictly enforce the calibration constraints with the black-box methods.
Common practice is to instead add extra loss terms to ``encourage'' calibration---%
but
    it can still be worthwhile for the optimizer to simply incur that loss 
    in order to violate the constraints.
Thus, for fairness, we must recalibrate the 
    the \actree s returned by all methods before evaluation.
The result is an even more significant advantage for the convex solver; 
see \cref{fig:clus-gap-vs-time}.

\textbf{Evaluation on BNs.~~}
We also applied the procedure of the Synthetic Experiment 2
to the smaller BNs in the
\href{https://www.bnlearn.com/bnrepository/}{\texttt{bnlearn}} repository,
and found similar results (but with fewer examples; see \cref{sec:bn-expt-details}). 
But for a PDG that happens to also be a BN, it is possible to use belief propagation, which is much faster and at least as accurate.

Explicit details about all of our experiments, 
and many more figures, can be found in \cref{sec:expt-setup}.

\section{Discussion and Conclusion}

In this chapter, we have provided the first practical algorithm for
    inference in PDGs. 
In more detail, we have defined a parametric family of PDG inference notions, 
given a fixed-parameter tractable inference algorithm for a subset of these parameters,
    proven our algorithm correct, implemented it, and
    shown our code to empirically outperform baselines.
Yet many questions about PDG inference remain open.

Asymptotically, there may be a lot of room for improvement.
Our implementation runs in time $\tilde O(N^4)$, and our analysis suggests one of time $\tilde O(N^{2.872})$. 
But assuming bounded tree-width, most graph problems, including
inference inference for BNs and FGs, can be solved in time $O(N)$. 


Furthermore, we have shown how to do inference for only a subset of
possible parameter values, specifically, 
when
either $\bbeta \ge \gamma \balpha$ or $\bbeta \gg \balpha$. 
The remaining cases are also of interest, and likely require different techniques. 
When $\bbeta = 0$ and $(\Ar, \balpha)$ encodes the structure of a BN,
    for instance,
    inference is about characterizing the BN's independencies.
While we do not know how to tackle 
the inference problem in the general setting, 
our methods can be augmented with the convex-concave procedure 
    \parencite{yuille2003concave} to obtain an inference
    algorithm that applies slightly more broadly; see \cref{sec:cccp}.
We imagine that this extension could also be useful for computing with PDGs 
    beyond the specific inference problem considered in this chapter.

% \vfull{
Our analysis does not resove these problems, but it
    does shed light on some of them.  
The $0$-semantics, for instance, is 
characterized by \cref{prop:marginonly,prop:cluster-inc-correct}, 
Also, when $\bbr{\dg M}_\gamma$ is not convex, we can still find an optimal distribution with the concave-convex procedure \cite{yuille2003concave}, which we do in \cref{sec:cccp}---but this only suffices for inference if we already know there's a unique optimal distribution.
In some cases, this might actually allow us to do inference---say, if we happen to know for external reasons that $\bbr{\dg M}^*_\gamma$ is pseudo-convex (although we loose polynomial time guarantees and have no ability to automatically recognize such situations). In any case, we have implemented this, and describe it in \cref{sec:cccp}.
% }


Given the long history of improvements to our
understanding of inference for 
    Bayesian networks,
we are optimistic that 
    faster and more general
    inference algorithms
    for PDGs
    are possible.



\begin{subappendices}
\relax

\section{Proofs}

Our results fall broadly into three categories:
\begin{enumerate}
    \item Foundational results about PDGs that we needed to prove to get an
        inference procedure, but which are likely to be generally useful
        for anyone working with PDGs
            (\cref{proofs:novel-pdg-results});
    \item Correctness and efficiency results, showing that the optimization
        problems we present in the body of the chapter give the correct answers,
        and that they can be formulated and solved in polynomial time;
            (\cref{proofs:expcone-efficient-correct})
    \item Hardness results, i.e., \cref{theorem:inf-via-inc-oracle} and
    the constructions and lemmas needed to support it
        (\cref{proofs:hardness-results}).
\end{enumerate}

% \subsection{Novel Results about PDGs}
\subsection{Properties of PDG Semantics Needed for Inference}
    \label{proofs:novel-pdg-results}

\recall{prop:marginonly}
\begin{lproof}\label{proof:marginonly}
    For contradiction, suppose that $\mu_1, \mu_2 \in \bbr{\dg M}_0^*$, but
    there is some $(\hat a, \hat s, \hat t) \in \V\!\Ar$ such that $\beta_a > 0$ and
    \[
        \mu_1(\Tgt a{=}\hat t, \Src a{=}\hat s)\mu_2(\Src a{=}\hat s) \ne \mu_2(\Tgt a{=}\hat t, \Src a{=}\hat s) \mu_1(\Src a\hat s).
    \]
    For $t \in [0,1]$,
    let $\mu_t := (1-t) \mu_0 + t \, \mu_1$ as before.
    Then define
    \begin{align*}
        F(t) := \kldiv[\Big]{ \mu_t(\Src a, \Tgt a) }{  \mu_t(\Src a) \p_a(\Tgt a|\Src a) }.
    \end{align*}
    Since $\mu_0(\Src a, \Tgt a)$ and  $\mu_1(\Src a, \Tgt a)$ are joint distributions over two variables, with different conditional marginals, as above, \cref{lem:seg-strictcvx} applies, and so $F(t)$ is strictly convex.

    Let
    \[ \OInc_{\dg M \setminus \hat a}
        := \sum_{a \ne \hat a} \beta_a \kldiv{\mu(\Tgt a, \Src a)}{\p_a(\Tgt a|\Src a) \mu(\Src a)}
    \]
    be the observational incompatibility loss, but without the term corresponding to edge $\hat a$.
    Since $\OInc_{\dg M \setminus \hat a}$ is convex in its argument, it is in particular convex along the segment from $\mu_0$ to $\mu_1$; that is, for $t \in [0,1]$, the function $t \mapsto \OInc_{\dg M \setminus \hat a}(\mu_t)$ is convex.
    Therefore, we know that the function
    \begin{align*}
        G(t) :=
        \OInc_{\dg M}(\mu_t)
        =
        \OInc_{\dg M \setminus a}( \mu_t ) + \beta_a\, F(t),
    \end{align*}
    is \emph{strictly} convex.
    But then this means $\mu_{\nf12}$ satisfies
    \[
        \OInc_{\dg M}( \mu_{\nicefrac12} ) < \OInc_{\dg M}( \mu_0 ),
    \]
    contradicting the premise that $\mu_0$ minimizes $\OInc_{\dg M}$ (i.e., $\mu_0 \in \bbr{\dg M}^*_0$).
    Therefore, it must be the case that all distributions in $\bbr{\dg M}_0^*$ have the same conditional marginals, as promised.
\end{lproof}

\clearpage
\recall{prop:idef-frozen}
\begin{lproof}\label{proof:idef-frozen}
    This is mostly a simple algebraic manipulation. By definition:
    \begin{align*}
        \SDef_{\dg M}(\mu) &= - \H(\mu) + \sum_{a \in \Ar} \alpha_a \H_\mu(\Tgt a | \Src a) \\
        &= \Ex_\mu \left[ - \log \frac{1}{\mu} + \sum_{a \in \Ar} \alpha_a \log \frac{1}{\mu(\Tgt a|\Src a)} \right] \\
        &= \sum_{w \in \V\!\X} \mu(w) \left[ \log \mu(w) + \sum_{a \in \Ar} \log \frac{1}{\mu(\Tgt a(w)|\Src a(w))^{\alpha_a}} \right] \\
        &= \sum_{w \in \V\!\X} \mu(w) \log \pqty[\bigg]{ \faktor{\mu(w)~}{~\prod_{a \in \Ar}\mu(\Tgt a(w)|\Src a(w))^{\alpha_a}}}
    \end{align*}
    But, by \cref{prop:marginonly}, if we restrict $\mu \in \bbr{\dg M}_0^*$, then the conditional marginals in the denominator do not depend on the particular choice of $\mu$; they're shared among all $\nu \in \bbr{\dg M}_0^*$.
\end{lproof}


\recall{theorem:markov-property}

\[
    \text{Or symbolically: }\qquad\quad
    \dg M_1 \bundle \dg M_2
        ~\models~
    \X_1 \mathbin{\bot\!\!\!\bot} \X_2 \mid \X_1 \cap \X_2. \]
\begin{lproof}\label{proof:markov-property}
    Note that,
    save for the joint entropy, every summand the scoring function $\bbr{\dg M_1 + \dg M_2}_\gamma : \Delta(\V\!\X_1 \times \V\!\X_2)$, is a function of the conditional marginal of $\mu$ along some edge.
    In particular, those terms that correspond to edges of $\dg M_1$ can be computed from the marginal $\mu(\X_1)$, while those that correspond to edges of $\dg M_2$ can be computed from the marginal $\mu(\X_2)$.
    Therefore, there are functions $f$ and $g$ such that:
    \[
        \bbr{\dg M_1 \bundle \dg M_2}_\gamma(\mu) = f(\mu(\X_1)) + g(\mu(\X_2)) - \gamma \H(\mu).
    \]

    To make this next step extra clear, let $\mat X := \X_1 \setminus \X_2$ and
    $\mat Z := \X_2 \setminus \X_1$, be the variables unique to each PDG, and $\mat S:= \X_1 \cap \X_2$ be the set of variables they have in common, so that $(\mat X, \mat S, \mat Z)$ is a partition of all variables $\mat X_1 \cup \mat X_2$.
    Now define a new distribution $\mu' \in \Delta(\V\!\X_1 \times \V\!\X_2)$ by
    \[
        \bf
        \mu'( X,  S,  Z)
            := \mu(S) \mu( Z \mid  S)\mu( X \mid  S)
            \qquad \Big(~
            = \mu( X,  S) \mu( Z \mid  S)
            = \mu( Z,  S) \mu( X \mid  S)~\Big).
    \]
    One can easily verify that $\mat X$ and $\mat Z$ are independent given $\mat S$ in $\mu'$ (by construction), and the alternate forms on the right make it easy to see that $\mu(\X_1) = \mu'(\X_1)$ and $\mu(\X_2) = \mu'(\X_2)$.
    Furthermore, for any $\nu'(\mat{X,S,Z})$, we can write
    \begin{align*}
        \H( \nu ) &=  \H_\nu(\mat{X,S,Z}) =
            \H_\nu(\mat{X,S}) + \H_\nu(\mat Z \mid \mat{X,S}) \\
            &= \H_\nu(\mat{X,S}) + \H_\nu(\mat Z \mid \mat{X,S}) - \H_\nu(\mat Z \mid \mat S) + \H_\nu(\mat Z \mid \mat S) \\
            &= \H_\nu(\mat X,\mat S) + \H_\nu(\mat Z \mid \mat S) - \I_\nu(\mat Z; \mat X| \mat S),
    \end{align*}
    where $\I_\nu(\bf X;Z|S)$, the conditional mutual information between $\mat X$ and $\mat Z$ given $\mat S$ (in $\nu$), is non-negative, and equal to zero if and only if $\mat X$ and $\mat Z$ are conditionally independent given $\mat S$ \parencite[see, for instance,][\S1]{mackay2003information}.
    So $\I_{\mu'}(\mat X; \mat Z| \mat S) = 0$, and
        $\H_{\mu'} = \H_{\mu'}(\mat X, \mat S) + \H_{\mu'}(\mat Z| \mat S)$.
    Because $\mu$ and $\mu'$ share marginals on $\X_1$ and $\X_2$, while the terms $\H(\mat X, \mat S)$ and $\H(\mat Z|\mat S)$ depend only on these marginals, respectively, we also know that $\H_{\mu}(\mat X, \mat S) = \H_{\mu'}(\mat X, \mat S)$ and $\H_{\mu}(\mat Z | \mat S) = \H_{\mu'}(\mat Z| \mat S)$; thus we have
    \begin{align*}
        \H(\mu) &= \H_\mu(\mat X,\mat S) + \H_\mu(\mat Z \mid \mat S) - \I_\mu(\mat Z; \mat X| \mat S) \\
            &= \H(\mu') - \I_\mu(\mat Z; \mat X| \mat S).
    \end{align*}
    Therefore,
    \begin{align*}
        \bbr{\dg M_1 \bundle \dg M_2}_\gamma(\mu)
         &= f(\mu(\X_1)) + g(\mu(\X_2)) - \gamma \H(\mu) \\
         &= f(\mu'(\X_1)) + g(\mu'(\X_2)) - \gamma \H(\mu') + \gamma \I_\mu(\mat Z; \mat X| \mat S) \\
         &= \bbr{\dg M_1 \bundle \dg M_2}_\gamma(\mu') + \gamma \I_\mu(\mat Z; \mat X| \mat S).
    \end{align*}
    But conditional mutual information is non-negative, and by assumption, $\bbr{\dg M \bundle \dg M_2}_\gamma(\mu)$ is minimal. Therefore, it must be the case that
    \[
        \I_\mu(\mat Z; \mat X| \mat S) = \I_\mu(\X_1; \X_2 \mid \X_1 \cap \X_2) = 0,
    \]
    showing that $\X_1$ and $\X_2$ are conditionally independent given the variables that they have in common. \\
    (The fact that $\I_\mu(\mat Z; \mat X| \mat S) = \I_\mu(\X_1; \X_2 \mid \X_1 \cap \X_2)$ is both easy to show and an instance of a well-known identity; see CIRV2 in Theorem 4.4.4 of \textcite{halpern-RAU}, for instance.)
\end{lproof}

\recall{coro:can-use-cliquetree}
\begin{lproof}\label{proof:can-use-cliquetree}

    The set of distributions that can be represented by a \cactree\ over $(\C,\cal T)$ is the same as the set of distributions that can represented by a factor graph for which $(\C, \cal T)$ is a tree decomposition.
    One direction holds because any such product of factors ``calibrated'', via message passing algorithms such as belief propagation, to form a \actree.
    The other direction holds because $\Pr_{\bmu}$ itself is a product of factors that decomposes over $(\C, \cal T)$.



    Alternatively, this same set of distributions that satisfy the independencies of the Markov Network obtained by connecting every pair of variables that share a cluster.
    More formally, this network is the graph $G := (\X, E := \{ (X{-}Y) :  \exists C \in \C.~\{X,Y\} \subseteq C\})$.
    Also, $G$ happens to chordal as well, which we prove at the end.


    Using only the PDG Markov property (\cref{theorem:markov-property}), we now show that every independence described by $G$ also holds in every distribution $\mu \in \bbr{\dg M}^*_\gamma$.
    Suppose that,
    for sets of variables $\mat X, \mat Y, \mat Z \subseteq \X$,
    $\I(\mat X; \mat Y|\mat Z)$ is an independence
    described by $G$.
    This means \parencite[Defn 4.8]{KF09} that
    if $X \in \mat X$, $Y \in \mat Y$, and $\pi$ is a path in $G$ between them, then
    some node along $\pi$ lies in $\mat Z$.


    Let $\cal T'$ be the graph that results from removing each edge $(C{-}D) \in \cal T$ that satisfies $C \cap D \subseteq \mat Z$, which is a disjoint union  $\mathcal T' = \mathcal T_1 \sqcup \ldots \sqcup \mathcal T_n$ of subtrees that have no clusters in common.
    To parallel this notation, let $\C_1, \ldots, \C_n$ be their respective vertex sets.
    Note that for every edge $e=(C{-}D)\in \cal T'$, there must by definition be some variable $U_e \in (C \cap D) \setminus \mat Z$.

    We claim that no subtree $\mathcal T_i$ can have both a cluster $D_X$ containing a variable $X \in \mat X \setminus \mat Z$ and also a cluster $D_Y$ containing a variable $Y \in \mat Y \setminus \mat Z$.
    Suppose that it did.
    Then the (unique) path in $\cal T$ between $D_X$ and $D_Y$, which we label
    \[
    \begin{tikzcd}[column sep=2em]
        D_X=
        &D_0 \ar[r,-,"e_1"]&
        D_1 \ar[r,-,"e_2"]&
          \cdots
        \ar[r,-,"e_{m-1}"]& D_{m-1}
        \ar[r,-,"e_m"] & D_m&
        =D_Y
    \end{tikzcd},
    \]
    would lie entirely within $\mathcal T_i \subseteq \mathcal T'$. This gives rise to
    a corresponding path in $G$:
    \[\begin{tikzcd}[column sep=1em,row sep=1.5ex]
        X \ar[r,-] \ar[d,sloped,phantom,"\in"]
        & U_{e_1}\ar[r,-] \ar[d,sloped,phantom,"\in"]
        & U_{e_2}\ar[r,-] \ar[d,sloped,phantom,"\in"]
           &\cdots\ar[r,-]
        & U_{e_{n{-}1}} \ar[r,-] \ar[d,sloped,phantom,"\in"]
        & U_{e_n}\ar[r,-] \ar[d,sloped,phantom,"\in"]
        & Y \ar[d,sloped,phantom,"\in"]
            \\
        D_0
        & D_0 \cap D_1
        & D_1 \cap D_2
        &
        & D_{n{-}2} \cap D_{n{-}1}
        & D_{n{-}1} \cap D_n
        & D_n
    \end{tikzcd}\quad,\]
    and moreover, this path is disjoint from $\mat Z$.
    This contradicts our assumption that every path in $G$ between a member of $\mat X$ and a member of $\mat Y$ must intersect with $\mat Z$, and so no subtree can have both a cluster containing a variable $X \in \mat X \setminus \mat Z$ and also one containing $Y \in \mat Y \setminus \mat Z$.

    \def\CX{\C_{\mat X}}
    \def\CNX{\C_{\mat{Y}}^+}
    We can now partition the clusters as $\C = \CX \sqcup \CNX$, where
    $\CX$ is the set of the clusters that belong to subtrees $\mathcal T_i$ with a cluster containing some $X \in \mat X \setminus \mat Z$, and
    its $\CNX$ is its complement, which in particular contains those subtrees have some $Y \in \mat Y \setminus \mat Z$.
    Or, more formally, we define
    \[
        \CX :=~ \bigcup_{\mathclap{\substack{i \in \{1,\ldots,n\}\\ (\cup\C_i) \cap (\mat X\setminus\mat Z) \ne \emptyset }}}\, \C_i
        \quad\qquad \text{and}\qquad
        \CNX :=~ \bigcup_{\mathclap{\substack{i \in \{1,\ldots,n\}\\ (\cup\C_i) \cap (\mat X\setminus\mat Z) = \emptyset }}}\, \C_i
        \quad.
    \]
    \def\XX{\X_{\mat X}}
    \def\XNX{\X_{\mat Y}^+}
    Let $\XX := \cup \CX$ set of all variables appearing in the clusters $\CX$; symmetrically, define $\XNX := \cup \CNX$.


    We claim that $\XX \cap \XNX \subset \mat Z$.
    Choose any variable $U \in \XX \cap \XNX$.
    From the definitions of $\XX$ and $\XNX$, this means $U$ is a member of some cluster $C \in \CX$, and also a member of a cluster $D \in \CNX$.
    Recall that the clusters of each disjoint subtree $\mathcal T_i$ either fall entirely within $\CX$ or entirely within $\CNX$ by construction.
    This means that $C$ and $D$, which are on opposite sides of the partition, must have come from distinct subtrees.
    So, some edge $e = (C'{-}D') \in \mathcal T$ along the (unique) path from $C$ to $D$ must have been removed when forming $\mathcal T'$, which by the definition of $\mathcal T'$, means that $(C' \cap D') \subset Z$.
    But by the running intersection property (\actree\ property 2), every cluster along the path from $C$ to $D$ must contain $C \cap D$---in particular, this must be true of both $C'$ and $D'$.
    Therefore,
    \[
        U \in C \cap D \subset C' \cap D' \subset \mat Z.
    \]
    So $\XX \cap \XNX \subset \mat Z$, as promised.  We will rather use it in the equivalent form $(\XX \cap \XNX) \cup \mat Z = \mat Z$.

    Next, since $(\C, \cal T)$ is a tree decomposition of $\Ar$, each hyperarc $a \in \Ar$ can be assigned to some cluster $C_a$ that contains all of its variables; this allows us to lift the cluster partition $\C = \CX \sqcup \CNX$ to a partition $\Ar = \Ar_{\mat X} \sqcup \Ar_{\mat Y}^+$ of edges, and consequently, a partition of PDGs $\dg M = \dg M_{\mat X} \bundle \dg M_{\mat Y}^+$.
    Concretely: let $\dg M_{\mat X}$ be the sub-PDG of $\dg M$ induced by restricting to the variables $\XX \subseteq \X$ arcs $\Ar_{\mat X} = \{ a \in \Ar : C_a \in \CX \} \subseteq \Ar$; define $\dg M_{\mat Y}^+$ symmetrically. (To be explicit: the other data of $\dg M_{\mat X}$ and $\dg M_{\mat Y}^+$ are given by restricting each of $\{\mathbb P,\balpha,\bbeta\}$ to $\Ar_{\mat X}$ and $\Ar_{\mat Y}^+$, respectively.)

    This partition of $\dg M$ allows us to use the PDG Markov property.
    Suppose that for some $\gamma > 0$ that $\mu \in \bbr{\dg M}^*_\gamma = \bbr{\dg M_{\mat X} \bundle \dg M_2}^*_\gamma$.
    We can then apply \cref{theorem:markov-property}, to find that
    $\XX$ and $\XNX$ are independent given $\XX \cap \XNX$.
    We use standard standard properties of random variable independence
        \parencite[CIRV1-5 of][Theorem 4.4.4]{halpern-RAU} to find that $\mu$ must satisfy:
    \begin{align*}
        \XX  &\CI \XNX \mid \XX \cap \XNX\\
    \implies~~~
        (\XX \setminus \mat Z) &\CI (\XNX\setminus \mat Z) \mid (\XX \cap \XNX) \cup \mat Z
            & \big[\,\text{CIRV3}\,\big] \\
    \implies\quad
        (\mat X \setminus \mat Z) &\CI (\mat Y \setminus \mat Z) \mid (\XX \cap \XNX) \cup \mat Z
        % & \big[\,\text{by CIRV2, as $\mat X \subseteq \XX$ and $\mat Y \subseteq \XNX$}\,\big] \\
        & \Big[\singlespacingmath \begin{array}{l}\text{by CIRV2, as }\\\mat X \subseteq \XX\text{ and }\mat Y \subseteq \XNX \end{array}\big] \\
    \implies\quad
        (\mat X \setminus \mat Z) &\CI (\mat Y \setminus \mat Z) \mid \mat Z
        & \big[\,\text{since $(\XX \cap \XNX) \cup \mat Z = \mat Z$}\,\Big] \\
    \iff\quad
        \mat X &\CI \mat Y \mid \mat Z
        & \hspace{-6em}\big[\,\text{standard; e.g., Exercise 4.18 of \textcite{halpern-RAU}}\,\big] \\
    \end{align*}

    Using only the PDG Markov property, we have now shown that every independence
    modeled by the Markov Network $G$ also holds
    in every distribution $\mu \in \bbr{\dg M}^*_\gamma$. Moreover, $G$ is chordal (as we will prove momentarily),
    and is well-known that distributions that have the independencies of a chordal graph can be can be represented by \actree s \parencite[Theorem 4.12]{KF09}.
    Therefore, there is a \actree $\bmu$ representing every $\mu \in \bbr{\dg M}^*_\gamma$.

    \begin{iclaim}
        $G$ is chordal.
            \label{subclaim:chordal}
    \end{iclaim}
    \begin{proof}
        Suppose that $G$ contains a loop $X{-}Y{-}Z{-}W{-}X$.
        Suppose further, for contradiction, that neither $X$ and $Z$ nor $Y$ and $W$ share a cluster.
        Given a variable $V$, it is easy to see that property (2) of the tree decomposition ensures that the subtree $\mathcal T(V) \subseteq \mathcal T$ induced by the clusters $C \in \C$ that contain $V$, is connected.
        By assumption, ${\cal T}(Y)$ and ${\cal T}(W)$ must be disjoint.
        There is an edge between $Y$ and $Z$, so some cluster must contain both variables, meaning ${\cal T}(Y) \cap {\cal T}(Z)$ is non-empty.
        Similarly, ${\cal T}(Z) \cap {\cal T}(W)$ is non-empty because of the edge between $Z$ and $W$.
        This creates an (indirect) connection in $\cal T$ between ${\cal T}(Y)$ and ${\cal T}(W)$. Because $\cal T$ is a tree, and ${\cal T}(Y) \cap {\cal T}(W) = \emptyset$,
        every path from a cluster $C_1 \in {\cal T}(Y)$ to a cluster $C_2 \in {\cal T}(W)$ must pass through ${\cal T}(Z)$, which is not part of ${\cal T}(Y)$ or ${\cal T}(W)$.
        ${\cal T}(X)$ and ${\cal T}(Y)$ intersect as well, meaning that, for any $C \in {\cal T}(X)$, there is a (unique) path from $C$ to that point of intersection, then across edges of ${\cal T}(Y)$, then edges of ${\cal T}(Z)$, and finally connects to the clusters of ${\cal T}(W)$. And also, since $\cal T$ is a tree, that path must be unique.
        The problem is that there is also an edge between $X$ and $W$, so there's some cluster that contains $X$ and $W$; let's call it $C_0$.
        It's distinct from the cluster $D_0$ that contains $Z$ and $W$, since no cluster contains both $X$ and $Z$ by assumption.
        The unique path from $C_0$ to $D_0$
        intersects with ${\cal T}(Y)$.
        But now $W \in C_0 \cap D_0$, and by the running intersection property, every node along this unique path must contain $W$ as well.
        But this contradicts our assumption that $W$ is disjoint from $Y$! So $G$ is chordal.
    \end{proof}
    Having proved the subclaim \cref{subclaim:chordal}, 
    we have now finished the proof of \cref{coro:can-use-cliquetree}.
\end{lproof}


% \subsection{Correctness and Efficiency of Inference via Exponential Conic Programming}
\subsection{Correctness and Complexity Analysis for PDG Inference via Exponential Conic Programming}
    \label{proofs:expcone-efficient-correct}

\recall{prop:joint-inc-correct}

\begin{lproof}
    \label{proof:joint-inc-correct}
    Suppose that $(\mu, \mat u)$ is a solution to \eqref{prob:joint-inc}.
    The exponential cone constraints ensure that, for every $(a, s,t) \in \V\!\Ar$,
    \[
        u_{a,s,t} \ge \mu(s,t) \log \frac{\mu(s,t)}{\p_a(t|s)\mu(s)},
    \]
    where $\mu(s,t)$ and $\mu(s)$, as usual, are shorthand for $\mu(\Src a{=}s, \Tgt a{=}t)$ and $\mu(\Src a {=} s)$, respectively.
    %
    Suppose, for contradiction, that one of these inequalities is strict at some an index $(a',s',t') \in \V\!\Ar$ for which $\beta_{a'} > 0$.
    Explicitly, this means
    \[
        u_{a',s',t'} > \mu(s_0,t_0) \log \frac{\mu(s',t')}{\p_{a'}(t'|s')\mu(s')}.
    \]
    In that case, we can define a vector $\mat u' = [u'_{a,s,t}]_{(a,s,t)\in\V\!\Ar}$ which is identical to $\mat u$, except that at $(a',s',t')$, it is halfway between the two quantities described as different above.  More precisely:
    \[
        u'_{a',s',t'} = \frac12 u_{a',s',t'} + \frac12 \log \mu(s',t') \log \frac{\mu(s',t')}{\p_a(t'|s')\mu(s')}.
    \]
    Note that $u'_{a',s',t'} < u_{a',s',t'}$,
    and also that, by construction, $(\mu, \mat u')$ also satisfies the constraints of \eqref{prob:joint-inc}.
    In more detail: at the index $(a', s', t')$,
    $\mat u'$ does not violate the associated exponential cone constraint
    because
    \[
        % \left( \text{because}~ 
        u'_{a',s',t'} = \frac12 u_{a',s',t'} + \frac12 \log \mu(s',t')\log \frac{\mu(s',t')}{\p_{a'}(t'|s')\mu(s')}
        >
        \mu(s',t') \log \frac{\mu(s',t')}{\p_{a'}(t'|s')\mu(s')}
        % \right)
        ,
    \]
    and $\mat u'$ equals $\mat u$ at other indices, and therefore satisfies the constraint everywhere else as well.
    But now, because $u'_{a', s', t'} < u_{a',s',t'}$, and $\beta_{a'} >0$, we also have
    \[
        \sum_{(a,s,t) \in \V\!\Ar} \beta_a u'_{a,s,t}
            > \sum_{(a,s,t) \in \V\!\Ar} \beta_a u'_{a,s,t}.
    \]
    Thus the objective value at $(\mu, \mat u')$ is strictly
    smaller than the one at $(\mu, \mat u)$, both of which are feasible points.
    This contradicts the assumption that $(\mu, \mat u)$ is optimal.
    We therefore conclude that none of these inequalities can be strict at points where $\beta_{a} > 0$.
    This can be compactly written as:
    \begin{align*}
        \forall (a,s,t) \in \V\!\Ar.\quad
        \beta_a u_{a,s,t} &= \beta_a \mu(s,t) \log \frac{\mu(s,t)}{\p_a(t|s)\mu(s)} \\
        \implies\qquad
        \sum_{(a,s,t) \in \V\!\Ar}\beta_a u_{a,s,t}
            &= \sum_{(a,s,t) \in \V\!\Ar} \beta_a \mu(s,t) \log \frac{\mu(s,t)}{\p_a(t|s)\mu(s)}
            = \OInc_{\dg M}(\mu).
    \end{align*}
    In other words, the objective of problem \eqref{prob:joint-inc} at
    $(\mu, \mat u)$ is equal to the observational incompatibility $\OInc_{\dg M}(\mu)$ of $\mu$ with $\dg M$.
    And, because $(\mu, \mat u)$ minimizes this value among all joint distributions, $\mu$ must be a minimum of $\OInc_{\dg M}$.

    More formally: assume for contradiction that $\mu$ is not a minimizer of $\OInc_{\dg M}$. Then there would be some other distribution $\mu'$ for which $\OInc_{\dg M}(\mu') < \OInc_{\dg M}(\mu)$.
    Let $\mat u'' := [ \mu'(s,t) \log \frac{\mu'(s,t)}{\p_a(t|s) \mu'(s)} ]_{(a,s,t) \in \V\!\Ar}$. Clearly $(\mu', \mat u'')$ satisfies the constraints of the problem, and moreover,
    \[
        \sum_{(a,s,t)\in \V\!\Ar} \beta_a u_{a,s,t} =
        \OInc_{\dg M}(\mu) >
        \OInc_{\dg M}(\mu') =
        \sum_{(a,s,t)\in \V\!\Ar} \beta_a u'_{a,s,t},
    \]
    contradicting the assumption that the $(\mu, \mat u)$ is optimal for problem \eqref{prob:joint-inc}. Thus, $\mu$ is a minimizer of $\OInc_{\dg M}$, and the objective value is $\inf_{\mu} \OInc_{\dg M}(\mu) = \aar{\dg M}_0$, as desired.
\end{lproof}

\recall{prop:joint-small-gamma-correct}
For convenience, we repeat problem \eqref{prob:joint-small-gamma}
(left) and an equivalent variant of it that we implement (right) below.
\begin{center}
\footnotesize	
\makebox[0pt]{%
\begin{minipage}{0.52\linewidth}
\begin{align*}
\minimize_{\mu, \mat u, \mat v} & ~~
    \sum_{\mathrlap{\!\!\!(a,s,t) \in \V\!\Ar}}
        (\beta_a \!- \alpha_a \gamma) u_{a,s,t}
        \,+
        \gamma
        \sum_{\mathclap{w \in \V\!\X}} v_w
    \tag{\ref{prob:joint-small-gamma}}
\\[-0.2ex]
    &
    - \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}}
        \alpha_a \gamma \,
        \mu(\Src a{=}s,\Tgt a {=} t) \log \p_a (t|s)
\\[0.2ex]
\subjto&\quad \mu \in \Delta\V\!\X,
        \quad ( -\mat v,  \mu,  \mat 1) \in K_{\exp}^{\V\!\X},
\\[-0.4ex]
    \forall a \in \Ar.~
        &\big(\shortminus\mat u_a, \mu( \Tgt a,\Src a),\p_a(\Tgt a | \Src a)  \mu(\Src a) \big)
            \in K_{\exp}^{\V a},
\\[-0.2ex]
    \forall (a,s,t) &\in \V\!\Ar^0\!.~
    \mu(\Src a{=}\mskip2mus, \Tgt a{=}\mskip2mut) = 0;
\end{align*}
\end{minipage}
~~\vrule~~
\begin{minipage}{0.52\linewidth}
\begin{align*}
\minimize_{\mu, \mat u, \mat v} & ~~
    \sum_{\mathrlap{\!\!\!(a,s,t) \in \V\!\Ar}}
        (\beta_a \!- \alpha_a \gamma) u_{a,s,t}
        \,+
        \gamma
        \sum_{\mathclap{w \in \V\!\X}} v_w
        \tag{\ref*{prob:joint-small-gamma}b}\label{prob:joint-small-gamma-b}
\\[-0.2ex]
    &
    - \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}}
        \beta_a \,
        \mu(\Src a{=}s,\Tgt a {=} t) \log \p_a (t|s)
\\[0.2ex]
\subjto&\quad \mu \in \Delta\V\!\X,
        \quad ( -\mat v,  \mu,  \mat 1) \in K_{\exp}^{\V\!\X},
\\[-0.4ex]
    \forall a \in \Ar.~
    &\big(\shortminus\mat u_a, \mu( \Tgt a,\Src a),
        \big[\,\mu(\Src a{=}s) \big]_{(s,t) \in \V a} \big)
        \in K_{\exp}^{\V a},
\\[-0.2ex]
    \forall (a,s,t) &\in \V\!\Ar^0\!.~
    \mu(\Src a{=}\mskip2mus, \Tgt a{=}\mskip2mut) = 0.
\end{align*}
\end{minipage}
}
\end{center}
\medskip

\begin{lproof}\label{proof:joint-small-gamma-correct}
    We start with the problem on the left, which is \eqref{prob:joint-small-gamma} from the main text.
    Suppose that $(\mu, \mat u, \mat v)$ is a solution to \eqref{prob:joint-small-gamma}.
    The exponential constraints ensure that
    \[
        \forall (a,s,t) \in \V\!\Ar.~
        u_{a,s,t} \ge \mu(s,t) \log \frac{\mu(t|s)}{\p_a(t|s)}
    \qquad\text{and}\qquad
        \forall w \in \V\!\X.~
        v_{w} \ge \mu(w) \log \mu(w).
    \]
    As in the previous proof, we claim that these must hold with equality (except possibly for $u_{a,s,t}$ at indices satisfying $\beta_a = \gamma \alpha_a$, when it doesn't matter).
    This is because otherwise one could reduce the value of a component of $u$ or $v$ while still satisfying all of the constraints, to obtain a strictly smaller objective, contradicting the assumption that $(\mu, \mat u, \mat v)$ minimizes it.

    Thus, $\mat v$ is a function of $\mu$, as is every value of $\mat u$ that affects the objective value of \eqref{prob:joint-small-gamma}, meaning that this objective value can be written as a function of $\mu$ alone:
    \begin{align*}
        &\sum_{\mathrlap{\!\!\!(a,s,t) \in \V\!\Ar}}
            (\beta_a \!- \alpha_a \gamma) u_{a,s,t}
        ~+ \gamma \sum_{\mathclap{w \in \V\!\X}} v_w
        ~- \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}}
            \alpha_a\gamma \, \mu(s,t) \log \p_a (t|s) \\
    &=
        \!\sum_{\mathrlap{\!\!\!(a,s,t) \in \V\!\Ar}}
            (\beta_a \!- \alpha_a \gamma) \Big[ \mu(s,t) \log \frac{\mu(t|s)}{\p_a(t|s)}\Big] \!
        + \gamma \sum_{\mathclap{w \in \V\!\X}} \mu(w) \log \mu(w)
        - \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}}
            \alpha_a\gamma \, \mu(s,t) \log \p_a (t|s) \\
    &=
        \sum_{a \in \Ar} (\beta_a \!- \alpha_a \gamma) \sum_{\mathclap{(s,t) \in \V a}}
             \mu(s,t) \log \frac{\mu(t|s)}{\p_a(t|s)}
        - \gamma \H(\mu)
        - \sum_{a \in \Ar} \alpha_a\gamma \, \sum_{\mathclap{(s,t) \in \V\!\Ar}}
             \mu(s,t) \log \p_a (t|s) \\
     &=
         \!\sum_{a \in \Ar} (\beta_a \!- \alpha_a \gamma)
          \sum_{\mathclap{(s,t) \in \V a}}
             \mu(s,t) \Big[ \!\log \frac{1}{\!\p_a(t|s)\mskip-2mu} - \log \frac{1}{\!\mu(t|s)\!}\Big]
         -\! \gamma \H(\mu)
         -\! 
         % \sum_{a \in \Ar} \alpha_a\gamma \Ex_\mu [\log \p_a (\Tgt a|\Src a)]\\
         \sum_{\mathclap{~~~\ed aST \in \Ar}} \alpha_a\gamma \Ex_\mu \log \p_a (T|S) \\
    &=
        \sum_{a \in \Ar} (\beta_a \!-\! \alpha_a \gamma)
           \Ex_{\mu}[ - \log \p_a(\Tgt a | \Src a)]
        - \sum_{a \in \Ar} (\beta_a \!-\! \alpha_a \gamma)
           \H_{\mu}(\Tgt a | \Src a)
           \\&\hspace{5cm}
        - \gamma \H(\mu)
        - \sum_{a \in \Ar} \alpha_a\gamma \, \Ex_{\mu} [ \log \p_a (\Tgt a|\Src a) ] \\
    &=
        \sum_{a \in \Ar} \Big( - \alpha_a\gamma - (\beta_a \!-\! \alpha_a \gamma) \Big)
           \Ex_{\mu}[ \log \p_a(\Tgt a | \Src a)]
        + \sum_{a \in \Ar} (\alpha_a \gamma \!-\! \beta_a)
           \H_{\mu}(\Tgt a | \Src a)
        - \gamma \H(\mu) \\
    &=
        -\sum_{a \in \Ar} \beta_a
           \Ex_{\mu}[ \log \p_a(\Tgt a | \Src a)]
        + \sum_{a \in \Ar} (\alpha_a \gamma \!-\! \beta_a)
           \H_{\mu}(\Tgt a | \Src a)
        - \gamma \H(\mu).
    \end{align*}
    ( In the third step, we were able to convert $\V\!\Ar^+$ to $\V\!\Ar$ because, as usual in when dealing with information-theoretic quantities, we take $0 \log \frac{1}0$ to equal zero, which is its limit. )

    The algebra for the right side variant
    \eqref{prob:joint-small-gamma-b}
    is slightly simpler. In this case the middle conic constraint is almost the same, except for that $\p_a(t|s)$ has been replaced with $1$, and so it ensures that $u_{a,s,t} = \mu(s,t) \log \mu(t\mid s)$ (i.e., the same as before, but without the probability in the denominator). So,
    \begin{align*}
        &\sum_{\mathrlap{\!\!\!(a,s,t) \in \V\!\Ar}}
            (\beta_a \!- \alpha_a \gamma) u_{a,s,t}
        ~+ \gamma \sum_{\mathclap{w \in \V\!\X}} v_w
        ~- \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}}
            \beta_a \, \mu(s,t) \log \p_a (t|s) \\
    &=
        \sum_{\mathrlap{\!\!\!(a,s,t) \in \V\!\Ar}}
            (\beta_a \!- \alpha_a \gamma) \mu(s,t) \log \mu(t|s)
        ~+~ \gamma \sum_{\mathclap{w \in \V\!\X}} \mu(w) \log \mu(w)
        ~-~ \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}}
            \beta_a \, \mu(s,t) \log \p_a (t|s) \\
    &=
        \sum_{a \in \Ar} (\beta_a \!- \alpha_a \gamma) \sum_{(s,t) \mathrlap{\in \V a}}
             \mu(s,t) \log \mu(t|s)
        - \gamma \H(\mu)
        - \sum_{a \in \Ar} \beta_a \, \sum_{(s,t) \mathrlap{\in \V\!\Ar}}
             \mu(s,t) \log \p_a (t|s) \\
        &=
        \sum_{a \in \Ar}
         (\alpha_a \gamma \!-\! \beta_a)
           \H_{\mu}(\Tgt a | \Src a)
        - \gamma \H(\mu)
        -\sum_{a \in \Ar} \beta_a
           \Ex_{\mu}[ \log \p_a(\Tgt a | \Src a)].
    \end{align*}


    In either case, the objective value is equal to $\bbr{\dg M}_\gamma(\mu)$, by \eqref{eq:altscore}.
    Because $(\mu, \mat u, \mat v)$ is optimal for this problem, we know that $\mu$ is a minimizer of $\bbr{\dg M}_{\gamma}(\mu)$, and that the objective value equals $\aar{\dg M}_\gamma$.
\end{lproof}


\begin{lemma}\label{lem:hess-relent}
    The gradient and Hessian of conditional relative entropy
    are given by
    \begin{align*}
        \Big[ \nabla_{\mu} \kldiv{\mu(X,Y)}{\mu(X) p(Y|X) } &\Big]_u
            = \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)} \\
        \Big[ \nabla^2_\mu \kldiv{\mu(X,Y)}{\mu(X)p(Y|X)}&\Big]_{u,v}
            = \frac{\mathbbm1[X\!u {=} X\!v \land Y\!u {=} Y\!v]}{\mu(Y\! u, X\! u)}
            - \frac{\mathbbm1[X\!v = X\!u]}{\mu(X\!u)}
        ,
    \end{align*}
    where $X\! u = X(u)$ it the value of the variable $X$ in the joint setting $u \in \V\!\X$ of all variables.
\end{lemma}
\begin{lproof} \label{proof:hess-relent}
    \allowdisplaybreaks

    \def\pd/d#1[#2]{\,\frac{\partial}{\partial #1}\!\! \left[\vphantom{\Big|}#2\right]}

    Represent $\mu$ as a vector $[\mu_{w}]_{w \in \V\X}$.
    We will make repeated use of the following facts:
    \begin{align*}
        \pd/d\mu_u [\mu(X{=}x)]=
        \pd/d\mu_u [\mu(x)]
         &= \sum_w \pd/d\mu_u[\mu_w] \! \mathbbm1[X\!w{=}x]
            ~=~  \mathbbm1[ X\! u {=} x] ; \quad\text{and}\\
        \pd/d\mu_u [\mu(y|x)] &=
            \pd/d\mu_u [ \frac{\mu(x,y)}{\mu(x)}] \\
        &= \mu(x,y) \pd/d\mu_u[ \frac{1}{\mu(x)} ]
            + \frac1{\mu(x)} \pd/d\mu_u[ \mu(x,y) ] \\
        &= - \mu(x,y)\frac{\mathbbm1[ X\!u = x]}{\mu(x)^2}
             + \frac{1}{\mu(x)} \mathbbm1[X\!u {=} x \land Y\!u {=} y] \\
        &= \frac{\mathbbm1[X\!u = x]}{\mu(x)}\Big( \mathbbm1[Y\!u=y] - \mu(y|x) \Big).
    \end{align*}

    We now apply this to the (conditional) relative entropy:
    \begin{align*}
        &\pd/d\mu_u [ \kldiv{\mu(X,Y)}{\mu(X) p(Y|X) }] \\
            &= \pd/d\mu_u [ \sum_{w} \mu_w \log \frac{\mu(Y\! w | X\! w)}{ p(Y\! w | X\! w)} ] \\
            &= \sum_{w} \mathbbm1[u{=}w]  \log \frac{\mu(Y\! w | X\! w)}{  p(Y\! w | X\! w)}
                + \sum_{w} \mu_w  \pd/d\mu_u [  \log \frac{\mu(Y\! w | X\! w)}{  p(Y\! w | X\! w)} ] \\
            &=  \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)}
                + \sum_{w} \mu_w
                \frac{  p(Y\! w | X\! w)}{\mu(Y\! w | X\! w)}
                \pd/d\mu_u [ \frac{\mu(Y\! w | X\! w)}{  p(Y\! w | X\! w)} ] \\
            &=  \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)}
                + \sum_{w} \mu_w
                \frac{1}{\mu(Y\! w | X\! w)}
                \pd/d\mu_u [\mu(Y\! w | X\! w) ] \\
            &=  \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)}
                + \sum_{w} \mu_w
                \frac{1}{\mu(Y\! w | X\! w)}
                 \frac{\mathbbm1[X\!u = X\!w]}{\mu(X\!w)}\Big( \mathbbm1[Y\!u=Y\!w] - \mu(Y\!w|X\!w) \Big)\\
            &=  \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)}
                + \sum_{w} \mu_w  \frac{\mathbbm1[X\!u{=}X\!w \land Y\!u{=}Y\!w]}
                    {\mu(X\!w, Y\!w)}
                - \sum_{w} \mu_w \frac{\mathbbm1[X\!u = X\!w]}{\mu(X\!w)}
                \\
            &=  \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)}
                + \frac{1}{\mu(X\!u, Y\!u)} \sum_w \mu_w  \mathbbm1[X\!u{=}X\!w \land Y\!u{=}Y\!w]
                - \frac{1}{\mu(X\!u)} \sum_w \mu_w \mathbbm1[X\!u = X\!w]
                \\
            &=  \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)}
                + \frac{\mu(X\!u, Y\!u)}{\mu(X\!u, Y\!u)}
                - \frac{\mu(X\!u)}{\mu(X\!u)}   \\
            &= \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)} + 1 - 1 \\
            &= \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)}
            .
    \end{align*}

    This allows us to compute the Hessian of the conditional relative entropy, whose  components are
    \begin{align*}
        \frac{\partial^2}{\partial \mu_u \partial \mu_v} \Big[ \kldiv{\mu(XY)}{\mu(X)p(Y|X)}\Big]
        &=
        \pd/d\mu_v[ \log \frac{\mu(Y\! u | X\! u)}{  p(Y\! u | X\! u)} ] \\
        &=
        \frac{ p(Y\! u | X\! u)}{\mu(Y\! u | X\! u)} \frac1{ p(Y\! u | X\! u)}
        \pd/d\mu_v[ \mu(Y\! u | X\! u) ] \\
        &= \frac{1}{\mu(Y\! u | X\! u)}
            \frac{\mathbbm1[X\!v{=}X\!u]}{\mu(X\!u)}\Big( \mathbbm1[Y\!v{=}Y\!u] - \mu(Y\!u|X\!u) \Big)\\
        &= \frac{\mathbbm1[X\!u {=} X\!v \land Y\!u {=} Y\!v]}{\mu(Y\! u, X\! u)}
            - \frac{\mathbbm1[X\!v = X\!u]}{\mu(X\!u)}
        . \qedhere
    \end{align*}
\end{lproof}


\begin{lemma}
    Let $p(Y|X)$ be a cpd,
    and suppose that $\mu_0, \mu_1 \in \Delta \V(X,Y)$ are joint distributions that have different conditional marginals on $Y$ given $X$; that is, that
    there exist $(x,y) \in \V(X,Y)$ such that
    $
        \mu_0(x,y) \mu_1(x)  \ne \mu_1(x,y) \mu_0(x).
    $
    Then the conditional relative entropy
    $
        \kldiv[\Big]{ \mu(X,Y) }{ \mu(X) p(Y|X) }
    $
    is strictly convex in $\mu$ along the line segment from $\mu_0$ to $\mu_1$.
    More precisely, for $t \in [0,1]$, if we define
    $\mu_t := (1-t) \mu_0 + t\, \mu_1$, then
    the function
    \[
    t ~\mapsto~ \kldiv[\Big]{ \mu_t(X,Y) }
        {\mu_t(X) p(Y|X)}
        \qquad\text{is strictly convex. }
    \]
    \label{lem:seg-strictcvx}
\end{lemma}
\begin{lproof}
    The function of interest can fail to be strictly convex only if the direction $\delta$ along $\mu_1-\mu_0$ is in the null-space of the Hessian matrix $\mat H(\mu)$ of the (conditional) relative entropy.
    By \cref{lem:hess-relent},
    \[
        \mat H_{(xy),(x'y')}
         = \frac{\mathbbm1[x {=} x' \land y {=} y']}{\mu(x,y)}
             - \frac{\mathbbm1[x {=} x']}{\mu(x)}.
    \]

    \def\bdelta{{\boldsymbol\delta}}
    Consider a function $\delta : \V(X,Y) \to \mathbb R$ that is not identically zero, which can be viewed as a vector $\bdelta = [\delta(x,y)]_{(x,y) \in \V(X,Y)} \in \mathbb R^{\V(X,Y)}$.
    We can also view $\delta$ as a (signed) measure on $\V(X,Y)$, that has marginals in the usual sense. In particular, we use the analogous notation
    \[
        \delta(x) :=
            \sum_{y \in \V Y} \delta(x,y).
    \]
    We then compute
    \begin{align*}
        \big(\, \mat H(\mu)\, \bdelta\, \big)_{x,y}
        &= \sum_{x', y'} \delta(x',y') \left( \frac{\mathbbm1[x {=} x' \land y {=} y']}{\mu(x,y)} - \frac{\mathbbm1[x {=} x']}{\mu(x)} \right) \\
        &= \frac{\delta(x,y)}{\mu(x,y)} - \frac{\delta(x)}{\mu(x)}.
    \end{align*}

    and also
    \begin{align*}
        \bdelta^{\sf T} \mat H(\mu) \,\bdelta
            &= \sum_{x,y} \delta(x,y) (\, \mat H(\mu)\, \bdelta\, )_{x,y} \\
            &= \sum_{x,y} \delta(x,y) \left(
                \frac{\delta(x,y)}{\mu(x,y)} - \frac{\delta(x)}{\mu(x)} \right) \\
            &= \sum_{x,y}
                \frac{\delta(x,y)^2}{\mu(x,y)} - \sum_{x} \frac{\delta(x)}{\mu(x)} \sum_y \delta(x,y) \\
            &= \sum_{x,y} \frac{\delta(x,y)^2}{\mu(x,y)} - \sum_{x} \frac{\delta(x)^2}{\mu(x)}  \\
            &= \sum_{x} \frac{\delta(x)^2}{\mu(x)} \left( \sum_y \frac{\delta(x,y)^2}{\delta(x)^2 \mu(y|x)} - 1 \right). \numberthis\label{line:beforabs}
    \end{align*}

    Now consider another discrete measure $|\delta|$, whose value at each component is the absolute value of the value of $\delta$ at that component, i.e., $|\delta|(x,y) := |\delta(x,y)|$.
    By construction, $|\delta|$ is now an unnormalized probability measure: $|\delta| = k q(X,Y)$, where $k = \sum_{x,y}|\delta(x,y)| > 0$ and $q \in \Delta\V(X,Y)$.

    Note also that $|\delta|(x)^2 = (\sum_{y} |\delta(x,y)|)^2 \ge (\sum_{y} \delta(x,y))^2$, and strictly so if there are $y,y'$ such that $\delta(x,y) < 0 < \delta(x,y')$.
    In other words, the vector $\bdelta_x = [\delta(x,y)]_{y \in \V Y}$ is either non-negative or non-positive: $\bdelta_x \ge 0$ or $\bdelta_x \le 0$ for each $x$.
     Meanwhile, $|\delta|(x,y)^2 = \delta(x,y)^2$ is unchanged.
    Thus, for every $x \in \V X$, we have:
    \begin{align*}
        \sum_y \frac{\delta(x,y)^2}{\delta(x)^2 \mu(y|x)} - 1
        &\ge \sum_y \frac{|\delta|(x,y)^2}{|\delta|(x)^2 \mu(y|x)} - 1 \\
        &= \sum_y \frac{k^2 q(x,y)^2}{k^2 q(x)^2 \mu(y|x)} - 1 \\
        &= \sum_y \frac{ q(y|x)^2}{\mu(y|x)} - 1   \\
        &= \chi^2 \Big( q(Y|x) \Big\Vert  \mu(Y|x) \Big) \ge 0.
    \end{align*}
    The final line depicts the $\chi^2$ divergence between the distributions $q(Y|x)$ and $\mu(Y|x)$, both distributions over $Y$.  Since it is a divergence, this quantity is non-negative and equals zero if and only if $q(Y|x)=\mu(Y|x)$.

    Picking up where we left off, we have:
    \begin{align*}
        \bdelta^{\sf T} \mat H(\mu) \bdelta
            &= \sum_{x} \frac{\delta(x)^2}{\mu(x)} \left( \sum_y \frac{\delta(x,y)^2}{\delta(x)^2 \mu(y|x)} - 1 \right) \\
            &\ge \sum_{x} \frac{\delta(x)^2}{\mu(x)} \left( \sum_y \frac{|\delta|(x,y)^2}{|\delta|(x)^2 \mu(y|x)} - 1 \right) \\
            &=
            \sum_{x} \frac{\delta(x)^2}{\mu(x)}
            \chi^2 \Big( q(Y|x) \Big\Vert  \mu(Y|x) \Big) \ge 0.
    \end{align*}
    As a non-negatively weighted sum of non-negative numbers, this final quantity is non-negative, and equals zero if and only if, for each $x \in \V X$, we have either $q(Y|x) = \mu(Y|x)$, or $\delta(x) = 0$.
    Furthermore, if $\bdelta^{\sf T} \mat H(\mu) \bdelta = 0$, then \emph{both} inequalities hold with equality. Therefore, we know that if $\delta(x) \ne 0$, then $\bdelta_x \ge \mat 0$ or $\bdelta_x \le \mat 0$.
    These two conditions are also sufficient to show that $\bdelta^{\sf T} \mat H(\mu) \bdelta = 0$.
    To summarize what we know so far:
    \begin{align*}
        \bdelta^{\sf T} \mat H(\mu) \bdelta = 0
            \quad\iff\quad\forall x \in \V\!X.\quad
                \text{either}&~~  (\bdelta_x \ge \mat 0 \text{ or } \bdelta_y \le \mat 0) \text{~~and~~ $|\delta|(Y|x) = \mu(Y|x),$}\\
                \text{or }&~~ \delta(x) = 0.
    \end{align*}

    The second possibility, however, is a mirage: it cannot occur.
    Let's now return to the expression we had in \eqref{line:beforabs} before considering $|\delta|$.
    We've already shown that the contribution to the sum at each value of $x$ is non-negative, so if $\bdelta^{\sf T} \mat H(\mu) \bdelta$ is equal to zero, each summand which depends on $x$ must be zero as well.
    So if $x$ is a value of $X$ for which $\delta(x) = 0$, then
    \begin{align*}
        0 = \frac{1}{\mu(x)} \left( \sum_y \frac{\delta(x,y)^2}{\mu(y|x)} - \delta(x)^2 \right)
         = \frac{1}{\mu(x)} \sum_y \frac{\delta(x,y)^2}{\mu(y|x)}
         = \sum_y \frac{\delta(x,y)^2}{\mu(x,y)},
    \end{align*}
    which is only possible if $\delta(x,y) = 0$ for all $y$.
    This allows us to compute, more simply, that
    \begin{align*}
        \bdelta^{\sf T} \mat H(\mu) \bdelta = 0
        \quad&\iff\quad
            \begin{array}{c}
            (\forall x .~  \bdelta_x \ge \mat 0 \text{ or } \bdelta_x \le \mat 0)
            % \qquad\text{and}\qquad
            \\\text{and}\quad
            \forall (x,y) \in \V(X,Y).~~
                \delta(x,y) \mu(x) = \delta(x) \mu(x,y)
            \end{array}
        \end{align*}

    % \medskip
    % \hrule
    % \medskip

    Finally, we are in a position to prove the lemma.
    Suppose that $\mu_0,\mu_1 \in \Delta\V(X,Y)$ and $(x^*,y^*) \in \V(X,Y)$
    are such that $\mu_0(x^*,y^*) \mu_1(x^*)  \ne \mu_1(x^*,y^*) \mu_0(x^*)$.
    So, the quantity
    \[
        \mathit{gap} := \mu_1(x^*,y^*) \mu_0(x^*) - \mu_0(x^*,y^*) \mu_1(x^*)
        \quad\text{is nonzero}.
    \]
    Then for all $t \in (0,1)$ the intermediate point $\mu_t = (1-t)\, \mu_0 + t\, \mu_1$ must have different conditional marginals from both $\mu_0$ and $\mu_1$, as
    \begin{align*}
        &\mu_t(x^*\!,y^*)\mu_0(x^*) - \mu_0(x^*\!\!,y^*) \mu_t(x^*) \\
            &= \Cancel[red]{(1{-}t)\mu_0(x^*\!,y^*\!)\mu_0(x^*)} + t \mu_1(x^*\!\!,y^*)\mu_0(x^*)
                - \!\Cancel[red]{(1{-}t)\mu_0(x^*\!\!,y^*\!) \mu_0(x^*)} - t\mu_0(x^*\!\!,y^*\!) \mu_1(x^*) \\
            &= t \pqty[\big] { \mu_1(x^*\!\!,y^*)\mu_0(x^*) -\mu_0(x^*\!\!,y^*) \mu_1(x^*)}
            \\
            &=~ t \cdot \mathit{gap}
            ~\ne~ 0,
    \end{align*}
    and analogously for $\mu_1$,
    \begin{align*}
        &\mu_t(x^*\!\!,y^*)\mu_1(x^*) - \mu_1(x^*\!\!,y^*) \mu_t(x^*) \\
            &= (1-t)\mu_0(x^*\!\!,y^*)\mu_1(x^*) + \!\Cancel[red]{t \mu_1(x^*\!\!,y^*\!)\mu_1(x^*\!) }
                -  (1-t)\mu_1(x^*\!\!,y^*) \mu_0(x^*) - \!\Cancel[red]{t\mu_1(x^*\!\!,y^*\!) \mu_1(x^*\!) } \\
            &= (1-t) (\mu_0(x^*,\!\!y^*)\mu_1(x^*) -\mu_1(x^*\!\!,y^*) \mu_0(x^*))
            \\
            &=~ -(1-t) \cdot \mathit{gap}
            ~\ne~ 0.
    \end{align*}

    Then for any direction $\delta := k(\mu_0 - \mu_1)$ parallel to the segment between $\mu_0$ and $\mu_1$ (intuitively a tangent vector at $\mu_t$, although this fact doesn't affect the computation), of nonzero length ($k\ne 0$), we have:
    \begin{align*}
        &
        \mu_t(x^*\!,y^*) \delta(x^*)  - \delta(x^*\!,y^*) \mu_t(x^*)
        \\
        &= k\; \mu_t(x^*\!,y^*) \pqty[\big]{\mu_0(x^*) - \mu_1(x^*)}  - k\; \pqty[\big]{\mu_0(x^*\!,y^*)-\mu_1(x^*\!,y^*)} \mu_t(x^*) \\
        &= k \pqty[\Big]{\mu_t(x^*\!,y^*)\mu_0(x^*) - \mu_t(x^*\!,y^*)\mu_1(x^*)
            -\mu_0(x^*\!,y^*)\mu_t(x^*) + \mu_1(x^*\!,y^*)\mu_t(x^*)} \\
        &= k \pqty[\Big]{ \pqty[\big]{ \mu_t(x^*\!,y^*)\mu_0(x^*) -\mu_0(x^*\!,y^*)\mu_t(x^*)} + \pqty[\big]{\mu_1(x^*\!,y^*)\mu_t(x^*) - \mu_t(x^*\!,y^*)\mu_1(x^*)}} \\
        &= k \pqty[\big]{ + t \,\mathit{gap} + (1-t) \,\mathit{gap}} \\
        &= k \,\mathit{gap} \qquad \ne~ 0.
    \end{align*}

    So at every $t$, directions parallel to the segment are not in the null space of $\mat H(\mu_t)$, meaning that
    $\bdelta^{\sf T} \mat H(\mu_t) \bdelta > 0$ and so our function is strictly convex along this segment.
\end{lproof}



\recall{prop:joint+idef-correct}
\begin{lproof}\label{proof:joint+idef-correct}
    Suppose that $(-\mat u, \mu, \mat k)$ is a solution to problem \eqref{prob:joint+idef}.
    The second constraint, by \cref{prop:marginonly}, ensures that $\mu \in \bbr{\dg M}_0^*$.
    Then
    \begin{align*}
        (-\mat u, \mu, \mat k) \in K^{\V\!\X}
        \quad\implies\quad
            \forall w \in \V\!\X.~ u_w &\ge \mu(w) \log \frac{ \mu(w) } { k_w } \\
            &=  \mu(w) \log \pqty[\bigg]{ \faktor{\mu(w)~}{~\prod_{a \in \Ar}\mu(\Tgt a(w)|\Src a(w))^{\alpha_a}}}.
    \end{align*}
    The same logic as in the
    \hyperref[proof:joint-inc-correct]{proofs}
    \hyperref[proof:joint-small-gamma-correct]{of}
    \cref*{prop:joint-inc-correct,prop:joint-small-gamma-correct}
    shows that this inequality must be tight, or else
    $(-\mat u, \mu, \mat k)$ would not be optimal for \eqref{prob:joint+idef}.
    So, $\mat u$ is a function of $\mu$.  Also, by \cref{prop:idef-frozen}, the problem objective satisfies
    \[
        \mat 1^{\sf T}\mat u = \sum_{w \in \V\!X} u_w = \SDef_{\dg M}(\mu).
    \]

    Finally, because $\mu$ is optimal, it must be the unique distribution
    $\bbr{\dg M}^*$, which among those distributions that minimize $\OInc_{\dg M}$, also minimizes $\SDef_{\dg M}$, meaning $\mu = \bbr{\dg M}^*$.
\end{lproof}



\recall{prop:cluster-inc-correct}
\begin{lproof}\label{proof:cluster-inc-correct}
    The final constraints alone are enough to ensure that $\bmu$ is calibrated.
    Much like before, the exponential conic constraints tell us that
    \[
        \forall (a, s,t) \in \V\!\Ar.\quad
            u_{a,s,t} \ge \mu_{C_{\!a}}\!(s,t) \log \frac{\mu_{C_{\!a}}\!(s,t)}{\mu_{C_{\!a}}\!(s)\p_a(t|s)}
    \]
    and they hold with equality (at least at those indices where $\beta_a > 0$) because $\mat u$ is optimal.
    So
    \begin{align*}
        \sum_{(a,s,t) \in \V\!\Ar} \beta_a u_{a,s,t}
        &= \sum_{(a,s,t) \in \V\!\Ar} \beta_a \mu_{C_{\!a}}\!(s,t) \log \frac{\mu_{C_{\!a}}\!(s,t)}{\mu_{C_{\!a}}\!(s)\p_a(t|s)} \\
        &= \sum_a \beta_a \sum_{(s,t) \in \V a}\mu_{C_{\!a}}\!(s,t) \log \frac{\mu_{C_{\!a}}\!(s,t)}{\mu_{C_{\!a}}\!(s)\p_a(t|s)} \\
        &= \OInc_{\dg M}(\Pr\nolimits_{\bmu}).
    \end{align*}
    Because $\bmu$ is optimal, it is the choice of \cactree\ that minimizes this quantity.
    By \cref{coro:can-use-cliquetree}, the distribution $\bbr{\dg M}^*$ can be represented by such a \actree, and by 
    % \textcite[Prop. 3.4]{pdg-aaai},
    \cref{prop:consist}
    this distribution minimizes $\OInc_{\dg M}$.
    All this is to say that there exist \actree s of this form whose corresponding distributions attain the minimum value $\OInc_{\dg M}(\Pr_{\bmu}) = \aar{\dg M}_0$.
    So $\bmu$ must be one of them, as it minimizes $\OInc(\Pr_{\bmu})$ among such \actree s by assumption. Thus $\Pr_{\bmu} \in \bbr{\dg M}^*_0$ and the objective value of \eqref{prob:cluster-inc} equals $\aar{\dg M}_0$.
\end{lproof}

\recall{prop:cluster-small-gamma-correct}

\begin{lproof}\label{proof:cluster-small-gamma-correct}
    Suppose that $(\bmu, \mat u, \mat v)$ is a solution to \eqref{prob:cluster-small-gamma}.
    The first and fourth lines of constraints ensures that $\bmu$ is indeed a \cactree.  The second line of constraints, plays exactly the same role that it did in the previous problems, most directly in the variant \eqref{prob:cluster-inc} for $\gamma=0$. In particular, it tells says
    \[
        \forall (a, s,t) \in \V\!\Ar.\quad
            u_{a,s,t} \ge \mu_{C_{\!a}}\!(s,t) \log \frac{\mu_{C_{\!a}}\!(s,t)}{\mu_{C_{\!a}}\!(s)\p_a(t|s)}
    \]
    as before, this holds with equality (at least at those indices where $\beta_a > \alpha_a\gamma$) because $\mat u$ is optimal.
    Because $\bbeta \ge \gamma \alpha$ by assumption, either $\beta_a > \gamma \alpha_a$ or the two are equal, for every $a \in \Ar$. Either way,
    the argument used at this point in \hyperref[proof:cluster-inc-correct]{the proof of} \cref{prop:cluster-inc-correct} goes through, giving us:
    \begin{align*}
        \sum_{(a,s,t) \in \V\!\Ar} (\beta_a - \alpha_a\gamma) u_{a,s,t}
        &= \sum_{(a,s,t) \in \V\!\Ar} ((\beta_a - \alpha_a\gamma) \mu_{C_{\!a}}\!(s,t) \log \frac{\mu_{C_{\!a}}\!(s,t)}{\mu_{C_{\!a}}\!(s)\p_a(t|s)} \\
        &= \sum_a (\beta_a - \alpha_a\gamma) \sum_{(s,t) \in \V a}\mu_{C_{\!a}}\!(s,t) \log \frac{\mu_{C_{\!a}}\!(s,t)}{\mu_{C_{\!a}}\!(s)\p_a(t|s)} \\
        &= \sum_a (\beta_a - \alpha_a\gamma)~
            \kldiv[\Big]{\mu_{C_{\!a}}\!(\Src a, \Tgt a)}
                  {\mu_{C_{\!a}}\!(\Src a)\, \p_a(\Tgt a|\Src a)}
    \end{align*}
    This time, though, that's not the problem objective. In this regard, our problem \eqref{prob:cluster-small-gamma} is more closely related to \eqref{prob:cluster-small-gamma}.

    Before we get to that, we have to first bring in the final collection of exponential constraints, which show that
    \begin{align*}
        \forall C \in \C.~ \forall c \in \V(C).\quad
            v_{C,c} \ge \mu_{C}(c) \log \frac{\mu_C(c)}{ \Pash_C(c) },
    \end{align*}
    and yet again these constraints hold with equality,
    for otherwise $\mat v$ would not be optimal (since we assumed $\gamma > 0$). Therefore,
    \[
        \sum_{\mathclap{(C,c) \in \V\C}} v_{C,c}
        ~=~
        \sum_{\mathclap{(C,c) \in \V\C}}
        \mu_{C}(c) \log \frac{\mu_C(c)}{ \Pash_C(c) }
        ~=~ - \H(\Pr\nolimits_{\bmu})\quad\text{by \cref{eq:cluster-ent-decomp}}.
    \]

    The objective of our problem \eqref{prob:cluster-small-gamma} is essentially the same as that of \eqref{prob:joint-small-gamma}, so the analysis in \hyperref[proof:joint-small-gamma-correct]{the proof of} \cref{prop:joint-small-gamma-correct} applies with only a handful of superficial modifications.
    Using that proof to take a shortcut, the objective of \eqref{prob:cluster-small-gamma} must equal
    \begin{align*}
        &\sum_{\mathclap{(a,s,t) \in \V\!\Ar}}
            (\beta_a \!- \alpha_a \gamma) u_{a,s,t}
        ~+ \gamma \sum_{\mathclap{(C,c) \in \V\C}} v_{C,c}
        ~- \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}}
            \alpha_a\gamma \, \mu_{C_{\!a}}\!(s,t) \log \p_a (t|s) \\
    &=
        \sum_{\mathclap{(a,s,t) \in \V\!\Ar}}
             (\beta_a - \alpha_a\gamma) \mu_{C_{\!a}}\!(s,t) \log \frac{\mu_{C_{\!a}}\!(s,t)}{\mu_{C_{\!a}}\!(s)\p_a(t|s)}
        ~-~ \gamma \H(\Pr\nolimits_{\bmu})
        ~-~ \sum_{\mathrlap{\!\!\!(a,s,t) \in \smash{\V\!\Ar^+}}}
            \alpha_a\gamma \, \mu_{C_{\!a}}\!(s,t) \log \p_a (t|s) \\
    &=
        \sum_{a \in \Ar} \beta_a
           \Ex_{\mu_{C_{\!a}}}[ \log \p_a(\Tgt a | \Src a)]
        + \sum_{a \in \Ar} (\alpha_a \gamma \!-\! \beta_a)
           \H_{\Pr_{\bmu}}(\Tgt a | \Src a)
        - \gamma \H(\Pr_{\bmu})  \\
    &= \bbr{\dg M}_\gamma(\Pr\nolimits_{\bmu}),
    \quad.
    \end{align*}
    Finally, since $\bmu$ is such that this quantity is minimized, and because
    its unique minimizer can be represented as a cluster tree (by \cref{coro:can-use-cliquetree}), we conclude that $\bmu$ must be the cluster tree representation of it.
    Therefore, $\Pr_{\bmu}$ is the unique element of $\bbr{\dg M}^*_\gamma$, and the objective at $(\bmu, \mat u, \mat v)$ equals $\aar{\dg M}_\gamma$, as desired.
\end{lproof}

\recall{prop:cluster-idef-correct}
\begin{lproof}\label{proof:cluster-idef-correct}
    Suppose that $(\bmu, \mat u)$ is a solution to \eqref{prob:cluster+idef}.
    The exponential cone constraints state that
    \begin{align*}
        \forall C \in \C.~ \forall c \in \V(C).\quad
        u_{C,c} &\ge \mu_{C}(c) \log \frac{\mu_C(c)}{k_{C,c} \Pash_C(c) } \\
        &= \mu_{C}(c) \log \frac{\mu_C(c)}{\Pash_C(c)}
            - \mu_{C}(c) \log \prod_{a \in \Ar_C} \nu_C (\Tgt a (c) | \Src a (c))^{\alpha_a} \\
        &= \mu_{C}(c) \log \frac{\mu_C(c)}{\Pash_C(c)}
         - \mu_{C}(c) \sum_{a \in \Ar_C} \alpha_a \log \nu_C (\Tgt a (c) | \Src a (c)),
    \end{align*}
    and once again this holds with equality, as each $u_{C,c}$ is minimal with this property.
    The third line of constraints
    \[
        \forall a \in \Ar.~~\mu_{C_{\!a}}\!(\Src a, \Tgt a) \nu_{C_{\!a}}\!(\Src a) = \mu_{C_{\!a}}\!(\Src a) \nu_{C_{\!a}}\!(\Src a, \Tgt a)
    \]
    and the assumption that $\Pr_{\boldsymbol\nu} \in \bbr{\dg M}^*_0$, suffice to ensure that $\Pr_{\bmu} \in \bbr{\dg M}^*_0$ by \cref{prop:marginonly}.
    They also allow us to replace each $\nu_{C_{a}}(\Tgt a(c) | \Src a (c))$ with
    $\nu_{C_{a}}(\Tgt a(c) | \Src a(c))$, in cases where $\Src a(c) \ne 0$.
    Therefore, we calculate the objective to be:
    \begin{align*}
        &\mat 1^{\sf T} \mat u =
        \sum_{C \in \C} \sum_{c \in \V(C)} \left( \mu_{C}(c) \log \frac{\mu_C(c)}{\Pash_C(c)} -
            \mu_{C}(c) \sum_{a \in \Ar_C} \alpha_a \log \nu_C (\Tgt a (c) | \Src a (c))
            \right)\\
        &= \sum_{C \in \C} \sum_{c \in \V(C)}
                \mu_{C}(c) \log \frac{\mu_C(c)}{\Pash_C(c)}
            - \sum_{C \in \C} \sum_{c \in \V(C)}
            \mu_{C}(c) \sum_{a \in \Ar} \mathbbm1[C = C_a] \alpha_a \log \nu_C (\Tgt a (c) | \Src a (c)) \\
        &= -\H(\Pr\nolimits_{\bmu}) - \sum_{a \in \Ar} \alpha_a \sum_{C \in \C} \mathbbm1[C = C_a] \sum_{c \in \V(C)}
            \mu_{C}(c)\log \nu_C (\Tgt a (c) | \Src a (c))
            \qquad\big[\,\text{by \eqref{eq:cluster-ent-decomp}}\,\big]\\
        &= -\H(\Pr\nolimits_{\bmu}) - \sum_{a \in \Ar} \alpha_a \sum_{c \in \V(C)_a}
                \mu_{C_{\!a}}\!(c) \log  \nu_{C_{\!a}}\! (\Tgt a (c) | \Src a (c)) \\
        &= -\H(\Pr\nolimits_{\bmu}) - \sum_{a \in \Ar} \alpha_a \sum_{c \in \V(C)_a}
                \mu_{C_{\!a}}\!(c) \log { \mu_{C_{\!a}}\! (\Tgt a (c) | \Src a (c))}
            ~~\quad\bigg[~\parbox{3.8cm}{\singlespacing since $\mu_{C_{\!a}}\!(\Src a(c)) > 0$ whenever
                $\mu_{C_{\!a}}\!(c) > 0$}~\bigg]\\
        &= -\H(\Pr\nolimits_{\bmu}) + \sum_{a \in \Ar} \alpha_a \H_{\Pr_{\bmu}}(\Tgt a | \Src a ) \\
        &= \SDef_{\dg M}(\Pr\nolimits_{\bmu}).
    \end{align*}

    To summarize: $\Pr_{\bmu}$ minimizes $\SDef_{\dg M}(\Pr\nolimits_{\bmu})$ among \cactree s with conditional marginals matching those of $\boldsymbol\nu$.
    Since we know that there is a unique distribution that minimizes $\SDef_{\dg M}$ among the elements $\bbr{\dg M}_0^*$, and also that this distribution can be represented by a \actree\ (by \cref{coro:can-use-cliquetree}), we conclude that $\bmu$ must represent this distribution. Thus, $\Pr_{\bmu} = \bbr{\dg M}^*$ as desired.
\end{lproof}

The next lemma packages the results of \textcite{dahl2022primal,nesterov1996infeasible} in a precise form that we will be able to make use of.

\begin{lemma} \label{lem:mainlemma}
    Fix integers $n_{\sf o}, n_{\sf e} \in \mathbb N$, and let $n:= 3n_{\sf e} + n_{\sf o}$.
     Suppose that
     $K = \mathbb R_{\ge 0}^{n_{\sf o}} \times K^{n_{\sf e}}_{\exp} \subset \mathbb R^n$ is a product cone, consisting of $n_{\sf o}$ copies of the non-negative orthant and $n_{\sf e}$ copies of the exponential cone.
    Let
    $\mat c \in [-1,1]^{n}$ and $ \mat b \in [-1,1]^m$
    be vectors, and $A \in [-1,1]^{m \times n}$
    be a matrix, defining
    an exponential conic program
    \begin{align*}
        &
        \minimize_{
            \mat x \in K}~~ \mat c^{\sf T} \mat x
        \quad\subjto\quad A \mat x = \mat b,
        \tag{\ref{eq:exp-conic-program}}
        .
    \end{align*}
    If this program
    is strictly feasible (i.e., if there exists $\mat x \in \mathrm{int}\, K$  such that $A \mat x = \mat b$),
    as is its dual problem
    \[
        \maximize
            \limits_{
            \mat s \in K^*,\, \mat y \in \Rext^m} ~~ \mat b^{\sf T} \mat y
        \quad\subjto\quad  A^{\sf T} \mat y  +  \mat s = \mat c,
    \]
    (i.e, if there exists $\mat s \in \mathrm{int}\,K_*$ such that $A^{\sf T} \mat y + \mat s = \mat c$),
    then both
    can be simultaneously
    solved to precision $\epsilon$
    in $O(n (m+n)^{\omega} \log\frac{n+m}{\epsilon}
    )$ time,
    where $\omega$ is the smallest exponent such that a linear system of $k$ variables and equations can be solved in $O(k^\omega)$ time.
    Furthermore, MOSEK solves this problem in $O(n (m+n)^3 \log \frac{n+m}{\epsilon})$ time.
\end{lemma}
\begin{lproof}
    For this, we begin by appealing to the algorithm and analysis of
    \textcite{badenbroek2021algorithm}, threading details through for this specific choice of cone $K$.
    To finish the proof, however, we will also need to supplement that analysis with some other well-established results of \textcite{nesterov1996infeasible} that the authors were no doubt familiar with, but did not bother referencing.

    First, we'll need some background material from convex optimization.
    A \emph{logarithmically homogeneous self-concordant barrier} with parameter $\nu$ ($\nu$-LHSCB) for a cone $K$ is a thrice differentiable strictly convex function $F: \mathrm{int}\, K \to \mathbb R$ satisfying
    $F(tx) = F(x) - \nu \log t$
    for all $t > 0$ and $x \in \mathrm{int}\, K$.
    In some sense, the point of such a barrier function is to augment the optimization objective so that we remain within the cone during the optimization process.


    For the positive orthant cone $\mathbb R_{\ge 0}$, the function
        $x \mapsto - \log x$ is a 1-LHSCB.
    We now fill in some background facts about exponential cones.
    The \emph{dual} of the exponential cone is
    \begin{align*}
        K_{\exp}^* &:= \big\{ (s_1, s_2, s_3) \in \mathbb R^3 \;:\;
            \forall (x_1, x_2, x_3) \in K_{\exp}.~~
            x_1 s_1 + x_2 s_2 + x_3 s_3 \ge 0   \big\}\\
            &= \big\{
                (s_1, s_2, s_3) \;:\; - s_1 \log (- s_1 / s_3) + s_1 - s_2 \le 0,
                    \, s_1 \le 0,\,  s_3 \ge 0
            \big\}.
    \end{align*}
    Consider points $x = (x_1, x_2, x_3) \in K_{\exp}$.
    The function
    \begin{equation}
        F_{\exp}(x) := - \log \Big(x_2 \log\frac{x_1}{x_2} - x_3\Big) - \log x_1 x_2
    \end{equation}
    is a $3$-LHSCB for $K_{\exp}$, since
    \begin{align*}
        F_{\exp}(t x) &=
            -\log \Big( t x_2 \log \frac{t x_1}{t x_2} - t x_3\Big) - \log(t^2 x_1 x_2) \\
        &= - \log \Big(t \big(\log \frac{x_1}{x_2} - x_3\big)\Big) - \log(x_1 x_2) - 2 \log t \\
        &= F_{\exp}(x) - 3 \log t
    \end{align*}
    Such barrier functions can be combined to act on product cones by summation.
    Concretely, suppose that for each $i \in \{1, \ldots, k\}$,
    we have a $\nu_i$-LHSCB $F_i: \mathrm{int}\, K_i \to \Rext$.
    For $x = (x_i)_{i=1}^k \in \prod_i K_i$, the function
    $F(x) := \sum_{i=1}^k F_i(x_i)$ is a $(\sum_i \nu_i)$-LHSCB for $\prod_i K_i$,
    since
    \[
        F(tx) = \sum_{i=1}^k F_i(t x_i)
            = \sum_{i=1}^k ( F(x_i) - \nu_i \log t)
            = F(x) - \sum_{i=1}^k \nu_i.
    \]
    In this way, our product cone $K = \mathbb R_{\ge 0}^{n_{\sf o}} \times K^{n_{\sf e}}_{\exp}$ admits a LHSCB $F$ with parameter $\nu = n_{\sf o} + 3 n_{\sf e} = n$.
    Furthermore it can be evaluated in $O(n)$ time, as can each component of
    its gradient $F'(x)$ and Hessian $F''(x) \in \mathbb R^{n \times n}$ at $x$, all of which can be expressed analytically.
    In addition, the convex conjugate of $F$
    also has a known analytic form.


    Generally speaking,
    the idea behind primal-dual interior point methods \parencite{nesterov1994book} such as the one behind MOSEK, is
    to maintain both a point $x \in K$ and a dual point $s \in K_*$ (as well as $y \in \mathbb R^m$)
    and iteratively update them, as we slowly relax the barrier and approach a point on the boundary of the cone.
    The quantity $\mu(z) := \nf{\langle s, x \rangle}{\nu} \ge 0$, called the complementarity gap, is a measure of how close the process is to converging.

    Because the initial points may not satisfy the constraints, instead
    the standard algorithms work with ``extended points'' $\bar x = (x, \tau)$ and $\bar s = (s, \kappa)$, for which the analogous complementarity gap is
    $\mu^{\sf e}(\bar x, \bar s) := (\langle x, s\rangle + \kappa\tau)/(\nu+1)$.
    Altogether, the data at each iteration may be summarized as a point $z = (y, x, \tau, s, \kappa) \in \mathbb R \times (K \times \mathbb R_{\ge 0}) \times (K_* \times \mathbb R_{\ge 0})$.
    The primary object of interest is then something called the \emph{homogenous self-dual} model.
    Originally due to \textcite{nesterov1996infeasible} and also used by others \parencite{skajaa2015homogeneous},
    it can be defined as a linear operator:
    \begin{align*}
        G
            &: \Rext^{m + 2n + 2} \to \Rext^{n + m + 1} \\
        G(y,x,\tau,s,\kappa)
            &:= \begin{bmatrix}
                0          &  A  &  -b \\
                -A^{\sf T} &  0  &  c \\
                b^{\sf T}  & -c^{\sf T} & 0
        \end{bmatrix}
        \begin{bmatrix}
            y \\ x \\ \tau
        \end{bmatrix}
        -
        \begin{bmatrix}
            0 \\ s \\k
        \end{bmatrix}.
    \end{align*}
    The reason for our interest is that if $z$ is such that $G(z) = 0$ and $\tau > 0$, then $(\nf x\tau)$ is a solution to the primal problem, and $\nf{(y,s)}{\tau}$ is a solution to the dual problem \parencite[Lemma 1]{skajaa2015homogeneous}, while if $G(z) = 0$ and $\kappa > 0$, then at least one of the two problems is infeasible.

    We now are in a better position to describe the algorithm.
    According to the MOSEK documentation \parencite{dahl2022primal},
        for the exponential cone,
            begins with an initial point
        \[
            \mat v := (1.291, 0.805, -0.828) \in (K_{\exp} \,\cap\, K_{\exp}^*)
        \]

        for this particular cone $K$,
    the algorithm begins at the initial point
    \begin{align*}
        z_0 &:= (y_0, x_0, \tau_0, s_0, \kappa_0) \\
        \qquad
                    \text{where}\quad
                x_0 &= s_0 = (\overbrace{\vphantom| 1, \ldots, 1}^{n_{\sf o} \text{ copies}},~
                    \overbrace{\vphantom|
                        \mat v, \ldots, \mat v}^{n_{\sf e}\text{ copies}})
                \in (\mathbb R_{\ge 0})^{n_{\sf o}} \times (K_{\exp} \,\cap\, K_{\exp}^*)^{n_{\sf e}}, \\
            \qquad
                y_0 &= \mat 0  \in \mathbb R^m,
            \quad
                \tau_0 = \kappa_0 = 1.
    \end{align*}

    \def\daff#1{\Delta {#1}^{\text{aff}}}
    \def\dcen#1{\Delta {#1}^{\text{cen}}}

    At each iteration, the first step is to predict a direction for which
    \textcite{badenbroek2021algorithm}
    compute a scaling matrix $W$.
    To describe it, we first need to define \emph{shadow iterates}
    \[
        \tilde x := -F'_*(s)
        \qquad \text{and} \qquad
        \tilde s := - F'(x).
    \]
    which are in a sense reflections of $s$ and $x$ across their barrier functions, and can be computed in in $O(n)$ time.
    The analogous notion of complementarity can then be defined as $\tilde \mu(z) := \nicefrac{\langle \tilde x, \tilde s \rangle}{\nu}$.
    The scaling matrix, which we do not interpret here, can then be calculated as:
    \begin{equation}
        W :=
            \mu F''(x) + \frac{s s^{\sf T}}{\nu \mu}
            - \frac{\mu \tilde s \tilde s^{\sf T}}{\nu}
            + \frac{(s- \mu\tilde s)(s-\mu\tilde s)^{\sf T}}
                    {(s-\mu\tilde s)^{\sf T} (x - \mu \tilde x) }
            - \frac{\mu [ F''(x) \tilde x - \tilde \mu \tilde s]
                [ F''(x) \tilde x - \tilde \mu \tilde s]^{\sf T}}
                { \tilde x^{\sf T} F''(x) \tilde x - \nu \tilde \mu^2}
        \label{eq:scalemat}
    \end{equation}
    Doing so requires $O(n^2)$ steps (although it may be parallelized).
    The first four terms clearly require $O(n^2)$ steps, since each one is an outer product resulting in a $n \times n$ matrix.
    The last term computes a matrix-vector product (which requires $O(n^2)$ steps), and computes an outer product with the resulting vector, which takes $O(n^2)$ steps as well.

    The next step involves finding a solution $\daff z = (\cdots)$
    to the system of equations
    \begin{subequations} \label{eqns:sys1}
    \begin{align}
        G(\daff z) &= -G(z) \\
        \tau \daff\kappa + \daff\tau &= - \tau \kappa \\
        W \daff x + \daff s &= -s.
    \end{align}
    \end{subequations}

    (\ref{eqns:sys1}a-c) describe a system of $(n + m + 1) + 1 + (n) = 2n + m + 2$ equations and equally many unknowns,
    and solved in $O((n+m)^\omega)$ steps.
    It may be possible to exploit the sparsity of $G$ to do better.

    The next step is to center that search direction so that it lies on the central path. This is done by finding a solution $\dcen z$ to
    \begin{subequations}\label{eqns:sys2}
    \begin{align}
        G(\dcen z) &= G(z) \\
        \tau \dcen \kappa + \kappa \dcen \tau &= \mu^e \\
        W \dcen x + \dcen s &= \mu^e \tilde s,
    \end{align}
    \end{subequations}
    which again can be done in $O((n+m)^3)$ steps with Gaussian elimination, or
    with a fancier solver in $O((n+m)^2.332)$ steps.
    The two updates are then applied to the current point $z$ to obtain
    \[
        z_+ = (y_+, x_+, \tau_+, s_+, \kappa_+) := z + \alpha (\daff z + \gamma \dcen z).
    \]

    Finally, a ``correction step'', which is the primary innovation of \textcite{badenbroek2021algorithm} and used in MOSEK's algorithm,
    is a third direction $\Delta z_+^{\text{cor}}$, which is found by solving the system of equations
    \begin{subequations}\label{eqns:sys3}
    \begin{align}
        G(\Delta z^{\text{cor}}) &= 0 \\
        \tau_+ \Delta \kappa^{\text{cor}}  + \kappa_+ \Delta \tau^{\text{cor}} &= 0 \\
        W_+ \Delta {x_+}^{\text{cor}} + \dcen s &= \mu^e \tilde s,
    \end{align}
    \end{subequations}
    where
    $W_+$ is defined the same way that $W$ is, except that it uses the components of $z_+$ instead of $z$.
    After adding the correction step $\Delta z_+^{\text{cor}}$ to $z$, we repeat the entire process. The full algorithm, then, is
    % summarized as follows:
    given by \cref{algo:dahl-primal-dual} below. 

    \begin{algorithm}
        \caption{~[\citeauthor*{badenbroek2021algorithm}]}
        \label{algo:dahl-primal-dual}
        \singlespacingplus
    \begin{algorithmic}
        \STATE $z \gets (y_0, x_0, \tau_0, s_0, \kappa_0)$;
        \WHILE{}
            \STATE Compute scaling matrix $W$ as in \eqref{eq:scalemat};
            \STATE Find the solution $\daff z$ to (\ref{eqns:sys1}a-c),
                and the solution $\dcen z$ to (\ref{eqns:sys2}a-c);
            \STATE $z_+ \gets z + \alpha (\daff z + \gamma \dcen z)$;
            \STATE Compute the scaling matrix $W_+$;
            \STATE Find the solution $\Delta z^{\text{cor}}_+$ to (\ref{eqns:sys3}a-c);
            \STATE $z \gets z_+ + \Delta z_+^{\text{cor}}$;
        \ENDWHILE
    \end{algorithmic}
    \end{algorithm}

    We have verified that each iteration of this process can be done in $O((n+m)^\omega))$ time.
    Their main result \parencite[Theorem 3]{badenbroek2021algorithm}, states that for every $\epsilon \in (0,1)$,
    the algorithm results in a solution $z$ satisfying
    \[
        \mu^{\sf e}(z)
        \le \epsilon
        \qquad \text{and}\qquad
        \Vert G(z) \Vert \le \epsilon
            \Vert G(z_0) \Vert
    \]
    in $O(n \log (1/\epsilon))$ iterations,
    for a total cost of
    $O(n (m+n)^3 \log (1/\epsilon) )$ time with Gaussian elimination, or
    $O(n (m+n)^{2.332} \log (1/\epsilon) )$ time using the linear solver with best
         known asymptotic complexity as of 2022 \cite{duan2022faster}.

    % \medskip
    % \hrule

    \paragraph{Verifying that the solution is approximately optimal.}
    What we have at this point is not quite enough: simply because the residual quantity $G(z)$ is approximately zero (so that we have approximately solved the homogenous model), does not mean that we've approximately solved the original problem.
    Specifically, it's entirely possible a priori that the parameter $\tau$ goes to zero at the same rate as everything else, and the quantity $(x/\tau)$ does not converge to a solution to the primal problem.
    To address this issue, we must also trace the analysis of the seminal work of \textcite{nesterov1996infeasible}, who use slightly different quantities, conflicting with the notation we have been using thus far.


    Following \textcite[pg. 231]{nesterov1996infeasible}, fix an initial point $z_0$, and let \emph{shifted feasible set}
    $\mathcal F := \{ z
        \in \mathbb R \times K \times \mathbb R_{\ge 0} \times K^* \times \mathbb R_{\ge 0}
        : G(z) = G(z_0)\}$
    be the collection of all points that have the same residual as $z_0$.
    \citeauthor*{nesterov1996infeasible} also refer to a complementary gap by $\mu(z)$ and define it identically, but the meaning of this parameter is different, because the set $\mathcal F$ on which it's defined is quite distinct from (if closely related to) the iterates of \citeauthor*{badenbroek2021algorithm}'s algorithm.
    In the service of clarity,
    will call this quantity $\mu^{\sf N}(z^{\sf N})$, for
    $z^{\sf N}
    = (y^{\sf N}, x^{\sf N}, \tau^{\sf N}, s^{\sf N}, \kappa^{\sf N})
    \in \mathcal F$.


    Although we made a point of emphasizing that the two are distinct,
    the actual relationship between them is straightforward.
    Let $z = (y, x,\tau, s, \kappa)$ be the final output of \textcite{badenbroek2021algorithm}.
    In proving their main theorem, they also prove that
    $G(z) = \epsilon G(z_0)$,  and $\mu^{\sf e}=\epsilon$;
    because $G$ is linear, we know that $G(\nf{z}{\epsilon}) = G(z_0)$.
    This means that $z^{\sf N}
    := \nf z\epsilon \in \mathcal F$.
    Therefore,
    \[
        \mu^{\sf N}(z^{\sf N} )
        = \frac{1}{\nu+1} \left( \left\langle\frac{s}{\epsilon}, \frac{x}{\epsilon}\right\rangle + \frac{\tau}{\epsilon} \frac{\kappa}{\epsilon} \right)
    = \frac{1}{\epsilon^2} \mu^{\sf e}(z) = \frac{1}{\epsilon}.
    \]
    So, roughly speaking, $\mu^{\sf N}$ and $\mu^{\sf e}$ are reciprocals.
    \citeauthor*{badenbroek2021algorithm} also
    prove that, every iterate $z$ satisfies their assumption (A2): for a fixed constant $\beta$ (equal to 0.9 in their analysis), $\beta \mu^{\sf e}(z) \le \tau \kappa$.
    Consequently,
    it happens that the same inequality holds with Nesterov's notation:
    \[
        \tau^{\sf N} \kappa^{\sf N} =
        \frac{\tau}{\epsilon} \frac{\kappa}{\epsilon}
            = \frac{\tau\kappa}{\epsilon^2} \ge \frac{\beta \epsilon}{\epsilon^2}
            = \frac\beta\epsilon = \beta \mu^{\sf N}
                (z^{\sf N}).
    \]
    This witnesses that $z^{\sf N} = \frac{z}{\epsilon}$ satisfies equation (81) of \citeauthor{nesterov1996infeasible}, which allows us to apply one of their main theorems, which addresses these issues.
    Supposing that the original problem is solvable,
    let $(x^*, s^*)$ be any solution to the primal and dual problems,
    and define the value $\psi := 1 + \langle s_0, x^*\rangle + \langle s^*, x_0 \rangle \ge 1$,
    which depends only on the problem and the choice of initialization.
    Then Theorem 1, part 1 of \citeauthor*{nesterov1996infeasible}, allows us to conclude that
    \[
        \frac{\kappa}{\epsilon}  \le \psi
        \quad\text{and}\quad
        \frac\tau\epsilon \ge \frac{\beta}{\epsilon\psi}
    \qquad\qquad \iff\qquad\qquad
        \kappa \le \epsilon\psi
        \quad\text{and}\quad \tau \ge \frac\beta\psi.
    \]
    Finally, the original theorem guarantees that
    $\Vert G(x) \Vert \le \epsilon \Vert G(z_0)\Vert$, meaning that
    \[
        \Big\Vert A \Big(\frac x\tau\Big) - b \Big\Vert \tau
        ~+~\Big\Vert A^{\sf T} \Big(\frac y\tau\Big) - \frac{s}\tau - c \Big\Vert \tau
        ~+~\Big\Vert b^{\sf T} \left(\frac{y}{\tau}\right) - c^{\sf T} \left(\frac{x}{\tau}\right) - \frac\kappa\tau \Big\Vert \tau \le \epsilon \Vert G(z_0) \Vert.
    \]
    Since the euclidean norm is an upper bound on the deviation in any component
    ( $\Vert v \Vert := \sqrt{\sum_i v_i^2} \ge \sqrt{\max_i v_i^2} = \max_i v_i =: \Vert v\Vert_\infty$ ), this means that in light of our bound on $\tau$ above, we have
    \[
        \Big\Vert A \Big(\frac x\tau\Big) - b \Big\Vert_\infty
        ~+~\Big\Vert A^{\sf T} \Big(\frac y\tau\Big) + \frac{s}\tau - c \Big\Vert_\infty
        ~+~\Big\Vert b^{\sf T} \left(\frac{y}{\tau}\right) - c^{\sf T} \left(\frac{x}{\tau}\right) - \frac\kappa\tau \Big\Vert_\infty
        \le \epsilon  \frac{\beta \Vert G(z_0) \Vert}{\psi }.
    \]
    The first two components show that the total constraint violation (in the primal and dual problems, respectively) is at most $\nicefrac{\epsilon\beta}{\psi} \Vert G(z_0) \Vert$.
    Meanwhile, the final component shows that the duality gap
    $\mathit{gap} = b^{\sf T} (\frac{y}{\tau}) - c^{\sf T} (\frac{x}{\tau})$,
    which is positive and an upper bound on the difference between the objective at $x/\tau$ and the optimal objective value, satisfies
    \[
        \mathit{gap}  \le \mathit{gap} + \frac\kappa\tau \le \frac{\epsilon \beta \Vert G(z_0) \Vert}{\psi}.
    \]
    Thus $x/\tau$ is an $(\epsilon \Vert G(z_0)\Vert)$-approximate solution to the original exponential conic problem.
    Since also $\psi \ge 1$, we may freely drop it to get a looser bound.
    All that remains is to investigate $\Vert G(z_0) \Vert$,
     the residual norm of the initial point
        chosen by the MOSEK solver, which equals:
    \[
        \Vert G(z_0) \Vert
        = \Vert A x_0 - b \Vert
            + \Vert A^{\sf T} y_0 + s_0 - c  \Vert
            + | c^{\sf T} x - b^{\sf T} y + 1 |.
    \]
    Making use of our assumption that every component of $A$, $b$, and $c$ is at most one, we find that
    \begin{align*}
        \Vert A x_0 - b \Vert^2
            &= \sum_j (\sum_i A_{j,i} (1.3)  - b_j)^2
            \le m (1.3n+1)^2 \in O(m n^2)
                &\subset O((m+n)^3)\\
        \Vert A^{\sf T}y_0 + s_0 - c \Vert^2
            &= \sum_i (\sum_j (A_{j,i})
            \le n (m + 2)^2 \in O(n m^2)
                &\subset O((m+n)^3) \\
        | c^{\sf T} x - b^{\sf T} y + 1 | ^2
            &\le (1.3n + m + 1)^2 \in O( (n+m)^2 )
                &\subset O((n+m)^3).
    \end{align*}
    Therefore, the residual of the initial point is
        $G(z_0) \in O((n+m)^{\nf32})$.

    To obtain a solution at most $\epsilon_0$ away from the true
    solution in any coordinate, we need to select $\epsilon$ small enough
    that the final output of the algorithm $z$ satisfies
    \[
        \epsilon \Vert G(z_0) \Vert  \le \epsilon_0
        \qquad\iff\qquad
        \frac1\epsilon \ge \frac1{\epsilon_0} \Vert G(z_0) \Vert
    \]
    It therefore suffices to choose
    $\frac{1}{\epsilon} \in O(\frac1{\epsilon_0} (n+m)^{\nf32})$,
    leading to $\log \frac{1}{\epsilon} = O( \log \frac{n+m}{\epsilon_0} ) )$
    iterations.
%
    Thus, we arrive at our total advertised asymptotic complexity of time
    \[
        O \Big( n (n+m)^\omega \log \frac{n+m}{\epsilon_0} \Big).
    \]

    In particular, to attain machine precision, we can fix
    $\epsilon_0$ to be the smallest gap between numbers representable
    (say with 64-bit floats, leading to $\epsilon_0 = 10^{-78}$ in the worst case), and omit the dependance on $\epsilon_0$ for the price of relatively
    small constant (78, for 64-bit floats).
\end{lproof}

Having combed through all of the details of the analysis of  \textcite{badenbroek2021algorithm} and \textcite{nesterov1996infeasible} for exponential
conic programs as we have defined them, we are ready to show that this algorithm solves the problems presented in \cref{sec:clique-tree-expcone} within polynomial time.

In the results that follow, we use the symbol $O_{\text{BP}}( \, \cdot \,)$ to describe the complexity under the \emph{bounded precision} assumption:  the numerical values of $(\balpha,\bbeta, \mathbb P)$ that describe the PDG, as well as $\gamma$, lie within a fixed range, e.g., are 64-bit floating point numbers.
Correspondingly, we use $\tilde O_{\text{BP}}(\,\cdot\,)$ to describe the complexity
under the same assumption, but hiding logarithmic factors for parameters on which the complexity also depends polynomially.

\begin{lemma}\label{lem:cluster-inc-polytime}
Problem \eqref{prob:cluster-inc} can be solved to $\epsilon$ precision in time
\[
    O\Big( (\V\!\Ar + \V\C)^{1 + \omega} ( \log \frac{|\V\!\Ar| + |\V\C|}{\epsilon}
        + \log \frac{\beta^{\max}}{\beta^{\min}} \Big)
    \quad \subset \quad
        \tilde O_{\text{BP}}
        \Big( |\V\!\Ar + \V\C|^4 \log \frac1\epsilon \Big),
\]
where $\beta^{\max} := \max_{a \in \Ar} \beta_a$ is the largest value of $\beta$,
 and $\beta^{\min}:= \min_{a \in \Ar} \{ \beta_a : \beta_a > 0\}$ is the smallest positive one.
\end{lemma}
\begin{lproof}
    Problem \eqref{prob:cluster-inc}
    can translated via the DCP framework to
    the following exponential conic program, which has:
    \begin{itemize}[label=$\blacktriangleright$]
    \item variables
        $x = (\mat u, \mat v, \mat w, \bmu) \in K_{\exp}^{\V\!\Ar} \times \mathbb R_{\ge 0}^{\V \C}$,
        where
        \begin{itemize}[label=\textbullet]
        \item $\mathbf{u, v,w} \in \Rext^{\V\!\Ar}$
            are all vectors over $\V\!\Ar$,
            that at index $\iota = (a,s,t) \in \V\!\Ar$, have
            components $u_\iota$, $v_\iota$, and $w_\iota$, respectively;
        \item
            $\bmu = [\mu_{C}(C{=}c)]_%
            {C \in \C,\,c \in\V(C)}
             \in \Rext^{\V \C}$ is a vector representation of a \actree\ over clusters $\C$;
    \end{itemize}

    \item constraints as follows:
        \begin{itemize}[label=\textbullet]
            \item
            two linear constraints for every $(a,s,t) \in \V\!\Ar$ to ensure that
            \begin{align*}
                v_{a,s,t} &= \mu_{C_{\!a}}\!(s,t)
                    \qquad\Big(~= \sum_{\bar c \in \V(C_a \setminus\{\Src a, \Tgt a\})}
                        \mu_{C_{\!a}}\!(\bar c, s, t) \Big) \\
                \qquad\text{and}\qquad
                w_{a,s,t} &= \mu_{C_{\!a}}\!(\Src a{=}s)\, \p_a(\Tgt a{=}t\mid\Src a{=}s)
                    \\
                    \Big(\text{or, more precisely, }& w_{a,s,t} = \p_a(\Tgt a{=}t\mid\Src a{=}s) ~~\sum_{\mathclap{\bar c \,\in\, \V(C_a \setminus\{\Src a\})}}~~
                        \mu_{C_{\!a}}\!(\bar c, s) ~~\Big);
            \end{align*}
            \item for every edge $(C\!{-}\!D) \in \cal T$, and every value $\omega \in \V(C \cap D)$ of the variables that clusters $C$ and $D$ have in common, a linear constraint
            \[
                \sum_{\bar c \in \V(C\setminus D)} \mu_C(\bar c, \omega)
                    =
                \sum_{\bar d \in \V(D \setminus C)} \mu_D(\bar d, \omega);
            \]
            \item and one constraint for each cluster $C \in \C$ to ensure that $\mu_{C}$ lies on the probability simplex, i.e.,
            \[
                \sum_{c \in \V(C)} \mu_C(c) = 1.
            \]
        \end{itemize}
    \end{itemize}

    Altogether this means that we have an exponential conic program in the form
    of \cref{lem:mainlemma}, with
        $n = 3|\V\!\Ar| + |\V\C|$ variables,
        and
        $m = 2 |\V\!\Ar| + |\V \mathcal T| +  |\C|$ constraints,
    where
    $\V\mathcal T = \{ (C\!{-}\!D, \omega) :  C\!{-}\!D \in \mathcal T, \omega \in \V(C\cap D)\}$.
    Since we can simply disregard variables whose value sets are singletons, we can assume $\V(C) > 1$; summing over all clusters yields $\V\C > |\C|$.
    At the same time, since $\V\mathcal T \le \V\C$,
    we have
    \[ m,n,(m + n) \in O(\V\!\Ar, + \V\C).  \]


    We now give the explicit construction of the data $(A, b,c)$ of the exponential conic program that \eqref{prob:cluster-inc} compiles to.
    The variables are indexed by tuples
    of the form $i = (\ell,a,s,t)$ for $(a,s,t) \in \V\!\Ar$ and $\ell \in \{u,v,w\}$,
    or by tuples of the form $(C,c)$, for $c \in \V(C)$ and $C \in \C$,
    while the
    constraints are indexed by tuples of the form
    $j = (\ell,a,s,t)$ for $(a,s,t) \in \V\!\Ar$ and $\ell \in \{v,w\}$,
    of the form $(C\!{-}\!D, \omega)$, for an edge $(C\!{-}\!D) \in \mathcal T$ and $\omega \in \V(C \cap D)$,
    or simply by $(C)$, the name of a cluster $C \in \C$.
    The problem data $A = [A_{j,i}],b = [b_j],c = [c_i]$ of this program are zero, except (possibly) for the
        components:
    \begin{align*}
        c_{(u,a,s,t)} &= \beta_a \\
        A_{(v,a,s,t), (C,c)} &=
        \mathbbm1[C {=} C_{a} ~\land~ \Src a(c) {=} s ~\land~ \Tgt a(c) {=} t] \\
        A_{(w,a,s,t), (C,c)} &=
           \p_a(\Tgt a{=}t\mid \Src a{=}s)
            \mathbbm1[C {=} C_a ~\land~ \Src a(c) {=} s] \\
        A_{(w,a,s,t), (w,a,s,t)} &= -1 \\
        A_{(v,a,s,t), (v,a,s,t)} &= -1 \\
        A_{(C\!{-}\!D, \omega),(C',c)} &= \mathbbm1[C{=}C'] - \mathbbm1[C'{=}D]\\
        A_{(C),(C,c)} &= 1 \\
        b_{(C)} &= 1,
    \end{align*}
    where $\mathbbm1[\varphi]$ is equal to 1 if $\varphi$ is true, and zero if $\varphi$ is false.
    We note that we can equivalently divide each $\beta_a$ by $\max_a \beta_a$ without affecting the problem,
    although this could affect the approximation accuracy by the same factor.
    Thus, we get another factor of
    \[
        \log ( \max \{1 \} \cup \{ \beta_a : a \in \Ar\} ) ~\subseteq~ O( \log (1 + \max_a \beta_a ) ).
    \]

    Finally, to find a point that is $\epsilon$-close (say, in 2-norm) to the limiting point $\mu^*$ on the central path, as opposed to simply one that for which the suboptimality gap is at most $\epsilon$, we can appeal to strong concavity of the objective function.
    (Conditional) relative entropy is 1-strongly convex, and each relative entropy term is scaled by $\beta_a$.
    Furthermore, we're only considering marginal conditional entropy, so this convexity may not hold in all directions.
    Still, if the next step direction $\delta$ is not far from the gradient (as is the case if the interior point method has nearly converged), then, in that direction, the objective will be at least ($\min_a \{ \beta_a : \beta_a > 0\}$)-strongly convex.
    Therefore, by multiplying the requested precision by an additional factor of $\min_a \{ \beta_a : \beta_a > 0\}$, we can guarantee that our point is $\epsilon$-close to $\mu^*$, and not just in complementarity gap.

    To summarize, applying \Cref{lem:mainlemma}, we find that we can solve problem \eqref{prob:cluster-inc} in time
    \begin{align*}
        O\Big( \big(|\V\!\Ar| + |\V\C|\big)^{1 + \omega} \Big( \log \frac{ |\V\!\Ar| + |\V\C| }{\epsilon} + \log \frac{\beta_{\max}}{\beta_{\min}} \Big) \Big)
        \quad
        \subset \tilde O_{BP}\Big( \big(|\V\!\Ar| + |\V\C| \big)^4 \log \frac1\epsilon\Big).
    \end{align*}
    The factor of $\log\frac{\beta_{\max}}{\beta_{\min}}$ can be treated as a constant under the bounded precision assumption.
\end{lproof}

We now quickly step through the analogous construction for problems \eqref{prob:cluster-small-gamma} and \eqref{prob:cluster+idef}, which
solve the $\zogamma$-inference problem, and $0^+$-inference, respectively.

\begin{lemma}\label{lem:smallgamma-polytime}
    Problem \eqref{prob:cluster-small-gamma} is solved to precision $\epsilon$ in time
    \begin{align*}
        &O\bigg( |\V\!\Ar + \V\C|^{1 + \omega} \Big( \log \frac{ |\V\!\Ar| + |\V\C|}{\epsilon} + \log(1+ \Vert\bbeta\Vert_\infty) + \log \log \frac{1}{p^{\min}} \Big) \bigg)
        \\&\quad
        \subset
        \quad
        \tilde O_{\text{BP}}\Big( |\V\!\Ar + \V\C|^4 \log\frac1\epsilon \Big)
    \end{align*}
    where $p^{\min}$ is the smallest nonzero probability in the PDG.
\end{lemma}
\begin{lproof}
    Problem \eqref{prob:cluster-small-gamma} has
    \begin{itemize}[label=$\blacktriangleright$]
    \item variables
        $x = (\mat u, \mat y, \mat w,\,\, \mat v, \bmu, \mat z)
        \in K_{\exp}^{\V\!\Ar} \times K_{\exp}^{\V \C}$
        where
        \begin{itemize}[label=\textbullet]
        \item
        $\mathbf{u,y,w} \in \Rext^{\V\!\Ar}$
            are all vectors over $\V\!\Ar$
            that at index $\iota = (a,s,t) \in \V\!\Ar$, have
            components $u_\iota$, $v_\iota$, and $w_\iota$, respectively;
        \item
        Meanwhile,
        $\mathbf{v,\bmu,z} \in \Rext^{\V\C}$
            are all vectors over $\V\C$
            which at index $(C,c)$, have
            components $v_{C,c}$, $\mu_C(c)$, and $z_{C,c}$, respectively.
            Once again, $\bmu = [\mu_{C}(C{=}c)]_%
            {C \in \C,\,c \in\V(C)}
             \in \Rext^{\V \C}$ is intended to be a vector representation of a \actree.
    \end{itemize}

    \item constraints as follows:
        \begin{itemize}[label=\textbullet]
            \item
            two linear constraints for each $(a,s,t) \in \V\!\Ar$, to ensure that
            \[
                y_{a,s,t} = \mu_{C_{\!a}}(s,t)
                \qquad\text{and}\qquad
                w_{a,s,t} = \mu_{C_{\!a}}\!(\Src a{=}s)\, \p_a(\Tgt a{=}t\mid\Src a{=}s),
            \]
            \item for every edge $(C\!{-}\!D) \in \cal T$, and every value $\omega \in \V(C \cap D)$ of the variables that clusters $C$ and $D$ have in common, a linear constraint
            \[
                \sum_{\bar c \in \V(C\setminus D)} \mu_C(\bar c, \omega)
                    =
                \sum_{\bar d \in \V(D \setminus C)} \mu_D(\bar d, \omega)
            \]
            \item for every $(a,s,t) \in \V\!\Ar^0$, a linear constraint
            that ensures
            \[
                0 = \mu_{C_a}\!(\Src a{=}s,\Tgt a{=}t)
                \qquad\Big(\quad
                   = ~~\sum_{\mathclap{\bar c \,\in\, \V(C \setminus \{\Src a, \Tgt a\})}} ~~ \mu_{C_a}(\bar c, s, t) \Big)
            \]

            \item a linear constraint for every value $c \in \V(C)$ of every cluster $C \in \C$, to ensure that
            \[
                z_{C,c} = \mu_C( \Pash_C(c) )
                    \qquad \Big(\quad=~~ \sum_{\mathclap{\bar c \,\in\, \V(C \setminus \Pash_C)}}~~
                        \mu_{C}(\bar c, \Pash_C(c)) ~~\Big)
            \]
            \item and one constraint for each cluster $C \in \C$ to ensure that $\mu_{C}$ lies on the probability simplex, i.e.,
            $
                \sum_{c \in \V(C)} \mu_C(c) = 1.
            $
        \end{itemize}
    \end{itemize}
    So in total, there are
    $n = |3 \V \!\Ar + 3 \V \C|$ variables,
    and
    $m = 2 |\V\!\Ar| + |\V \mathcal T| + |\V\!\Ar^0| + |\V \C| + |\C|$ constraints.
    The same arguments made in \cref{lem:cluster-inc-polytime} show that both $n,m \in O(|\V \!\Ar + \V \C|)$.

    Also like before, it is easy to see that the components of $A$ and $b$ are all at most 1.  However, we will need to rescale the objective $c$ in order for each of its components to be most 1. We can do this by dividing it by
    $\max \{ - \beta_a \log {p_a(t|s)} \}_{(a,s,t) \in \V\!\Ar} \cup \{ 1 \}$.

    Finally, to ensure that we have a solution that is $\epsilon$-close to the end of the central path, as opposed to one that is merely $\epsilon$-close in complementarity gap, we must appeal to convexity.
    As in the proof of \cref{lem:cluster-inc-polytime}, this amounts to reducing the target accuracy by a factor of the smallest possible coefficient of strong convexity, along the next step direction.
    In this case, the bound is simpler: because negative entropy is (unconditionally) 1-strongly convex, and since $\bbeta \ge \balpha \gamma$, the remaining terms are convex, this could be, at worst, $\frac1\gamma$.

    This gives rise to our result: problem \eqref{prob:cluster-small-gamma} can be solved in
    \begin{align*}
        O\left( |\V \!\Ar + \V \C|^{1+\omega}
            \left(\log \frac{|\V \!\Ar + \V \C|}{\epsilon} + \log \frac1\gamma \left(1 + \max_{(a,s,t) \in \V\!\Ar} \beta_a \log \frac{1}{\p_a(t|s)} \right) \right)  \right) \\
        \subset
        O\left( |\V \!\Ar + \V \C|^{1+ \omega}
        \left\{
            \log \frac{|\V \!\Ar + \V \C|}{\epsilon}+
            \log  \frac{\beta^{\max}}{\gamma} +
            \log\log \frac{1}{p^{\min}}
        \right\}
        \right) \\
        \subset
        \tilde O_{\text{BP}}\left( |\V \!\Ar + \V \C|^{1+ \omega}
        \Big(
            \log \frac{1}{\epsilon}
        \Big)
        \right)
    \end{align*}
    operations, where $p$ is the smallest nonzero probability in the PDG, and $\beta^{\max}$ is the largest confidence in the PDG larger than 1.
\end{lproof}

\begin{lemma}\label{lem:cluster+idef-polytime}
    Problem \eqref{prob:cluster+idef} is solved to precision $\epsilon$ in
    \[
        O\Big( |\V \C| |\V \!\Ar + \V \C|^{\omega}
            \log \frac{|\V \!\Ar + \V \C|}{\epsilon} \Big)
        \quad\subset\quad
        \tilde O_{\text{BP}}\Big( |\V \C + \V \! \Ar|^{4} \log\frac1\epsilon \Big) \text{~~time}.
    \]
\end{lemma}
\begin{lproof}
    Problem \eqref{prob:cluster+idef} is slightly more straightforward; having done
    \cref{lem:cluster-inc-polytime,lem:smallgamma-polytime} in depth, we do this one more quickly.
    In the standard form, problem \eqref{prob:cluster+idef}, has variables
    $x = (\mat u, \bmu, \mat w)
        \in K_{\exp}^{\V\C}$.
    The constraints  are:

    \begin{itemize}[label=\textbullet]
        \item
        one linear constraint for each $(C,c) \in \V\C$, to ensure that
        \[
            w_{C,c} = k_{(C,c)} \mu_C( \Pash_C(c) )
            \qquad\Big(~~= \sum_{\bar c \in \V(C\setminus \Pash_C )} \mu_C(\bar c, \Pash_C(c))
                \Big)
        \]
        \item for every edge $(C\!{-}\!D) \in \cal T$, and every value $\omega \in \V(C \cap D)$ of the variables that clusters $C$ and $D$ have in common, a linear constraint
        \[
            \sum_{\bar c \in \V(C\setminus D)} \mu_C(\bar c, \omega)
                =
            \sum_{\bar d \in \V(D \setminus C)} \mu_D(\bar d, \omega)
        \]
        \item for every $(a,s,t) \in \V\!\Ar$, a linear constraint
        that ensures
        \[
            \mu_{C_a}(\Src a{=}s, \Tgt a{=}t) \, \nu_{C_a}(\Src a{=}s)
                =
            \nu_{C_a}(\Src a{=}s, \Tgt a{=}t) \, \mu_{C_a}(\Src a{=}s).
        \]
        This is linear, because recall that $\nu$ is a constant in this optimization
        problem, found by having previously solved \eqref{prob:cluster-inc}.

        \item and one constraint for each cluster $C \in \C$ to ensure that $\mu_{C}$ lies on the probability simplex.
    \end{itemize}
    So in total, there are
    $n = 3 |\V \C|$ variables,
    and
    $m =  |\V \C| + |\V \mathcal T| + |\V\!\Ar| + |\C|$ constraints.
    Once again the components of $A$ and $b$ are all at most one, and now the components of the cost function $c = \mat 1$ are identically one.
    Furthermore, our objective is 1-strongly convex, so no additional multiplicative terms are required to convert an $\epsilon$-close solution in the sense of suboptimality, to an $\epsilon$-close solution in the sense of proximity to the true solution.

    Therefore \eqref{prob:cluster+idef} can be solved in
    \begin{align*}
        O\Big( |\V \C| |\V \!\Ar + \V \C|^{\omega}
            \log \frac{|\V \!\Ar + \V \C|}{\epsilon} \Big)
        \quad\subset\quad
        \tilde O_{\text{BP}}( |\V \C + \V \! \Ar|^{4} \log\frac1\epsilon )
    \end{align*}
    operations.
\end{lproof}


\recall{theorem:main}
\begin{lproof}\label{proof:main}
    Suppose that the PDG has $N$ variables
    (each of which can take at most $V$ distinct values),
    and $A$ hyperarcs, which together form a structure has tree-width $T$.
    Then each cluster (of which there are at most $N$)
    can have at most $T+1$ variables, and so can take at most $V^T$ values.
    Therefore, $|\V \C| \le N V^{T+1}$.
    Since each arc must be entirely contained within some cluster,
    $|\V\!\Ar| \le A V^T$.
    So, $|\V\!\Ar + \V \C| \le (N+A) V^{T+1}$.

    By \cref{lem:smallgamma-polytime},
    we know that, for $\gamma \in (0, \min_a \frac{\beta_a}{\alpha_a}]$,
    a \actree\ $\epsilon$-close (in $\ell_2$ norm) to
    the one that represents the unique distribution in the
    $\zogamma$-semantics can be found in time
    in time
    \[
        O\Big(  (N+A)^4 V^{4T+4} \log \Big(V^{T+1}(N+A)\frac{1}{\epsilon}  \frac{\beta^{\max}}{\gamma}
         + \log \frac{1}{p^{\min}} \Big)  \Big).
    \]
    Similarly, by \cref{lem:cluster-inc-polytime,lem:cluster+idef-polytime}
    a \actree\ $\epsilon$-close to the one representing the $0^+$
    semantics can be found in time
    \begin{align*}
        O\Big( |\V\C + \V\!\Ar|^{4} \log \frac{\V\!\Ar+ \V\C}{\epsilon}\Big) +
        O\Big( |\V\C + \V\!\Ar|^{4} \log \frac{\V\!\Ar+ \V\C}{\epsilon}\frac{\beta^{\max}}{\beta^{\min}}\Big)
        \\
        \subseteq
        O\Big(  (N+A)^4 V^{4(T+1)} \log \Big( V^{T+1} (N+A)
            \frac{1}{\epsilon}  \frac{\beta^{\max}}{\beta^{\min}} \Big)
            \Big).
    \end{align*}
    Either way, a \actree\ $\epsilon$-close to the one that represents the $\zogamma$-semantics, for $\gamma \in \{0^+ \} \cup (0, \min_a \frac{\beta_a}{\alpha_a})$,
    can be found in
    \[
        O \bigg(|\V\!\Ar + \V \C|^{4}  \log \Big( \frac{|\V\!\Ar + \V \C|}{\epsilon} \frac{\beta^{\max}}{\beta^{\min}} + \log \frac1{p^{\min}} \Big) \bigg)
        ~\subseteq~
        \tilde O_{\text{BP}}\Big(|\V\!\Ar + \V \C|^{4}\log \frac{1}{\epsilon} \Big)
    \]
    arithmetic operations, each of which can be done in $O(k \log k)$ time. 
    
    If $\bbeta, \mathbb P$, and $\gamma$ are all binary numbers specified in $k$
    bits, then $\log_2 \frac{\beta^{\max}}{\beta^{\min}} \le 2k$ and $\log \log \frac{1}{p^{\min}} \le \log k + \log(2)$, 
    Thus, under these assumptions, such a \actree\ 
    can be found in 
    \begin{align*}
        O \bigg(|\V\!\Ar + \V \C|^{4}  \Big( \log \frac{|\V\!\Ar + \V \C|}{\epsilon} + k + \log k \Big) k \log k \bigg) 
    ~\subseteq~
        \tilde O \bigg(|\V\!\Ar + \V \C|^{4}  \log \Big( \frac{1}{\epsilon} \Big) k  \bigg) 
    \end{align*}
    time.    
    Finally, we prove part (b).  The $\infty$-norm is smaller than the $\ell_2$ norm,
    so if $\Vert \bmu - \bmu^* \Vert_2 < 2^{-(k+1)}$, then any change to $\bmu$ 
    of size $2^{-k}$ or larger will cause it to be further from $\bmu^*$.
    Thus, selecting $\epsilon = 2^{-(k+1)}$ produces the \actree\ of $k$-bit
    numbers that is closest to $\bmu^*$.  Plugging in this value of $\epsilon$, 
    we find that finding it takes 
    $
        \tilde O (|\V\!\Ar + \V \C|^{4} k^2 )
    $ time. 
\end{lproof}

\begin{lemma} \label{lem:logeps-conditioner}
    Let $k \ge 1$ be a fixed integer, and $\Phi$, $K_0$, $K_1, \ldots, K_k$ be parameters. 
     Given a procedure that
    produces $\epsilon$-approximate unconditional probabilities in 
    $O(\Phi \cdot (K_0 +  \sum_{i=1}^k K_i \log^i \frac1\epsilon) )$ time, 
    we can approximate conditional probabilities $\Pr(B|A)$ to within $\epsilon$ in 
    $
    O(\Phi  \cdot (K_0 \log \log \frac1{\Pr(A)} + \sum_{i=1}^k K_i \log^i \frac1{\epsilon \Pr(A)} ))
    $ 
    time.
\end{lemma}
\begin{lproof}
    Let $f$ be our algorithm for approximating unconditional probabilities.
    If $A$ is an event and $\epsilon > 0$, we write $f(A ; \epsilon)$
    for the corresponding approximation to $\Pr(A)$, which by definition satisfies
    \[
        \Pr(A) - \epsilon ~\le~ f(A; \delta) ~\le~ \Pr(A) + \epsilon.
    \]
    
    Now suppose that $A$ and $B$ are both events, and
    we want to find the conditional probability 
    $\Pr(B|A)$.
    To do so, we can run the following algorithm.     
    
    {\singlespacingplus
    \rule{4in}{0.2ex}
    \begin{algorithmic}[1]
        \STATE $\delta \gets \epsilon$;
        \LOOP
            \STATE let $a \gets f(A; \delta)$;
            \smallskip
            \IF{$a > 2 \delta$}
                \STATE let $\delta^* \gets \epsilon (a - \delta) /3$;
                \STATE let $p \gets f(A ; \delta^*)$~~and~~ $q \gets f(A \cap B ; \delta^*)$;
                \STATE \textbf{return}~~$q ~/~ (p + \delta^*)$.
            \ELSE
                \STATE $\delta \gets \delta^2$;
            \ENDIF
        \ENDLOOP

    \end{algorithmic}
    \rule{4in}{0.2ex}%
    }
    
    \textbf{Proof of correctness.}
    We claim that the final output of the algorithm is within $\epsilon$ of the true conditional probability $\Pr(B|A)$.
    In the first iteration in which $a > 2\delta$ (line 4),
    we know that $\delta \le a - \delta \le \Pr(A)$.

    By assumption,
    \begin{align*}
        \Pr(A) - \delta^* ~\le~ p ~\le~ \Pr(A) + \delta^*
        \qquad\text{and}\qquad
        \Pr(A \cap B) - \delta^* ~\le~ q ~\le~ \Pr(A \cap B) + \delta^*,
    \end{align*}
    from which it follows that
    \begin{align*}
        \frac{\Pr(A \cap B) - \delta^*}{\Pr(A) + 2\delta^*}
            ~\le~ \frac{q}{p + \delta^*}
            ~\le~ \frac{\Pr(A \cap B) + \delta^*}{\Pr(A)}
        . \numberthis\label{eq:bound1}
    \end{align*}
    We now extend the bounds on $q/(p+\delta^*)$ in both directions, 
    starting with the upper bound. 
    Because $a - \delta \le \Pr(A)$, the RHS of \eqref{eq:bound1} is at most
    \begin{align*}
        \frac{\Pr(A \cap B) + \delta^*}{\Pr(A)}
        ~&=~ \Pr(B|A) + \frac{\delta^*}{\Pr(A)}
        ~=~ \Pr(B|A) + \frac{\epsilon}{3}\frac{(a-\delta)}{\Pr(A)}
        ~\\&\le~ \Pr(B|A) + \frac{\epsilon}{3} \frac{\Pr(A)}{\Pr(A)}
        ~<~ \Pr(B|A) + \epsilon.
    \end{align*}
    The analysis of the lower bound (the LHS of \eqref{eq:bound1}) is slightly more complicated, but we still find that
    {\allowdisplaybreaks
    \begin{align*}
        &\frac{\Pr(A \cap B) - \delta^*}{\Pr(A) + 2 \delta^*}
        = \Pr(B|A) - \frac{\mu^*(x,y)}{\Pr(A)} + \frac{\Pr(A \cap B) - \delta^*}{\Pr(A) + 2 \delta^*}
        \\
        &= \Pr(B|A) + \frac{\Cancel{-\Pr(A)\, \Pr(A \cap B)} - 2 \delta^* \Pr(A \cap B) + \Cancel{\Pr(A) \Pr(A \cap B)} - \delta^* \Pr(A)}{\Pr(A) (\Pr(A) + 2 \delta^*)} \\
        &= \Pr(B|A) + \frac{ - 2 \delta^* \Pr(B|A) - \delta^* }{\Pr(A) + 2 \delta^*} \\
        &= \Pr(B|A) - \delta^* \Big( \frac{2 \Pr(B|A) + 1}{ \Pr(A) + 2 \delta^*} \Big) \\
        &\ge \Pr(B|A) - \delta^* \frac{3}{\Pr(A)+ \delta^*}
            \qquad &\mathllap{
            \Big[\text{ since $\Pr(B|A) \le 1$, and thus $- 2\Pr(B|A) \ge -2$ }\Big]}\\
        & \ge \Pr(B|A) - \delta^* \frac{3}{\Pr(A)}
            \qquad &\mathllap{
            \Big[ \text{ as eliminating $\delta^*$ makes this more negative }\Big]} \\
        &= \Pr(B|A) - \frac{\epsilon(a-\delta)}{3} \frac{3}{\Pr(A)}
            \qquad &\mathllap{ \Big[ \text{ by definition of $\delta^*$ }\Big]}\\
        &\ge \Pr(B|A) - \frac{\epsilon \Pr(A)}{\Pr(A)}
            \qquad &\mathllap{ \Big[ \text{ since $-(a-\delta) \ge - \Pr(A)$ }\Big]}\\
        &= \Pr(B|A) - \epsilon.
    \end{align*}}
    These two arguments extend the bounds of \eqref{eq:bound1} in both directions.  Chaining all of these inequalities together, we have shown that our procedure returns a number $\mathtt{output}$ satisfying
    \[
    \Pr(B|A) - \epsilon ~\le~ \mathtt{output} ~\le~ \Pr(B|A) + \epsilon,
    \]
    and hence calculates the desired conditional probability to within $\epsilon$.
    
    \bigskip
    
    
    \textbf{Analysis of Runtime.}
    Let $m$ denote the total number of iterations of the algorithm.
    We deal with the simple case of $m=1$ separately. 
    If $m = 1$, then already in the first iteration
    $a > 2 \delta = 2 \epsilon$, so by definition $\delta^* > \frac13 \epsilon^3$.
    Line 6 is just two calls to the procedure, and takes
    \begin{align*}
    O\left( \Phi \Big(K_0 + \sum_{i=1}^k K_i \log^i \frac{1}{\delta^*}  \Big) \! \right)
    &=
    O\left( \Phi \Big(K_0 +  \sum_{i=1}^k K_i \log^i \frac{3}{\epsilon^3} \Big) \!\right)
    \\&\subseteq
    O\left( \Phi \Big(K_0 + \sum_{i=1}^k K_i \log^i \frac{1}{\epsilon} \Big) \!\right)
    ~\text{time}.
        \numberthis
        \label{eq:cost-case1}
    \end{align*}

    Now consider the case where $m > 1$.
    Observe that, in the final iteration, $\delta = \epsilon^{2^{m-1}}$.
    The procedure halts when $a > 2 \delta$, and the smallest possible value of $a$ that our approximation can return is $\Pr(A) -\delta$.  Thus, the procedure must halt by the time $\Pr(A) > 3 \delta = 3 \epsilon^{2^{m-1}}$.
    On the other hand, since $m-1$ iterations are not enough to ensure termination, it must be that  $\Pr(A) - \delta' \le 2\delta'$,
    where $\delta' := \epsilon^{2^{m-2}}$ is the value of $\delta$ in the penultimate iteration.
    Together, these two facts give us a relationship between $m$ and $\Pr(A)$:
    \begin{align*}
        &&3 \epsilon^{2^{m-2}} ~&\ge& & \Pr(A) &&>~ 3 \epsilon^{2^{m-1}} \\
        &\iff~~&
        - \log_2 3 - 2^{m-2} \log_2 \epsilon ~&\le& - \log_2 & \Pr(A) &&<~ - \log_2 3 - 2^{m-1} \log_2 \epsilon \\
        &\iff~~&
    %    
        % 2^{m-2} ~&\le& \Big(\log_2 \frac3{\Pr(A)} \Big) & / \log_2(\nf1\epsilon) &&<~ 2^{m-1}
        && \mathllap{2^{m-2} ~\le~ \Big(\log_2 \frac3{\Pr(A)} \Big)} &
            \mathrlap{~/ \log_2(\nf1\epsilon) ~<~ 2^{m-1} }&&
        .
            \numberthis\label{eq:bound2}
    \end{align*}
    In particular, the first inequality tells us that the number of required iterations is at most
    \[
        m \le 2 + \log_2 \log_2 \frac3{\Pr(A)} - \log_2 \log_2 \frac1\epsilon
            \quad = 2 + \log_2 \log_\epsilon \frac{\Pr(A)}{3}
            .
    \]

    Across all iterations, the total cost of line 3 is on the order of
    {\allowdisplaybreaks\begin{align*}
        &m \Phi K -  \Phi \sum_{i=1}^k K_i \sum_{j=1}^{m}  \log^i (\epsilon^{2^{j-1}}) \\
        &= m \Phi K -  \Phi \sum_{i=1}^k K_i \log^i (\epsilon) \sum_{j=0}^{m-1} 2^{kj} \\
        &= m \Phi K +  \Phi \sum_{i=1}^k K_i \log^i \frac1\epsilon\, \, 
            \frac{2^{im} - 1}{2^i -1}
             \\
        &< \Big(\log \log \frac3{\Pr(A)} - \log \log \frac1\epsilon \Big) \Phi K_0 
        \\&\qquad\quad + \Phi \,  
            \sum_{i=1}^k K_i \Cancel{\log^i (\nf1\epsilon)} \cdot \left[ 
            4^i \Big(\log^i \frac3{\Pr(A)} \Big) ~/~ \Cancel{\log^i(\nf1\epsilon)}
            \right] / (2^i-1) \\
        &\le \Phi K_0 \log \log \frac3{\Pr(A)}   + \Phi \sum_{i=1}^k K_i \frac{4^i}{2^i-1} \log^i \frac3{\Pr(A)} 
            \\
        &\subseteq O \Big( \Phi \cdot  \Big(K_0 \log \log \frac1{\Pr(A)} + \sum_{i=1}^k K_i \log^i \frac1{\Pr(A)}\Big)\Big)
        .            
            \numberthis
            \label{eq:cost-line4}
    \end{align*}}

    
    Line 6 is the last part of the procedure that
    incurs a nontrivial cost.  The procedure executes it one time, in the final iteration.
    Because $a > 2 \delta$ at this point, we know that
    \[
        \delta^*
        ~=~ \frac{\epsilon}3(a-\delta)
        ~>~  \frac\epsilon3\delta
        ~=~  \frac \epsilon3 \epsilon^{2^{m-1}}
        ~=~  \frac\epsilon3 \frac99 \epsilon^{2(2^{m-2})}
        ~=~ \frac \epsilon{27} \Big( 3 \epsilon^{2^{m-2}}\Big)^2
        ~\ge~ \frac\epsilon{27} \Pr(A)^2.
    \]
    Thus line 6 requires time
    \begin{align*}
        &O\Big(\Phi \cdot \Big( K_0 + \sum_{i=1}^k K_i \log^i \frac{27}{\Pr(A)^2\epsilon} \Big)\Big) 
        \subseteq
            O\Big(\Phi K_0  + \Phi \sum_{i=1}^k K_i \Big(\log \frac{1}{\Pr(A)} + \log \frac1\epsilon \Big)^{\!i\,}\Big) 
        \numberthis\label{eq:cost-line8}.
    \end{align*}
    Summarizing, the total running time is (at most) the sum of \eqref{eq:cost-case1}, \eqref{eq:cost-line4}, and \eqref{eq:cost-line8}, 
    or explicitly,
    \begin{align*}
        O \Big( \Phi \cdot \Big(
            K \log \log \frac1 {\Pr(A)} + \sum_{i=1}^k K_i \log^i \frac1{\epsilon \Pr(A)} %
        \Big)\Big)
        .
    \end{align*}
\end{lproof}

\recall{theorem:approx-infer}
\begin{lproof}  \label{proof:approx-infer}
    \Cref{theorem:main} gives us an approximation to a calibrated
    \actree\ that represents the distribution of interest,
    and \cref{lem:logeps-conditioner} allows us to approximate conditional probabilities
    once we can approximate unconditional ones.     
    The final ingredient is tto approximate unconditional
    probabilities using an approximate \actree. 
    
    Concretely, suppose that we are
    looking to find $\mu^*(X{=}x)$, where $\mu^* \in \bbr{\dg M}_\gamma$. 
    Once we have a \cactree\ $\bmu$ that represents $\mu^*$, 
    calculating a marginal $\mu^*(X{=}x)$ (exactly) from $\bmu$ 
    can be done with standard methods \parencite[][\S 10.3.3]{KF09}.
    In the worst case, it requires taking a marginal of every cluster,
    which can be done in $O(|\V\C|) \subseteq O(N V^{T+1})$ arithmetic operations. 
    
    The wrinkle is that $\bmu$ only \emph{approximately} represents $\mu^*$, 
        in the sense that there is some $\bmu^*$ that does represent $\mu^*$ such that the L2 norm of $\bmu^* - \bmu$ is small. 
    As usual, we write $\bmu_C$ for the components of $\bmu$ that
        are associated with cluster $C$.
    For each $C \in \C$, let $E_{C}$ denote the event that 
    $(X \cap C) = x|_{C}$. 
    That is, the variables of $X$ that lie in cluster $C$ take the values
    prescribed by $x$. Then    
    \begin{align*}
        \big| \Pr\nolimits_{\!\bmu}(X{=}x) - \Pr\nolimits_{\!\bmu^*}(X{=}x) \big|
        ~&\le~ \sum_{C \in \C} \big|
            \Pr\nolimits_{\!\bmu^*_C}(E_C) - 
            \Pr\nolimits_{\!\bmu_C}(E_C)
        \big|
        \\
        ~&\le~
        \sum_{C \in \C} \big\Vert \bmu^*_C - \bmu_C \big\Vert_1
        ~=~
        \big\Vert \bmu^* - \bmu \big\Vert_1
        ~.
    \end{align*}
    
    
    Applying the L2-L1 norm inequality to the vector $\bmu - \bmu^*$, 
    we find
    \begin{align*}
        \big\Vert \bmu - \bmu^* \big\Vert_1
        \le 
        \big\Vert \bmu - \bmu^* \big\Vert_2 \sqrt{|\V\C|}
        \le \sqrt{N V^{T+1}} \big\Vert \bmu - \bmu^* \big\Vert_2.
    \end{align*}
    Thus, to answer unconditional queries about $X$ within (absolute) precision
    $\epsilon$, it suffices to find a \actree\ within $\epsilon / \sqrt{N V^{T+1}}$
    of $\bmu^*$ by L2 norm. 
    
    From the proof of \cref{theorem:main}, we know that we can find
    such a $\bmu$ 
    in
    \begin{align*}
        O\bigg( 
            (N{+}A)^4 V^{4(T+1)}
            \log \Big( \frac{(N{+}A)^4 V^{4(T+1)}\cdot N^{\frac12} V^{\frac{T+1}{2}}}{\epsilon} \frac{\beta^{\max}}{\beta^{\min}} + \log \frac1{p^{\min}} \Big) 
        \bigg) \\
        ~\subseteq~
        \tilde O\bigg( 
            (N{+}A)^4 V^{4(T+1)}
            \Big(
            \log \frac1\epsilon + \log \frac{\beta^{\max}}{\beta^{\min}}\Big) 
        \bigg) \\
        ~\subseteq~
        \tilde O_{\text{BP}}\Big(|\V\!\Ar + \V \C|^{4}\log \frac{1}{\epsilon} \Big)
    \end{align*}
    arithmetic operations,
    which dominates the number of operations required to then find the marginal probability $\Pr_{\!\bmu}(X{=}x)$ given the \actree\ $\bmu$.
    Thus, the complexity of finding unconditional probabilities is the same. 
    The arithmetic operations need to be done to precision at most $k \in O(\log\nf1\epsilon)$, and can be done in time $O(k\log k)$. 
    Thus, unconditional inference can be done in 
    \begin{align*}
        O\bigg( 
            \begin{matrix}{}(N{+}A)^{4.5} \\ V^{4.5(T+1)}\end{matrix}
            \log \Big( \frac{(N{+}A)^4 V^{4(T+1)}\cdot N^{\frac12} V^{\frac{T+1}{2}}}{\epsilon} \frac{\beta^{\max}}{\beta^{\min}} + \log \frac1{p^{\min}} \Big) 
            \log\frac{1}{\epsilon} \log\log\frac{1}{\epsilon}
        \bigg) \\
        ~\subseteq~
        \tilde O\bigg( 
            (N{+}A)^4 V^{4(T+1)}
            \Big(
            \log \frac1\epsilon + \log \frac{\beta^{\max}}{\beta^{\min}}\Big) 
            \log \frac1\epsilon
        \bigg)
        \quad\text{time}. 
    \end{align*}
    
    \def\mustar{\mu^{\mskip-2mu*\!}}
    Now that we have characterized the cost of unconditional inference, we can apply \cref{lem:logeps-conditioner} with $\Phi := (N+A)^4 V^{4(T+1)}$,
    $k = 2$,
    $K_0 = 0$, 
    $K_1 := \log \Phi + \log \frac{\beta^{\max}}{\beta^{\min}} + \log \log \frac1{p^{\min}}$, 
    and
    $K_2 = 1$
    to find that conditional probabilities can be found in
    \begin{align*}
        \tilde O \bigg(\! (N{+}A)^4\,V^{4(T+1)} 
        \log \frac1{\epsilon\,\mustar(x)}
        \Big(
              \log \frac{\beta^{\max}}{\beta^{\min}} 
               + \log \frac1{\epsilon\, \mustar(x)} 
         \Big)\bigg) 
        \quad \text{time},
    \end{align*}
    where $\mustar(x)$ is shorthand for
    $\mu^*(X{=}x)$. 
\end{lproof}

\section{The Convex-Concave Procedure, and Implementation Details}
    \label{sec:cccp}

Optimization problems \eqref{prob:joint-small-gamma} and \eqref{prob:cluster-small-gamma}
can be extended to apply slightly more broadly.
There are some cases where there is a unique optimal distribution
but $\gamma$ is large
enough that $\bbeta \not\ge \gamma\balpha$.
In these cases, our convex program will fail to satisfy the dcp requirements, and
    so we cannot compile it to an exponential conic program---but
    it turns out to still be a useful building block.
We now describe how we can still do inference in some of these cases with the
    convex-concave procedure, or CCCP \parencite{yuille2003concave}.
This will give us a local minimum of the
    PDG scoring function $\bbr{\dg M}_\gamma$,
    without requiring us to write this scoring function
    in a way that proves its convexity,
    (as is necessary in order to specify a disciplined convex program).
At this point, if we happen to know that the problem is convex (or even
    just pseudo-convex) for other reasons, then finding this distribution
    suffices for inference.
We now describe how this can be done in more detail.



Suppose
    $\beta_a < \gamma \alpha_a$ some $a \in \Ar$.
In this case $\bbr{\dg M}_\gamma$ may not be convex, in general.%
\footnote{
    Consider the PDG $({\to} X,\, Y {\gets})$ for instance, which
    has arcs to $X$ and $Y$, both with $\alpha = 1$ and $\beta = 0$.
    The minimizers of
     $\bbr{{\to} X,\, Y {\gets}}_\gamma$
        are the distributions that make $X$ and $Y$ is independent.
    It is easily seen that this set
    is not convex: $X$ and $Y$ are independent if either variable is deterministic,
    and every distribution is a convex combination of deterministic distributions.
    }
However, we do know how to decompose $\bbr{\dg M}_\gamma$ into a sum
of a convex function $f(\mu)$ and a concave one $g(\mu)$.
Concretely: each term on the second line of \eqref{eq:altscore} is either convex or concave, depending on the sign of the quantity $\gamma \alpha_a - \beta_a$.
Once we sort the terms into convex terms $f(\mu)$ and strictly concave terms $g(\mu)$,
    the CCCP tells us to repeatedly solve $f$ plus a
        linear approximation to $g$.
In more detail, the algorithm proceeds as follows.
First, choose an initial guess $\mu_0$, and iteratively use the convex solver
    as in the main part of the chapter to compute
\begin{align*}
    \mu_{t+1} &:= \argmin_{\mu} f(\mu) + (\mu - \mu_{t})^{\sf T}
        \nabla g(\mu_t).
\end{align*}
This can be slow because each iteration of the solver is expensive.
Still, it is guaranteed to make progress, since
\def\tplus1{{t\mskip-2mu+\mskip-2mu1}}
\begin{align*}
    f(\mu_\tplus1) \!+\! g(\mu_\tplus1) &<  f(\mu_\tplus1) \!+\! (\mu_\tplus1 \!-\! \mu_t)^{\sf T} \nabla g(\mu_t) \!+\! g(\mu_t)
        \\
    &\le  f(\mu_t) + (\mu_t - \mu_{t})^{\sf T}\nabla g(\mu_t)  + g(\mu_t)
    \\
&= f(\mu_t) + g(\mu_t).
\end{align*}
Furthermore, because in our case $g$ is bounded,
    the process eventually converges a local minimum
    of $\bbr{\dg M}_\gamma$.
This alone, however, is not sufficient for inference,
because we may not be able to use this local minimum
    to answer queries in a way that is true of \emph{all} minimizing distributions.
But, if it happens there is a unique local minimum, then the CCCP will
    find it, leading to an inference procedure.




Notice that if $\bbeta \ge \gamma\balpha$, then the concave part $g$ is identically
zero, and CCCP converges after making just one call to the convex solver.
Therefore, in the cases we could already handle, this extension
reduces to the algorithm we described before.
For this reason, all of our code that handles problems
 \eqref{prob:joint-small-gamma} and \eqref{prob:cluster-small-gamma}
is augmented with the CCCP.





Compared to the black-box optimization baselines (Adam and LBFGS),
 which also only find one minimum,
    the CCCP still has some advantages.
One can see in \cref{fig:gamma-v-gap-fine}, for example, that when $\gamma = 2 > 1 = \max_a {(\beta_a / \alpha_a)}$,
CCCP performs better than the baselines.
In fact, the CCCP-augmented
solver
could probably even higher accuracy,
    if were we not limiting it to
    a maximum of only five iterations.


\section{Details on the Empirical Evaluation}\label{sec:expt-setup}
Imagine a very steep $V$-shaped canyon, and inside a small slow-moving stream at a gentle incline. The end of the river may be very far away, and the whole landscape may be smooth and strongly convex, but the gradient will still almost always point perpendicular to it, and rather towards the center of the river.
This intuition may help explain why, even though $\bbr{\dg M}_\gamma$ is infinitely differentiable in $\mu$ and $\gamma$-strongly convex, it can still be challenging to optimize, especially when the $\beta$'s are very different, or when $\gamma$ is small.
For example, a solution to \eqref{prob:cluster-inc} finds a minimizer of $\OInc$, but such minimizers may be very far away from $\bbr{\dg M}_{0^+}^*$, despite sharing an objective value.

We now see how this is true even when working with very small PDGs and joint distributions.


\begin{figure}
    \includegraphics[width=\linewidth]{figs/rand-joint/resource-costs}
    \caption[More details: resource costs for joint-distribution optimization setting]{
    %\small
        Resource costs for the joint-distribution optimization setting of \cref{sec:inf-as-cvx-program}.
        We measure computation time (\texttt{total\_time}, top) and maximum memory usage (\texttt{max\_mem}, bottom) for the various optimization methods (by color), as the size of the PDG increases, as measured by the number of parameters in the PDG (\texttt{n\_params}$\,=\V\!\Ar$, left), and the size of a joint distribution over its variables (\texttt{n\_worlds}$\,=\V\!\X$, right).
        Note that the convex solvers for the 0 and $0^+$ semantics are significantly faster than LBFGS, and on par with Adam.
        However, all three convex-solver based approaches require significantly more memory than the black-box optimizers.
     }\label{fig:resources}
\end{figure}



\subsection{Synthetic Experiment: Comparison with Black-Box Optimizers, on Joint Distributions.} \label{sec:joint-expt-details}
\begin{wrapfigure}[14]{R}{4.8cm}
    \centering
    \vspace{-3ex}
    \includegraphics[width=4.5cm]{figs/rand-joint/representation}
    \captionsetup{format=plain}
    \caption{differences in performance between the Gibbs and simplex parameterizations of probabilities.}%
    \label{fig:representation}%
\end{wrapfigure}


Here is a more precise description of our first synthetic experiment,
on joint distributions, which contrasts the convex optimization approaches of \cref{sec:inf-as-cvx-program} with black-box optimizers.



\begin{itemize}
    \item generate 300 PDGs, each of which has the following quantities, to each of which we choose the following natural numbers uniformly at random:
    \begin{itemize}
        \item $N \in \{5,\ldots,9\}$ of variables
            (so that $\X := \{1, \ldots, N\}$),
        \item $V_X \in \{2, 3\}$ values per variable
            (so that $|\V X| = V_X$ for each $X \in \X$)
        \item $A \in \{7, \ldots, 14\}$ hyperarcs,
        each $a \in \{1, \ldots, A\} =: \Ar$ of which has
        \item $N^S_a \in \{0, 1, 2, 3\}$ sources, and
        \item $N^T_a \in \{1,2\}$ targets.
    \end{itemize}
    \item For each arc $a \in \Ar$, $N^S_a$ of the $N$ variables are chosen without replacement to be sources $S_a \subseteq N$, and $N^T_a$ of remaining variables are chosen to be targets. Finally, to each value of $S_a$ and $T_a$, a number $p_{a,s,t} \in [0,1]$ is chosen uniformly at random, and the cpd
    \[
     \p_a(\Tgt a {=} t \mid \Src a {=} s) =
        \frac{p_{a,s,t}}{\displaystyle\sum_{t' \in \V(T)} p_{a,s,t'}}
     \qquad\text{ is given by normalizing appropriately.}
    \]
    This defines a PDG $\dg M = (\X, \Ar, \mathbb P, \mat 1, \mat 1)$, that
    has $\balpha = \bbeta = \mat 1$, which will allow us to compare against
    belief propagation and other graphical models at $\gamma = 1$.
    The complexity of this PDG is summarized by two numbers:
    \begin{itemize}[nosep]
        \item \texttt{n\_params}$\,:= \V\!\Ar$, the total number of parameters in all cpds of $\dg M$, and
        \item \texttt{n\_worlds}$\,:= \V\!\X$, the dimension of joint distributions over $\dg M$'s variables.
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item Run MOSEK on \eqref{prob:joint-inc} to find a distribution that minimizes $\OInc$; we refer to this method as \texttt{cvx-idef}
    \item Use the result to run MOSEK on \eqref{prob:joint+idef} to find the special distribution $\bbr{\dg M}^*_{0^+}$; we refer to this method as \texttt{cvx+idef}. These names are due to the fact that $\SDef$ is called $\IDef{}$ in previous work \parencite{pdg-aaai,one-true-loss};
    thus, this refers to using the convex solver to compute minimizers of $\OInc$ with and without considering $\IDef{}$.

    \item Run the \texttt{pytorch} baselines.
    Let $\theta = [\theta_{\mat x}]_{\mat x \in \V\!\X} \in \mathbb R^{\V\X}$ be a vector of optimization variables, and choose a representation of the joint distribution, either:
    \begin{align*}
        % \Big(\begin{array}{c}\text{renormalized}\\
        % \text{simplex}\end{array}\Big)\quad
        \mu_{\theta}(\mat x) &= \frac{\max\{\theta_{\mat x}, 0\} }
            {\sum_{\mat y \in \V\!\X}\max\{\theta_{\mat y}, 0\} }
        &(\text{ renormalized simplex }) \\
    \text{or}\qquad
    \mu_{\theta}(\mat x) &= \frac{\exp(\theta_{\mat x})}{\sum_{\mat y \in \V\!\X} \exp(\theta_{\mat y})} & (\text{Gibbs})
    % \qquad\quad\text{(see \cref{fig:representation})}
    \end{align*}
    See \cref{fig:representation} for a visual representation of the (relatively minor) effect of this choice. 
    \item
    For each value of the trade-off parameter 
    $\gamma \in \{0, 10^{-8}, 10^{-4}, 10^{-2}, 1\}$, and each learning rate $\texttt{lr} \in 1E-3, 1E-2, 1E-1, 1E0$, and each optimizer $\mathit{opt} \in \{\texttt{adam}, \texttt{L-BFGS}\}$,
    run $\mathit{opt}$ over the parameters $\theta$ to minimize $\bbr{\dg M}_\gamma(\mu_{\theta})$
     until convergence (or a maximum of 1500 iterations)

     \item We collect the following data about the resulting distribution and the process of computing it:
     \begin{itemize}[nosep]
         \item the total time taken to arrive at $\mu$;
         \item the maximum memory taken by the process computing $\mu$;
         \item the objective and its component values:
         \vspace{-1ex}
         \[
            \begin{array}{c}
            \texttt{inc} := \SDef_{\dg M}(\mu), \\
            \qquad \texttt{idef} := \SDef_{\dg M}(\mu),
            \end{array}
            \qquad \texttt{obj} := \OInc_{\dg M}(\mu) + \gamma \SDef_{\dg M}(\mu) = \bbr{\dg M}_\gamma(\mu)
        \]
     \end{itemize}
\end{itemize}



The numbers can then be recreated by running our experimental script as follows:
\begin{verbatim}
python random_expts.py -N 300 -n 5 9 -e 7 14 -v 2 3
    --ozrs lbfgs adam
    --learning-rates 1E0 1E-1 1E-2 1E-3
    --gammas 0 1E-8 1E-4 1E-2 1E0
    --num-cores 20
    --data-dir random-joint-data
\end{verbatim}
which creates a folder called \verb|random-joint-data|,
and fills it with \verb|.mpt| files corresponding to each distribution
and the method / parameters that gave rise to it.

\textbf{Analyzing the Results.}
Look at  \cref{fig:resources}.  Our theoretical analysis, and in particular the proof of \cref{lem:cluster-inc-polytime}, suggest that the magnitudes of $\V\!\X$ and $\V\!\Ar$ play similar roles in the asymptotic complexity of PDG inference.
Our experiments reveal that, at least for random PDGs, the number of worlds is the far more important of the two; observe how much more variation there is on the left side of the figure than the right---and now note that the left side has been smoothed, while the right side has not.
The black-box py-torch based approaches clearly have an edge in that they can handle larger models, as evidenced by the cut-offs on the right-hand side of \cref{fig:gap-resource-fine-old}, when with 5GB memory.

Note that the exponential-cone-based methods for the observational limit (gold) are actually faster than L-BFGS (the black-box optimizer with the lowest gap), and also seem to be growing at a slower rate.
However, they use significantly more memory, and cannot handle large models.
In addition to being faster, our techniques also seem to be more precise; they achieve objective values that are consistently much better than the black-box methods.


Now look at \cref{fig:joint-gap-vs-time-by-gamma},
which contains a break-down of the information in \cref{fig:joint-gap-time}. The bottom half of the figure is just the same information, but with each value of $\gamma$ separated out, so that the special cases of the factor product and $0^+$ inference become clear, while the top half shows why it's more important to look at the gap than the actual objective value for these random PDGs.
\Cref{fig:joint-gap-vs-time-by-gamma} also makes it clearer how larger problems take longer, and especially so for \texttt{cccp} (violet), which solves the most complex version of the problem \eqref{prob:joint-small-gamma}.

\begin{figure}
    \includegraphics[height=0.45\textheight]{figs/rand-joint/gap-vs-time-by-gamma}
    \caption[A disaggregated version of \cref*{fig:joint-gap-time}]{\small
        An un-compressed version of the information in \cref{fig:joint-gap-time}, that groups by the value of $\gamma$, and also gives the absolute values of the objectives (top row) in addition to the relative gaps (bottom row).
    }\label{fig:joint-gap-vs-time-by-gamma}
\end{figure}




% \discard{\begin{figure}
%     \includegraphics[height=0.45\textheight]{figs/gamma-vs-gap-bettergap}
%     \caption{
%         A graph of the gap (the difference between the attained objective value, and the best objective value obtained across all methods for that value of $\gamma$),
%         as $\gamma$ varies. The x-axis is $\log_{10} ( \gamma + 10^{-15})$.
%         As before, colors indicate the optimization method; here blue corresponds to \eqref{prob:joint+idef}, while orange corresponds to \eqref{prob:joint-small-gamma}, and green, as before, corresponds to all optimization baselines.
%         The size of the circle illustrates the relative number of worlds.
%         See \cref{fig:gamma-v-gap-fine} for a more detailed breakdown.
%     }\label{fig:gamma-v-gap}
% \end{figure}}


\begin{figure}
    \includegraphics[width=\linewidth]{figs/2}
    \caption[
        Plot of the accuracy gap for inference methods and baselines, for various values of $\gamma$.
    ]{
        A graph of the gap (the difference between the attained objective value, and the best objective value obtained across all methods for that value of $\gamma$),
        as $\gamma$ varies. The x-axis is $\log_{10} ( \gamma + 10^{-15})$.
        As before, colors indicate the optimization method, and
        the size of the circle illustrates the number of optimization variables (i.e., the number of possible worlds).
        \texttt{cvx-idef} corresponds to just solving \eqref{prob:joint-inc}, and \texttt{cvx+idef} corresponds to then solving problem \eqref{prob:joint+idef} afterwards.
        The CCCP runs are split into regimes where the entire problem is convex ($\gamma \le 1$, labeled \texttt{cccp-VEX}), and the entire problem is concave ($\gamma > 1$, labeled \texttt{cccp-CAVE}).
        The optimization approaches \texttt{opt\_dist} are split into three different optimizers: LBFGS, Adam, and also a third one that
        performs relatively poorly: accelerated gradient descent.
        Note that for small $\gamma$, the exponential-cone based methods significantly outperform the gradient-based ones.
    }\label{fig:gamma-v-gap-fine}
\end{figure}


\subsection{Synthetic Experiment: Comparing with Black-Box Optimizers, on \AcTree s} \label{sec:clus-expt-details}

\begin{figure}
    \centering
    \includegraphics[width=0.67\linewidth]{figs/rand-clus/gap-vs-time}
    \caption[Objective gap vs time in the cluster setting; shows more separation]
        {An analogue of \cref{fig:joint-gap-time}, for the cluster setting.
    Note that there is even more separation between the exponential-cone based approaches, and the black-box optimization based ones.
    The new grey points on the bottom correspond to belief propagation, which is both faster and typically the most accurate.}
    \label{fig:clus-gap-vs-time--appendix}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.67\linewidth]{figs/rand-clus/resource-costs}
    \caption[Resource costs for the cluster setting.]
        {Resource costs for the cluster setting. Once again, the $\OInc$-optimizing exponential cone methods are in gold, the small-gamma and CCCP is in violet, and the baselines are in green. The bottom line is belief propagation, which is significantly faster and requires very little memory, but also only gives the correct answer under very specific circumstances.}
    \label{fig:clus-resource-costs}
\end{figure}


\begin{enumerate}
    \item Choose a number of variables $N \in \{ 8, \ldots, 32 \}$, and a treewidth $k \in \{1, \ldots, 4\}$ uniformly at random.
    Then draw a random $k$-tree and corresponding tree of clusters $(\C, \mathcal T)$, as follows:
    \begin{enumerate}
        \item Initialize $G \gets K_{k+1}$ to a complete graph on $k+1$ vertices, and $\C \gets\{ K_{k+1} \}$ to be set containing a single cluster, and $\mathcal T\gets \emptyset$.
        \item Until there are $N$ vertices: add a new vertex $v$ to $G$, then randomly select a size $k$-clique (fully-connected subgraph) $U \subset G$, and add edges between $v$ and every vertex $u \in U$.
        Add $U \cup \{v\}$ to $\C$, and add edges to every other cluster $C \in \C$ such that $U \subset C$.
    \end{enumerate}
    \item Draw the same parameters $V_X \in \{2,3\}$, $A \in \{8, \cdots, 120\}$, $N_a^S \in \{0,1,2,3\}$, and $N^{T}\in \{1,2\}$
    as in \cref{sec:joint-expt-details} uniformly at random.
    While $N_a^S + N^T_a > k+1$, for any $a$, resample $N_a^S$ and $N_a^T$.

    \item Form a PDG whose structure $\Ar$ can be decomposed by $(\C, \cal T)$, as follows:
    for each edge $a \in \Ar$, sample a cluster $C \in \C$ uniformly at random; then select $N_a^S$ nodes from that cluster without replacement as sources, and $N_a^T$ nodes as targets; this is possible because each cluster has $k+1$ nodes, and $N_a^S + N_a^T \le k+1$ by construction.
    \item Fill in the probabilities by drawing uniform random numbers and re-normalizing, just as before, to form a PDG $\dg M$

    \item The black-box optimization baselines work in much the same way also, although now the optimization variables include not one distribution $\mu$ but a collection $\bmu$ of them;
    this time, we use only the simplex representation of $\bmu_\theta$.
    More importantly, we want these clusters to share appropriate marginals; to encourage this, we add a terms to the loss function, so overall, it is
    \[
        \ell(\theta) := \bbr{\dg M}_{\gamma}(\bmu_{\theta})  + \sum_{\mathclap{C{-}D \in \mathcal T}}\exp \!\left(\sum_{w \in \V(C\cap D)\!\!\!\!} \big(\mu_C(C\cap D{=}w) - \mu_D(C \cap D {=}w)\big)^2 \right) - 1.
    \]
    This is admittedly pretty ad-hoc; the point is just that it is zero and does not contribute to the gradient if $\bmu_\theta$ is calibrated, and otherwise quickly becomes overwhelmingly important.
\end{enumerate}

\textbf{Analyzing the Results.}
Observe in \cref{fig:clus-gap-vs-time} that the separation between the \actree\ convex solver and the black-box algorithms is even more distinct. This is because, in this case, the penalty for violating constraints was too small, and the optimization effort was largely wiped out by the calibration before evaluation.


\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figs/bn/gap-v-time}
    \caption{Gap vs inference time for the small PDGs in the \href{https://www.bnlearn.com/bnrepository/}{\texttt{bnlearn}} repository}
    \label{fig:bn-gap-v-time}
\end{figure}

This illustrates another general advantage that the convex solver has over black-box optimizers: it is much less brittle and reliant and exactly tuning parameters correctly. Note that even in this minimal example, there were many hyper-parameters that require tuning:
the regularization strengths that enforce soft constraints (\actree\ calibration, normalization), as well as learning rate, not to mention
various other structural choices: the optimizer, the representation of the distribution, and the maximum number of iterations, none of which are clear-cut choices, but rather require first being tuned to the data.
While the convex solver does have internal parameters (tolerances and such) these do not need to be tuned to the problem under normal circumstances.

\subsection{Comparing to Belief Propagation, on \AcTree s.}
    \label{sec:bn-expt-details}
 Since PDGs generalize other graphical models, one might wonder how our method stacks up against algorithms tailored to the more traditional models. In brief: our algorithm is much slower, and only handle much smaller networks.
 Concretely, our methods can handle all of the ``small'' networks, and some of the ``medium'' ones, from the \href{https://www.bnlearn.com/bnrepository/}{\texttt{bnlearn}} repository.
  In these cases, we have verified that the two methods yield the same results.
  \Cref{fig:bn-gap-v-time} contains the analogue of \cref{fig:joint-gap-time,fig:clus-gap-vs-time}
  for the Bayesian Nets. This graph looks qualitatively quite similar to the other graphs we've seen, suggesting that the results in our synthetic experiments hold more broadly for small real-world models as well.




 \begin{figure}
     \includegraphics[height=0.45\textheight]{figs/1}
     \caption{
         A variant of \cref{fig:resources}, with
         with gap (accuracy) information on the left, and slightly different parameter settings.
     }\label{fig:gap-resource-fine-old}
 \end{figure}


\end{subappendices}
