
\subsection{Basic Notation}
If $A$ is a finite set, we write $\#A$ or $|A|$ for its cardinality.
We will often be concerned with \emph{variables}, which intuitively correspond to aspects of the world or properties of some object. 
Mathematically, a variable has two aspects.
Qualitatively, a variable is just some unique identifier (the variable name),
    such as ``height''.
Quantitatively, a variable $X$ is also associated with a set $\V(X)$, or simply $\V\!X$, of possible values. 
For example, $\V(\text{height})$ might be the set of positive real numbers, 
    or the set $\{ \texttt{short}, \texttt{tall} \}$. 

\subsection{Algebra}
\begin{defn}[Monoid]%
    A \emph{monoid} is a tuple $(S, *, e)$, where $S$ is a set, $* : S \times S \to S$ is a binary operation, and $e \in S$ is a distinguished identity element, such that:
    \begin{itemize}[itemsep=0pt,parsep=0pt,topsep=0pt,]
        \item (associativity) $\forall a, b,c \in S.~~(a*b)*c = a*(b*c)$;
        \item (identity) $\forall a \in S.~~a * e = a = e * a$.
    \end{itemize}
    A monoid is called \emph{commutative} if it also satisfies
    \begin{itemize}[nosep]
        \item (commutativity): $\forall a, b \in S.~~ a * b = b * a$,
    \end{itemize}
    and \emph{idempotent} if it satisfies
    \begin{itemize}[nosep]
        \item (idempotence): $\forall a \in S.~~ a + a = a$. 
    \end{itemize}
    An idempotent semiring defines partial order by $a \le b \iff a + b = b$. 
\end{defn}

\subsection{Relations}

Let $\mathcal X = \{ X_1, \ldots, X_n \}$ be variables, traditionally called atributes. 
A \emph{relation} $R(\mathcal A) = R(X_1, \ldots, X_n) \subseteq 
\V(X_1) \times \cdots \times \V(X_n)$, or equivalently, $R : \prod_{i=1}^n \V\!X_i \to \{0,1\}$, is a subset of joint values of attributes. 
The natural number $n$ is called the \emph{arity} of $R$. 


The \emph{natural join} of two relations $R(A,B)$ and $S(B,C)$ combines them in a particularly obvious way: $(a,b,c) \in R \bowtie S$ iff $(a,b) \in R$ and $(b,c) \in S$. 
More generally, we have

\begin{defn}[natural join]
    $R(\mathcal X) \bowtie S(\mathcal Y)
        := 
        \Big\{
            \boldsymbol\omega \in  \V(\mathcal X \cup \mathcal Y)
            ~\Big|~
            \mathcal X(\boldsymbol\omega) \in R \land
            \mathcal Y(\boldsymbol\omega) \in S
        \Big\}.
    $
\end{defn}

At one extreme, if $\mathcal X$ and $\mathcal Y$ are disjoint sets of attributes, then $R(\mathcal X) \bowtie S(\mathcal Y)$ coincides with the cartesian product of $R \subseteq \V \mathcal X$ and $S \subseteq \V\mathcal Y$.
At the opposite extreme, if $\mathcal X = \mathcal Y$ are the same set of variables, then $R(\mathcal X) \bowtie S(\mathcal X)$ coincides with the intersection of the subsets $R$ and $S$. 

Even when $A_1, \ldots, A_n \subseteq \X$ are not disjoint, we give a convenient extended syntax by defining the quantity $R(a_1, \ldots, a_n)$, where $a_i \in \V(A_i)$. 
Concretely, define $R(a_1,\ldots, a_n) := 0$ if when $\{a_1, \ldots, a_n\}$ do not agree on the value of some shared attribute (i.e., if $\exists X \in \X, \exists i,j \in [n]. ~X \in A_i \cap A_j \land X(a_i) \ne X(a_j)$).
When $\{a,b,c\}$ do agree on all values of shared attributes, let $\mat x$ denote the joint value of $A \cup B \cup C$ obtained from $(a,b,c)$ by removing redundant copies of variable values.
In this case, define $R(a,b,c) := R(\mat x)$. 


\subsection{Graph Theory}
\begin{defn}
    A \emph{(directed) (multi) graph} $G = (N, A)$, or simply a \emph{graph}, is a set $N$ of nodes,
    and a collection $A$ of arcs, such that each $a \in A$ has a source node $\Src a \in N$ and a target node $\Tgt a \in N$.
    So, formally, the definition is
    $G = (N, A, \Src{}, \Tgt{})$, with $\Src{},\Tgt{}: A \to N$ often left implicit.
\end{defn}

\begin{defn}[Undirected (Multi) Graph]
    An undirected (multi)graph $G = (N,E)$ is a set $N$ of vertices (or nodes)
    and a set $E$ of edges,
    each element $e \in E$ of which
    corresponds to an unordered pair of vertices $\{u,v\}$.
    More formally, there is a map
    \[
        \iota: E \to~ \faktor{ V \times V \setminus \{(v,v):v \in N\} }{ \{(u,v)\sim(v,u)\mid (u,v) \in N \times N\} }~.
    \]
    implicit in the definition of $G$, which we will write $G =
    % (V,E{,~ \color{gray}\iota})$ 
     (N,E, \iota)$ 
    only when being extra careful.
    \qedhere
\end{defn}

It is common to identify a graph $H = (N,A)$ (or an undirected graph $G = (N,E)$) with its (symmetric) adjacency matrix
\[
    \mathbb A_H = \Big[ \#\Big\{ a \in A : \begin{array}{c}\Src a = u,\\ \Tgt a = v \end{array} \Big\} \Big]_{(u,v) \in N \times N}
    \qquad
    \mathbb A_G = \Big[
    \#\{ e \in E : \iota(e) = \{u,v\}         \Big]_{(u,v) \in N\times N}~~,
\]
in part because there is a natural bijection between
(undirected) multigraphs and (symmetric) square matrices
over the natural numbers.  
For example:
\[
    \begin{bmatrix}
        0 & 1 & 2 \\
        1 & 0 & 0 \\
        2 & 0 & 1
    \end{bmatrix}
    \qquad
    \leftrightsquigarrow
    \qquad
    \begin{tikzpicture}[center base]
        \begin{scope}
            % \node at (0:1) (a) {a};
            % \node at (120:1) (b) {b};
            % \node at (-120:1) (c) {c};
            \node at (0,0) (a) {a};
            \node at (1,0) (b) {b};
            \node at (-1,0) (c) {c};
        \end{scope}
        \draw[-] (a) to (b);
        % \draw (a) to[bend left] (b);
        % \draw (b) to[bend left] (a);
        
        \draw[-] (a) to[bend left] (c);
        \draw[-] (a) to[bend right] (c);
        
        \path[every loop/.style={}] (c) edge[loop above] (c);
    \end{tikzpicture}
\]

A (directed) graph has more information than an undirected one.
There are natural ways to convert between the two: one forgets the direction of arcs to turn a directed graph into an undirected one, and annotates each arc with arrows in both directions to make an undirected graph directed. These choices are essentially locked in if we want the correspondence with square matrices to hold properly. 
\[ 
\begin{tikzcd}
\text{(Directed) Graphs} \ar[r,bend left,"\mathit{forget}"]&
\text{Undirected Graphs}
\ar[l,bend left,"\mathit{annotate}"]
\end{tikzcd}
\]
in which
$\mathit{forget} \circ \mathit{annotate} = \id_{\text{Undirected Graphs}}$
but
$\mathit{anotate} \circ \mathit{forget}$ is not the identity on (directed) graphs. Technically, this makes $\mathit{forget}$ a \emph{retraction}, and $\mathit{annotate}$ a \emph{section}.

\begin{defn}
    A bipartite graph $G = (L, R, E)$ is a graph $(L \sqcup R, E)$ whose
    vertices are partiioned into two components $V = L \sqcup R$, 
    and whose edges $E \subset L \times R$ are only between $L$ and $R$. 
\end{defn}


\fadeout{ \begin{defn}
    A directed bipartite graph $G = (L, R, E)$ is a bipartite graph $(L, R, E)$ whose edges $E \subset (L \times R) \cup (R \times L)$ are directed. 
    \end{defn} }


\begin{defn}
    A \emph{hypergraph} $G = (V, \mathcal E)$ is a set $V$ of vertices,
    and a collection $\cal E$ of edges, which correspond to finite
    subsets of vertices. 
\end{defn}

Thus, a hypergraph is the generalization of an undirected graph in which the codomain of $\iota : \mathcal E \to 2^V$ is arbitrary subsets of $V$, not just those of cardinality 2. 


\begin{prop} 
There is a natural bijection between hypergraphs and bipartite graphs:
% \def\bitgr{\mathit{BG}}
\def\bigr{\mathit{bipart}}
% \def\bitgr{\mathit{HG}}
\def\hygr{\mathit{hyper}}
\begin{align*}
    \bigr(V, \mathcal E) &:=  (V, \mathcal E, \{(v, E) \in V \times \mathcal E : v \in E \} ) \\
    % (L, \{\{x \in L : \} \}) &\maspfrom (L, R, E)
    \hygr(L, R, E) &:= (L, \{\{v \in L : (v,r) \in E\} : r \in R\}),
\end{align*}    
    \[
        \bigr \circ \hygr = \mathrm{id}_{BG}
        \quad\text{and}\quad
        \hygr \circ \bigr = \mathrm{id}_{HG}.
    \]
\end{prop}

The consequences of this can be unintuitive.
It is common to think of bipartite graphs as a strict (particularly nice) special case of ordinary undirected graphs, which themselves are a strict (particularly easy to draw) strict special case of hypergraphs.  
By transitivity, one might expect bipartite graphs to naturally be an extremely strict special case of hypergraphs---yet in fact they are naturally isomorphic. 

\begin{defn}
    A \emph{directed} hypergraph $(N, \mathcal A)$ is a set $N$ of nodes,
    and a collection $\Ar$ of hyperarcs, each of which has a set $S_a \subset N$ of
    source variables and a set $T_a \subset N$ of target variables.        
\end{defn}

A directed hypergraph $(N, \mathcal A)$ can be equivalently defined as an (ordinary) directed graph $(2^N, \Ar)$ whose set of nodes is the powerset of some set $N$. 

\medskip
\hrule
\medskip

\begin{defn}
The \emph{dual} of the hypergraph $G = (V, \mathcal E)$ is
\(
    \check G := (\mathcal E, \{\{e \in \mathcal E : v \in e\} : v \in V\})
\).
\end{defn}

\begin{defn}
    The \emph{dual} of a directed hypergraph $\mathcal H = (N, \Ar)$ is 
    \(
        \check{\mathcal H} := (\mathcal A, N)
    \),
    where
    \[
    \check{\Src n} = \{ a \in \Ar : n \in \Tgt a\} \quad\text{and}\quad
    \check{\Tgt n} = \{ a \in \Ar : n \in \Src a\}.
    \qedhere
    \]
\end{defn}

% \begin{prop}
We now verify that $\check{\check{\mathcal H}} = \mathcal H$.
Observe that 
\begin{align*}
    \check{\check{\Src a}}
    &= \{ n \in N : a \in \check{\Tgt n} \} \\
    &= \{ n \in N : a \in \{ a' \in \Ar :  n \in \Src a' \} \} \\
    &= \{ n \in N : n \in \Src a\} \\
    &= \Src a;
\end{align*}
% \end{prop}
symetrically, $\Tgt a = \check{\check{\Tgt a}}$. 
% What does this look like?
% To visualize . 
% One might wonder why $\check\Src n$ is definde in terms of $\Tgt a$ instead of $\Src a$.

See \cref{fig:dhygraph-duals} for some visual illustrations.
\begin{figure}%
    \centering
% \begin{tabular}{c}
    \begin{tikzpicture}[xscale=1.2,center base]
    \begin{scope}[every node/.style={draw,rounded corners=5pt,outer sep=2pt}]
        \node[] (X) at (0,1) {X};
        \node[] (Y) at (1,1) {Y};
        \node[] (Z) at (2,1) {Z};
    \end{scope}
        \draw[arr1,<-] (X) to node[above]{\small 1} +(-0.9,0);
        \draw[arr1] (X) to node[above,pos=0.35]{\small 2} (Y);
        \draw[arr1] (Y) to node[above,pos=0.35]{\small 3} (Z);
    % \end{tikzpicture}\\
    % \begin{tikzpicture}
        \node[draw,outer sep=2pt] (1) at (-0.5,0) {1};
        \node[draw,outer sep=2pt] (2) at (0.5,0) {2};
        \node[draw,outer sep=2pt] (3) at (1.5,0) {3};
        \draw[->,arr1] (1) to node[below,pos=0.35]{\small X} (2);
        \draw[->,arr1] (2) to node[below,pos=0.35]{\small Y} (3);
        \draw[arr1,] (3) to node[below,pos=0.35]{\small Z} +(0.9,0);
    \end{tikzpicture}
    \hfill
    \begin{tikzpicture}[xscale=1.2,center base]
    \begin{scope}[every node/.style={draw,rounded corners=5pt,outer sep=2pt}]
        \node (A) at (0,0) {A};
        \node (B) at (1,0.6) {B};
        \node (C) at (1,-0.6) {C};
        \node (D) at (2,0) {D};
    \end{scope}
        \draw[arr1,<-] (A) to node[above]{\small 1} +(-0.9,0);
        \draw[arr1] (A) to node[above,pos=0.35]{\small 2} (B);
        \draw[arr1] (A) to node[below,pos=0.35]{\small 3} (C);
        \mergearr[arr1] BCD
        \node[above=1pt of center-BCD]{\small 4};
    % \end{tikzpicture}\\
    % \begin{tikzpicture}
    \begin{scope}[shift={(-0.5,-2)}]
        \node[draw,outer sep=2pt] (1) at (0,0) {1};
        \node[draw,outer sep=2pt] (2) at (1,0.6) {2};
        \node[draw,outer sep=2pt] (3) at (1,-0.6) {3};
        \node[draw,outer sep=2pt] (4) at (2,0) {4};
        \unmergearr[arr1] 123
        \node[above left=1pt and 1pt of center-123]{\small A};
        \draw[arr1] (2) to node[above,pos=0.35]{\small B} (4);
        \draw[arr1] (3) to node[below,pos=0.35]{\small C} (4);
        \draw[arr1,] (4) to node[above]{\small D} +(0.9,0);
    \end{scope}
    \end{tikzpicture}% \end{tabular}
    %
    \hfill
    %
    \begin{tikzpicture}[xscale=1.2,center base]
    \begin{scope}[every node/.style={draw,rounded corners=5pt,outer sep=2pt}]
        \node[draw,outer sep=2pt] (X) at (0,0) {$X$};
        \node[draw,outer sep=2pt] (Y) at (1,0) {$Y$};
    \end{scope}
        \draw[arr1] (X) to node[above,pos=0.35]{\small 1} (Y);
        \draw[arr1,<-] (Y) to node[above]{\small 2} +(0.9,0);
        %
        \begin{scope}[shift={(0.5,-1.5)}]
        \node[draw,outer sep=2pt] (1) at (0,0) {1};
        \node[draw,outer sep=2pt] (2) at (1,0) {2};
        \draw[arr1,<-] (1) to node[above]{\small $X$} +(-0.9,0);
        % \draw[arr1] ()
        \coordinate (a) at (0.5,-0.5);
        \mergearr[arr1] 12a
        \node at (0.5,0) {\small $Y$};
        \end{scope}
    \end{tikzpicture}
    \caption[Examples of directed hypergraphs and their duals]
    {Examples of directed hypergraphs (first row) and their duals (second row).}
        \label{fig:dhygraph-duals}
\end{figure}%
We remark that
the left and center diagrams on the top can be viewed as (the hypergraphs corresponding to) qualitative Bayesian Networks, by regarding X,Y,Z and A,B,C,D as variables, and imagining that there is a (randomized) causal determination occuring along each arc. 
% The structures that arise from causal models
One can also imagine an analogue with cycles---resuling in perhaps a (randomized) causal model of the given shape.  But a causal model has one equation corresponding to each variable, and the corresponding hypergraphs thus has exactly one hyperarc leading to it. 
In the dual hypergraphs, one should view the nodes as processes and the arcs as wires. Such a hypergrah has precisely one hyperarc leading out of every node. When wires branch, one imagines a copy; when two arcs point to the same process (as in process 4, in the middle center), that process takes both of the wires as inputs.
In the duals of hypergraphs corresponding to causal models, there are no two-tailed arrows, which might be thought of as a ``merge''. 
Yet it is not clear how to merge the values of two variables, when they are not the same, in general---especially if we expect associativity and commutativity, as we do with \emph{copy}. 

((What can be done with these objects? ))


\subsection{Categories}
Category theory is a mathematical inderlingua that captures the essential form of many arguments across mathematics. 
Sometimes (lovingly) called ``abstract nonsense'', category theory is often seen as extremely abstract meta-mathematics.  
% But it can be much more concrete and easier to understand than the traditional mathematical disciplines that reference it. 
Nevertheless, the basics more concrete and simpler than one might imagine.
% from the fields that algebraic topology.
At its core, it's essentially just the mathematic underpinnings of typed composition.  

\begin{defn}[category]
    A \emph{category} $\mathcal C$ consists of four pieces of data:
    \begin{itemize}[left=0pt,topsep=0pt]
        \item a collection of \emph{objects} $\ob_{\cal C}$;
        \item a collection of \emph{morphisms}
            $\Hom_{\mathcal C}(X,Y)$,  also written $\mathcal C(X,Y)$, for each pair of objects $(X,Y) \in \ob_{\mathcal C}^2$;
        \item a \emph{composition} operator 
        $\circ_{X,Y,Z}: \mathcal C(Y,Z) \times \mathcal C(X,Y) \to \mathcal C(X,Z)$ for each triple $(X,Y,Z) \in \ob_{\cal C}^3$, that is written inline (i.e., $f \circ g$ instead of $\circ(f,g)$), and is associative, i.e., $(f \circ g) \circ h = f \circ (g \circ h)$;
        \item a special \emph{identity element} $\id_{X} \in \mathcal C(X,X)$ for each object $X \in \mathcal C$, satisfying $\id_X \circ f = f$ and $g \circ \id_X = g$ for any morphism $f \in \mathcal C(Y,X)$ or $g \in \mathcal C(X,Y)$ for some $Y \in \ob_{\mathcal C}$.
        \qedhere
    \end{itemize}    
    % Note that the subscript $X,Y,Z$ on $\circ_{X,Y,Z}$ is almost always dropped and inferred from context, and the elements of $\mathcal C(X,Y)$ are referr
    % This means we are effectively instead  a polymorphic fuction $\circ : \forall X,Y,Z \in \ob_{\mathcal C}.~\mathcal C(Y,Z) \times \mathcal C(X,Y) \to \mathcal C(X,Z)$.
\end{defn}

Common examples of categories include:
\begin{itemize}[left=0pt,noitemsep,topsep=0pt]
\item    
 $\Set$, the category whose objects are sets and whose morphisms are functions between them,  

\item 
$\Top$, the category whose objects are topological spaces and whose morphisms are continuous maps,

\item 
$\Rel$, the category whose objects are sets, and whose morphisms are relations, and

\item $\Diff$, the category of smooth manifolds (possibly with boundary or corners) and differentiable maps. 

\end{itemize}

All of these are also known as ``conrete categories'', because they all build on \Set: their objects can be interpereted as sets, and their morphisms interprereted as functions. 
But categories can also be much more combinitorial in nature. 
We will be much more interested in dinkier categories.
Here are some more extreme kinds of categories:

\begin{itemize}[]
    \item A category with one object is just a monoid---observe that $\circ$ is associative and has an identity. 
     % In this case, all information is in the set of morphisms from the unique object to itself, and the way they compose. 
    
    \item At the opposite extreme, a category with only identity morphisms is just a collection of objects. 
    
    \item A category with at most one morphism between any two objects is a preorder---in this case we write $a \le b$ iff there is a morphism from object $a$ to object $b$; the relation is reflexive because of the identity, and transitive because of composition. 
\end{itemize}

What will be most relevant for our purposes is a construction 

\begin{defn}[free category generated by a graph]
    \label{def:freecat}
    If $G = (N, A)$ is a directed (multi) graph with nodes $N$ and arrows $A$, the \emph{free category generated by $G$} is the category 
    % $\mathrm{Paths}(N,A)$
    $G^*$,  whose objects are the elements of $N$, and whose set of morphisms from $x$ to $y$, for $x,y \in N$, is the collection of paths from $x$ to $y$.
    That is, 
    \[
        \ob_{G^*} = N, \qquad
            G^*(x,y) = \Big\{\text{ sequences }
                \langle a_1, \ldots, a_n\rangle ~\Big|~
                \begin{array}{c}
                n \in \mathbb N,\;\;
                n>0 \Rightarrow (\Src{a_1} = x \land \Tgt{a_n} = y),\\
                % n>1 \Rightarrow (
                \forall i \in \{1, \ldots,n-1\}.~\Tgt{a_i} = \Src{a_{i+1}} 
                % x = x_1, x_n = y,  x_
                \end{array}
                \Big\},
    \]
    with composition given by sequence concatenation, and the identity being the empty sequence. 
    % , generated by the arrows of $A$ and identity self-loops from variables to themselves. 
    % 
    % \begin{align*}
    %     \mathrm{ob}~
    % \end{align*}
\end{defn}

% Observe that the notation $A^*$ does not depend on $N$. 

The superscript-star notation has some standard meanings throughout mathematics, and this construction in \cref{def:freecat} reduces to several of them in the appropriate contexts. 

% interstingly the construction of \cref{def:freecat} recovers several
% of these standard notion.
    
\begin{itemize}
    \item 
A (multi) graph $G = (\{\ast\}, A)$ with one vertex can be identified with its arc set $A$. Every arrow has the same type ($\ast \to \ast$), and so a path is a sequence 
% $a_1.a_2.\,...\,.a_n$
$\langle a_1, a_2, ..., a_n\rangle$
where each $a_i \in A$. 
So in this case, $G^*$ (as given by \cref{def:freecat}) coincides
with the familiar set of strings $A^*$ over the alphabet $A$.

    \item
Let $R \subseteq V \times V$ be a binary relation on $V$.
Then the transitive closure of $R$, often denoted $R^*$,
    is the reachability relation generated by $R$. 
That is, $(u,v) \in R^*$ if and only if there is a path $\langle u{=}u_1,\, \ldots, u_n{=}v\rangle$ with each $(u_i, u_{i+1}) \in R$.

    % \item 
    % We now revisit the previous example from an alternate perspective. 
Equivalently, we can view $R$ as a graph $G = (V,R)$ by regarding each $(i,j) \in R$ as an arrow $i \to j$. The free category $G^*$ generated by these arrows (per \cref{def:freecat}) has an arrow from $u$ to $v$ (i.e., $G^*(u,v) \ne \emptyset$) iff $(u,v) \in R^*$.

\item 
% Continuing the preivous example, given a matrix
% If a  matrix $A \in \overline{\mathbb N}^{n\times n}$
A (directed) (multi) graph $G$ on $n$ vertices also has an adjacency matrix 
$A := \mathbb A_G \in \mathbb N^{n\times n}$.  Square matrices over a semiring
also have notion of a star, given by:
\[
    A^* = \sum_{n=0}^\infty A^n  \in \overline{\mathbb N}^{n\times n},
    \qquad \text{ where } \overline{\mathbb N} := \mathbb N \cup \{\infty\}.
\]
And, yet again, we have $\#G^*(i,j) = (\mathbb A_G^*)_{i,j}$
\end{itemize}


What about hypergraphs?
% Let $(N, \mathcal A)$ be a directed hypergraph. 
The free category generated by a directed hypergraph
$(N, \mathcal A)$
 % has objects equal to the powerset of $N$, 
is the free category generated by 

% How should we define the composition of two hyperarcs? 

\begin{defn}
    
\end{defn}


\subsection{Measures and Probabilities}

\begin{defn}[Measurable Space]
    A measurable space is a pair $(X, \mathcal F_X)$, where $X$ is a set, and   $\mathcal F_X$ is a sigma-algebra over $X$, which is to say a set of subsets of $X$, containing the empty set, and closed under countable union, intersection, and complement with respect to $X$.
    The elements of $\mathcal F_X$ are referred to as measurable sets.
\end{defn}

\begin{defn}[Measure]
    A \emph{measure} $\lambda$ over a measurable space $(X, \mathcal F)$ is a function $\lambda : \mathcal F \to \mathbb R \cup \{\infty\}$, with the follwing properties.
    \begin{itemize}[itemsep=0pt]
        \item \textbf{Null Empty Set.} $\lambda(\emptyset) = 0$.
        \item \textbf{Non-negativity.} $\lambda(U) \ge 0$ for all $U \in \mathcal F$.
        \item \textbf{Countable additivity.} 
            For every coutable collection 
            $\{U_i\}_{i=1, 2, \ldots}$
            of pairwise disjoint measurable sets ($U_i \in \mathcal F$), we have
            $\sum_{i} \lambda(U_i) = \lambda(\sqcup_i U_i)$.
    \end{itemize}
\end{defn}

\begin{defn}
    Consider a measure $\lambda$ on a mesurable space $\mathcal X = (X, \mathcal F)$.
    \begin{enumerate}
        \item If $\lambda(X) = 1$, then $\lambda$ is a \emph{probability} measure. 
        \item If $\mathcal T$ is a topology on $X$, and 
            $\lambda(U) > 0$ for every non-empty open set $U \in \mathcal F \cap \mathcal T$, then $\lambda$ is said to be \emph{strictly positive} (wrt $\cal T$).
        \item The measure $\lambda$ is called \emph{$\sigma$-finite} if $X$ can be
        covered with a countable set of sets with finite measures --- that is, if
        there exist countable sequence $(A_1, A_2, \ldots ) \subset \mathcal F$ the
        such that each $\lambda(A_i) < \infty$ is finite, and $X = \cup_{i=1}^{\infty}
        A_i$.
        \qedhere
    \end{enumerate}
\end{defn}

\begin{defn}[Measurable Functions]
    If $\mathcal X  = (X, \mathcal F)$, and $\mathcal Y = (Y, \mathcal G)$ are two measurable spaces, a measurable function $f : \mathcal X \to \mathcal Y$ is a function $f: X \to Y$ on the underlying spaces, such that 
    $f^{-1}(U) \in \mathcal F$ for every $U \in \mathcal G$.
\end{defn}

It is easy to verify that identity maps are measurable, and that, when $f$ and $g$ are measurable, so is $f \circ g$. 
It follows that there is a category $\Meas$ whose objects are measurable spaces, and whose maps are measurable functions. 


\begin{defn}[absolute continuity]
    If $\mu$ and $\nu$ are measures over a space $(X, \mathcal F)$, 
    we say that $\mu$ is absolutely continuous with respect to $\nu$, denoted $\nu \ll \mu$, if, for every $U \in \mathcal F$ such that $\nu(U) = 0$, we also have $\mu(U) = 0$. 
\end{defn}

\begin{defn}[Radon-Nikodym Derivative]
    Suppose $\mu$ and $\nu$ are both measures over a measurable space $(X,\mathcal F)$, and $\mu \ll \nu$. 
    The Radon-Nikodym theorem states that there is then a unique $\mathcal F$-measurable function $f$
    such that for all $A \in \mathcal F$,
    \[
        \mu(A) = \int_{A} f \,\mathrm d \nu.
    \]
    The function $f$ is called the Radon-Nikodym derivative, and
    denoted $\frac{\mathrm d\mu}{\mathrm d\nu} := f$.
\end{defn}

\begin{defn}[Markov Kernels]
    If $\mathcal X  = (X, \mathcal F)$, and $\mathcal Y = (Y, \mathcal G)$ are two measurable spaces, a Markov Kernel $\kappa : \mathcal X \to \mathcal Y$, which we sometimes write as ``$\kappa(Y|X)$'', is a function $\kappa : X \times \mathcal G \to \mathbb R$, such that
    \begin{enumerate}
        \item For every $x \in X$, the map $\kappa(x, -) : \mathcal U \to [0,1]$ is a probability measure. (So $\kappa$ is also a cpd.)
        \item For every $U \in \mathcal G$, the map $\kappa(-, U) : X \to [0,1]$ is a measurable function from $\mathcal X$ to the Borell space $[0,1]$.
        Or more explicitly: for every open set $S \subseteq [0,1]$, and $U \in \mathcal G$, we have that
        $\{x : \kappa(x,U) \in S\} \in \mathcal F$. 
\end{enumerate}
\end{defn}

\begin{defn}
    % [stochastic category]
    [category of measurable spaces and Markov kernels]
    Let $\Stoch$ be the category whose
    objects are measureable topological spaces with a base measure, and 
    whose morphisms are Marov kernels that are absolutely continuous with respect to the base measure.
    Concretely,
    the objects of $\Stoch$ are pairs $(\mathcal X, \lambda)$, where $\mathcal X$ is a mesurable topological space, and $\lambda$ is a strictly positive and $\sigma$-finite measure on $\mathcal X$.
    % \begin{align*}
    %     \mathrm{ob}~\Stoch &= \Big\{ \text{pairs}~(\mathcal X, \lambda),
    %         ~\text{where $\mathcal X$ is a mesurable space, and $\lambda$ is a measure on $\mathcal X$} \Big\}%\\
    % \end{align*}
        % \Stoch(\lambda(X), \mu(Y)) &= \Big\{ \text{Markov Kernels $p(Y|X)$ such that} \\
        % 
        %     & \Big\}    
        % \end{align*}
    % and for objects $(X,\mathcal F_X \lambda_X)$ and
     % $(\mathcal Y = (Y,\mathcal G), \mu_X)$, 
    The collection of morphisms from 
    $(X,\mathcal F_X, \lambda_X)$ to $(Y, \mathcal F_Y, \lambda_Y)$ is the 
    set of Markov Kernels $\kappa : \mathcal X \to \mathcal Y$
    such that 
    % $\mu \ll \kappa(x)$ for all $x$.        
    $\kappa(x,-) \ll \lambda_Y$ for all $x$.        
    %   $\Stoch(, (\mathcal Y, \mu))$ from $(\mathcal X, \lambda)$ to $(\mathcal X, \mu)$
    % are Markov Kernels $\kappa : \mathcal X \to \mathcal Y$ such that 
    The reason we require this is so that the Radon-Nikodym derivative
    $\frac{\mathrm d \kappa(x)}{\mathrm d\lambda}$, i.e., the unique 
    $\mathcal F_Y$-measurable function satisfying
    \[ 
        \forall x. \forall A \in \mathcal F_Y.\qquad
        \kappa(x,A) = \int_{A} \frac{\mathrm d \kappa(x)}{\mathrm d\lambda} \mathrm d \lambda~,
        \qquad\text{exists.}
    \]
    
    Composition in $\Stoch$ is given by Lebesgue Integration: for Markov Kernels $p(Y|X) : \mathcal X \to \mathcal Y$ and $q(Z|Y) : \mathcal Y \to \mathcal Z$, define
    $(p \circ q) : \mathcal X \to \mathcal Z$  (i.e., $p \circ q : X \times \mathcal F_Z \to [0,1]$) by:
    \begin{align*}
        (p\circ q)(x, U) :=& \int_{\mathcal Y}
            q(-, U)
            \mathrm d p(x,-).
            % \overbrace{q(-, U)}^{\mathcal Y\text{-measurable function}}
            % \mathrm d \overbrace{p(x,-)}^{\text{a measure of }\mathcal Y}
    \end{align*}
    This typechecks because $q(-,U)$ is a $\mathcal Y$-measurable function, and $p(x,-)$ is a measure on $\mathcal Y$. 
    We must also prove that the result is a Markov Kernel, which we do below. 
    % for $U \in \mathcal F_Z$
    The identities are given by
    \begin{align*}
    \mathrm{id}_{\mathcal X}(x, U) &= \begin{cases}
            1 & \text{ if }x \in U \\ 0 & \text{otherwise}
        \end{cases}.
    \end{align*}
    These functions are clearly identities, but are they Markov kernels,
    and can they be made absolutely continuous with respect to our
    base measure?
    
    {\color{red}
    % Then, 
    More explicitly:
    \[
        \mathrm{id}_{\cal X}(x,-) \ll \lambda_X
        \quad\iff\quad
        \Big( \lambda_X(A)=0 ~~\Rightarrow~~ x \notin A\Big),
    \]
    and so there is a problem if we can find $A \subset \V X$ with
    $\lambda_X(A) = 0$ but $x \in A$. Or equivalently, a non-empty
    subset $A \subseteq \V\! X$ that has measure zero. By strict positivity,
    this means $A$ cannot be an open set. 
    
    In the discrete case, in which every variable can take a finite set of values,
    and every subset is measurable and clopen, this is not a problem so long
    as the base measure gives every element positive probability.
    
    % takes a finite set of values, over which the base measure $\lambda(Y)$ is uniform, for all $Y$. 
    }
\end{defn}

% \TODO[
%     Possible to have other identity morphisms? Require that, for each $X \in \N$, the identity morphism $\dg M(\ed {\mathrm{id}}XX)$ preserves the base measure $\lambda_X$, in addition to pre/post committing 
% ]

% \begin{fact}
%     All morphisms 
% \end{fact}

\subsection{Independencies}

\subsection{Information Theory}

\subsection{Graphical Models}

There are two aspects any graphical model: 
a ``qualitative/structural'' aspect, which describes influences between variables, and
a ``quantitative/observational'' aspect, 
    that annotates those influences with data.

A qualitative BN, for example, is a directed graph whose semantics are given in terms of independencies: any variable $X$ is independent of its non-descendents, given the values of its parents, $\mathbf{Pa}\, X$.  
A quantitative BN, then, includes both that directed graph, and also each variable $X$ to a conditional probability distribution $\Pr_X(X|\mathbf{Pa}\, X)$.
