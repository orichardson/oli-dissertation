% You try to give a big-picture
% summary of what you've  done, perhaps suggest some avenues for future
% work (I would suggest that you do this under the assumption that there
% will be no extra chapters), and perhaps conclude with what you see as the
% potential impact of PDGs on the field.

\section{Summary}

We have now seen a far-reaching unified account of probabilistic modeling,
% and one that is able to step outside the bounds of consistency 
    with implications far beyond the usual limits of probabilistically consistent reasoning. 
%
This theory is based on probabilistic dependency graphs (PDGs), an extremely expressive probabilistic modeling language.
As we saw in \cref{part:univ-model}, PDGs can capture essentially every standard fragment of epistemic information, ranging from traditional probabilistic graphical models such as Bayesian Networks and factor graphs (\cref{chap:pdg-repr}) to standard representations of uncertainty (\cref{chap:repr-tools}).
% The qualitative information in a PDG spun off another 
A PDG has two kinds of information: structural, and observational.
Understanding the meaning of just the structural information in a PDG has been fruitful, leading to a generalized notion of independence that seems to be the beginning of a bridge between (possibly cyclic) causal models and multivariate information theory (\cref{chap:QIM}). 
%
% And, as we saw in
% As evidenced by many of the results in \cref{part:univ-objective}, the observational information is perhaps even more useful. 
The observational information in a PDG is even more useful. 
With it, PDGs can capture systems composed of neural networks; moreover, 
    the degree of observational inconsistency of the resulting PDG always seems to be the standard loss function used to train the model in question (\cref{chap:one-true-loss}),
Furthermore, a wide variety of standard algorithms can be viewed as instances of a simple approach to resolving inconsistencies (\cref{chap:LIR}).
Indeed, learning, inference, and 
    much else can be viewed as different aspects of a single objective: the pursuit of consistency. 

In \cref{part:algo-logic-complexity}, we saw how these two views of PDGs---as a very general kind of probabilistic model, and as a universal objective function (the foci of \cref{part:univ-model,part:univ-objective}, respectively) are in fact two faces of the same concept, both semantically and algorithmically (\cref{chap:inc-infer-connection}). 
We also gave polynomial algorithm for inference in PDGs that have bounded treewidth (\cref{chap:infer}), finally solving both problems. 
% {\color{red}%
We also develop useful principles for manipulating PDGs, 
    allowing them to function as a visual proof language (\cref{chap:reason}).
% }%


% \commentout{%
\paragraph{Sewing things back together, with self-consistency.}
\def\selfconsist{\xi}
We conclude our summary by reframing a handful of our simpler results in slightly different form.
A PDG's degree observational inconsistency is a number in $[0,\infty]$;
it is also additive, in the sense that $\aar{\dg M_1 + \dg M_2} = \aar{\dg M_1} + \aar{\dg M_2}$ when $\dg M_1, \dg M_2$ are PDGs over disjoint sets of variables. 
\iffoundations
    As shown in \cref{chap:conf}, additive measures
\else
    Additive measures
\fi
in the range $[0,\infty]$ 
can be equivalently represented as multiplicative measures in $[0,1]$.
% and the set of such isomorphisms itself is isomorphic to $(0,\infty)$. 
% For $k > 0$, 
So, for readers who are more comfortable with the latter range, we quickly summarize a few of our results.  
% in a way that might make the

% In service of this, 
% Let the \emph{(observational) self-consistency} of a PDG $\dg M$ be
% quantity
% Given objects $M_1, M_2, \ldots$,
% each of which can be implicitly converted to a PDG
Suppose that $M_1, M_2, \ldots$ are objects that, based on the theory developed in this dissertation, can be viewed as PDGs.
Writing $\dg M_{1}, \dg M_{2}, \ldots$ denote the corresponding PDGs, 
define the \emph{(observational) self-consistency} of $M_1, M_2, \ldots$
to be the quantity
% to be
\[
    % \Xi[\dg M] := \mathfrak\exp( -  \aar{\dg M}_0) ~~\in[0,1]. 
    \selfconsist\{ M_1, M_2, \ldots \} := \mathfrak\exp\Big( 
        -  \aar[\big]{
            % \dg M_{M_1} + \dg M_{M_2} + \cdots
            \dg M_{1} + \dg M_{2} + \cdots
        }_0\Big) ~~\in[0,1]
\]
% be the \emph{(observational) self-consistency}
that results from converting each object to a PDG, 
    joining them together, 
    and then reporting their overall (lack of) inconsistency in the form
    of a score in the range $[0,1]$. 
% This allows us to reframe some of the properties we have already seen in a way that, to some, may look even more natural in this form.
The following facts are either immediate or follow immediately from a result in \cref{chap:repr-tools} or \ref{chap:one-true-loss}.
% We can summarize and reframe a number of the properties we have seen in terms of the self-consistency $\Xi[\dg M]$
% \begin{prop}
\begin{itemize}
    \item 
    A flat out logical contradiction has $\selfconsist\{\False\} = 0$ because it is completely inconsistent, while a collection of fully consistent probabilistic information $\dg M$ (such as a Bayesian Network or probability distribution) has $\selfconsist\{ \dg M \} = 1$. 

    \item If $U$ is an event, then $\selfconsist\{U\} = {\singlespacingmath \begin{cases}
        0 & \text{ if } U = \emptyset \\
        1 & \text{ if } U \ne \emptyset
    \end{cases}}$

    \item If $U_1$ and $U_2$ are both events over the same sample space, then 
        $\selfconsist\{ U_1, U_2 \} = 
            % \mathbbm 1[ U_1 \cap U_2 \ne \emptyset]
            \selfconsist\{U_1 \cap U_2\}
            $.  
        
    \item More generally, if $R_1(\mat X)$ and $R_2(\mat Y)$ are relations,
        then $\selfconsist\{ R_1, R_2\} = \selfconsist\{ R_1 \bowtie R_2\}$, where $R_1 \bowtie R_2$ is the natural join of $R_1$ and $R_2$.
         % (\cref{prelim:relations}).

    \item If $\mu$ is a probability distribution, and $U$ is an event, 
        then $\Xi\{\mu, U\} = \mu(U)$.
    
    \item If $\Bel$ is a Dempster-Shafer Belief function and $\Plaus$ is the corresponding plausibility function, and $U$ is an event, then 
    \[
    % $
    \selfconsist\{\Plaus, U\} = \selfconsist\{\Bel, U\} = \Plaus(U)
    .
    % $
    \] 

    \item If $\mathcal P$ is a convex set of probability distributions and $U$ is an event, then $\selfconsist\{ \dg M_{\mathcal P} \} = \sup_{P \in \mathcal P} P(U)$. 

    % \item If $\dg M$ represents a deterministic classifier and gold standard labels $\Xi(\dg M)$ is the accuracy of the classifier.
    \item If $D = \{(x_i, y_i) \}$ is a set of training data and $f : X \to Y$ is a
        deterministic classifier, 
        then 
        $\selfconsist\{ \Pr_D, f \}$ is the accuracy of $f$ on $D$. 
    
    \item If $p, q \in \Delta \V\!X$ are distributions over a discrete variable $X$, then
        $\selfconsist\{ p(X), q(X)\} = \Big( \sum_{x \in \V\!X} \sqrt{p(x) q(x)} \Big)^2$ is the square of the Bhattacharya coefficient, a well-established measure of similarity between distributions. 
        
        If $p$ and $q$ are each given confidence $\frac12$, then $1-\Xi[p,q]$ is the squared Hellinger distance between $p$ and $q$. 

    \item 
        % If $p = \mathcal N(\mu_1, \sigma_1^2), q = \mathcal N(\mu_2, \sigma_2^2)$
        If $p$ and $q$ are both unit normal distributions over $X$, 
        with means $m_1$ and $m_2$, respectively, then
         % are both normal distributions over $X$, then
        $\selfconsist\{ p(X), q(X) \} = \exp( - \frac12 (m_1 - m_2)^2)$
        itself resembles the density of a unit normal distribution.        
    % If $p(Y|X)$ is instead a probabilistic classifier, then 
% $\Xi[ \Pr_D !  + p(Y|X)]$
    % is the cross entropy 
    % $\Ex_{D}[ \log \frac1{p(Y|X)} ]$.
\end{itemize}
% \end{prop}


\section{Future Work and Open Questions}

% What we have seen is just the beginning. 
The theory presented in this thesis is a significant reframing of the probabilistic modeling process with far-reaching implications.
This thesis has presented quite a few of them. 
% Even accounting for 
But the theory is still in its infancy, 
    % and it has a long way to go before its limits and applications.
    % and we are still very far away from .
    and we are still a far away from having fully developing its limits and applications. 
We conclude with just a few of these avenues for future work.

\paragraph{Capturing even more modeling formalisms.}
There is no reason to think that the material presented here reflects the limits of what PDGs can represent. 
%
For instance, PDGs can capture relations (\cref{sec:constraint-widget}), so it makes sense to wonder whether they can capture relational databases
    \citep{abiteboul1995foundations}. 
Preliminary investigations suggest that this is the case,
    although fully capturing the relationship will require also developing an analogue of a databases's query language.  
Another reason to believe this is that data dependencies \citep{fagin1986theory} seem to closely match the qualitative semantics of a PDG's underlying hypergraph. 
Since databases do not describe probabilities (apart from 0 and 1), 
    encoding them with PDGs should involve only deterministic cpds.
    % a natural question becomes: what happens if we relax the 
This raises another question: what can we encode by allowing probabilistic relationships?
Our initial investigations suggest that the result may be quite different from the standard notion of a probabilistic database \citep{suciu2011probabilistic}, and perhaps has elements of modern information retrieval systems \citep{mitra-neural-info-retrieval,karpukhin2020dense}.
%
% All of this is just starting from encoding relational databases.  
\commentout{%
So far we have talked only about relational databases---but there is also a second important class of \emph{graph-based} databases \citep{graphdb-comparison,}.
% But there is a second important class of databases: graph based databases, and the object graphs of object-oriented programming languages.
In many ways, this seems an even closer fit to a PDG, and understanding whether and how they bear relationship to PDG semantics remains a promising open problem. 
}%

In Machine Learning, there has been a recent deluge of work introducing new representations and training objectives. At the moment, the two dominant architectures are \emph{diffusion models} \citep{pmlr-v37-sohl-dickstein15,ho2020denoising} and \emph{transformers} \citep{vaswani-attn}. 
Because of their roots in VAEs (which PDGs capture well (\cref{sec:variational})), it is not hard to show that diffusion models can also be regarded as PDGs. %---%
    Does this view yield any practical or conceptual benefits, beyond what we have already seen? 
    We do not know.
    % Perhaps 
%
So far, even less said for a relationship between PDGs and transformers.
% Owing to their capabilities and dominance,
Still, it is a question worth taking seriously, if one believes in the promise of PDGs as a foundation for modern probabilistic AI systems.      

\paragraph{Further investigation into qualitative PDGs.}
\Cref{sec:qim-info} explores how one (perhaps surprising) way in which the qualitative information in a PDG is deeply related to the notion of mechanism independence (\cref{defn:qim}).
We suspect there may be more to the story. 
% First, an analogue of the principle of maximum entropy leads us to
% % First, 
% For instance, the principle of maximum entropy suggests
%     a special case of QIM-compatibility in which the witness does not break any unnecessary symmetries---and
%     this special
%     variant appears to have an even closer relationship with $\SDef$.
For instance, the connection to causality suggests a more restrictive special case of QIM-compatibility, in which the witness must be uniform over the solutions
 of some causal model. (This also happens to also be the maximum entropy distribution among those that can arise from that causal model.) 
Preliminary investigations suggest that this special variant of QIM-compatibility may have an even closer relationship with $\SDef$ than the (already close) one detailed in \cref{sec:qim-info}.
Furthermore, preliminary experiments suggest that minimizing $\SDef$ may suffice to ensure QIM compatibility. 

A second avenue of future research into qualitative PDGs involves the relationship between quantifiers and extreme values of the parameter $\alpha$. 
% can be shown that very large values of $\alpha$ can be used to 
Specifically, it seems that existential quantifiers $(\exists)$ can be implemented with qualitative arcs that have $\alpha = +\infty$, while universal quantifiers ($\forall$) can be implemented with $\alpha = -\infty$. 
This observation may be useful in developing a query language for PDG-based databases (discussed above).
It also raises some deeper questions;
can we square this with our understanding of $\alpha$ as representing independent mechanisms (\cref{chap:QIM})?
 % This observation raises more questions than it answers, 


\paragraph{Further investigation into PDG inference.}
As mentioned in the conclusion to \cref{chap:infer}, we now have an $\tilde O(N^{2.9})$ approach to inference in the case of bounded treewidth,
% This is still a significant gap, that leaves PDGs trailing far behind other graphical models with analogous inference approaches
which is still significantly worse than the $\tilde O(N^1)$ algorithms for other graphical models with analogous inference approaches.
 % but the best known lower bound is $\tilde \Omega( N^1)$. 
As they are more expressive, PDG inherits an $\tilde \Omega(N^1)$ lower bound.
This leaves a significant gap;
we do not yet know whether it is possible to perform PDG inference more efficiently, or if we need to strengthen the lower bound. 
Moreover, our algorithm only provably works for inference in cases where 
    % $\bbeta \ge \gamma\balpha$).
    % $\gamma$ (the relative importance of structural information) is sufficiently small. 
    the importance $\gamma$ of structural information is sufficiently small
        (i.e., $\bbeta \ge \gamma\balpha$). 
The inference problem remains open in cases where structural information plays a leading role, and appears to be a significantly more difficult in general. 

There are many different approaches to inference in traditional graphical models;
see Chapters 9-14 of \citet{KF09} for a survey of them.
Our approach to inference in PDG is closely related to the techniques developed in Chapter 11. But what of analogues of the other approaches? 
Particle-based and MCMC methods in particular (the analogue of Chapter 12 [ibid])
for PDGs remain almost completely unexplored; can these techniques be adapted for use in PDGs?
%    
%
A related question is that of a deeper understanding of the local inconsistency resolution (LIR) algorithm (the subject of \cref{chap:LIR}). 
Under what conditions does this procedure converge?
If it converges, when does it produce ``correct'' answers?
It has taken decades of research to address similar questions about belief propagation \citep{yedida-genbp,wiegerinck-fracbp,minka2005divergence}, which is a special case.


While treewidth dominates the complexity of (exact) inference in traditional graphical models, it is not obvious that the same must be true for PDGs. 
PDGs can express many things that other graphical models cannot. 
Therefore, there may be nontrivial subclasses of PDGs that are completely unrelated to treewidth, which still admit tractable inference. 
%
% Some inconsistencies, for example, are easier to quantify than others---a fact to which variational inference owes its existence.
Some inconsistencies are easier to quantify than others, for example,
    which is arguably the basis of variational inference.
% Without even looking at the probabilities
In some cases, one can easily verify that a PDG has zero inconsistency through its hypergraph alone, without even looking at the probabilities.
(That is why it is possible to ensure representations are consistent by construction in the first place.)
These subclasses of PDGs have nothing to do with bounded treewidth. 
Are there general principles that tell us how difficult it could be to calculate a PDG's degree of inconsistency from $(\balpha,\bbeta,\Ar)$?
Might it be possible to automate the 
    search for PDGs that upper and lower bound a PDG's inconsistency,
    to get an adaptive general purpose analogue of variational inference?
    % in a more intelligent way?
    
% \paragraph{Other Approaches to (Approximate) Inference.}
% \paragraph{Deeper Exploration of Theoretical Connections to Other Fields.}
\paragraph{Deepening theoretical roots.}
% There's no reason to think that this is 
% 
\iffoundations
    In \cref{chap:PDG-cat}, we found that PDGs can be viewed as diagrams in a certain category. 
    We saw that categorical limits of PDGs are important. But what about colimits, and natural transformations between them? 
    The categorical picture opens a vast landscape of abstract research directions.
    One natural question is whether probability can replaced by something else---in categorical terms, what is needed to make probability work for a different monad.
    %
    Other connections that seem promising connecting to categorical characterizations of relative entropy \citep{baez2014bayesiancharacterizationrelativeentropy} 
    and of information loss \citep[Theorem 12.4.9]{leinster2021entropy}.
    Doing this properly may also require developing a categorical account of confidence (the subject of \cref{chap:conf}). 
\else
    % \TODO
    %
    An astute reader with training in pure mathematics may have noticed a similarity between PDGs and (commutative) diagrams.
    Indeed, technically speaking, there is a simple definition of a PDG as a diagram (i.e., a certain kind of functor) in a category of probabilistic transitions. 
    This observation raises many interesting questions about the category theory of PDGs, which we are only just beginning to explore.
    Preliminary investigations suggest that categorical notions such as limits and colimits of PDGs, for example, coincide with important concepts in probabilistic modeling. 
    
    % Other connections that seem promising connecting to categorical
    % The ultimate prize would be a satisfying way to 
    What is missing is a satisfying connection between this perspective and PDG's entropy-based semantics.
    We suspect such a connection may exist; after all, there are elegant characterizations of relative entropy \citep{baez2014bayesiancharacterizationrelativeentropy} 
        and of information loss \citep[Theorem 12.4.9]{leinster2021entropy}, which are the building blocks of PDG semantics, in categorical terms. 
    Making this connection properly may also require developing a more general theory of confidence, which is also the subject of ongoing work. 
\fi

Yet the most important future work lies in application rather than theory.

\section{Implementing and Applying the Theory}

% The material here has been conceptual, mathematically technical, and sometimes philosophical.
This material has been conceptual, mathematical, and at times philosophical.
% $\qquad$ 
% \\~\hfil
% But is it \emph{useful}?
% \hfil\par
{\par~\hfil
But is it \emph{useful}?
\hfil\par}

Narrowly construed as ``can it be used to help us understand AI systems built with probabilistic tools'', we submit that the answer is a resounding yes. 
% For pedagogical reasons alone, there is clear value in unifying so many different concepts and clarifying the relationships between them.
% Especially so because it also answers important foundational questions, such as how loss functions are related to one another, and to probability.
For pedagogical reasons alone, there is clear value in unifying so many different concepts 
in a simple language---especially 
    because it answers foundational questions about these concepts (such as where loss functions come from) and explains relationships between them.
    % in a simple  that answers foundational questions about where 
Equally narrowly construed as, ``can I run it on my laptop?'', the answer is also yes:
\commentout{%
% For the reader interested in playing around with PDGs, I have developed a general-purpose Python library implementing the framework in the discrete case, as well as many of the constructions in this thesis;
% it can be found at \url{https://github.com/orichardson/pdg}.
% Many of the concepts we have seen have proven difficult to manipulate in my head, and the truth has surprised me often.
% % Every paper in this thesis has had, at some point, a fatal mistake.  
% Using and developing this library has helped me explore and understand the material more deeply; I cannot recommend implementing one's math highly enough. 
% To a reader who wonders why one should bother testing something when you could prove it, I say it's better to have two ways of understanding things than it is to have just one. 
}%
a secondary artifact of this research program has been a general-purpose Python library implementing these concepts, which can be found at
    % in the discrete case
    {\small\url{https://github.com/orichardson/pdg}}.
% I cannot highly enough recommend implementing one's math; to a reader who wonders why bother testing something when you could prove it, I say it's better to have two ways of understanding things than it is to have just one. 
% Implementing the math has been immensely helpful for the development of these ideas---after all, it's better to have two ways of understanding things than it is to have just one. 
%
% But much of the work
% While some of the ideas 
% Many of these ideas, while technical, are also very abstract. 
% Indeed, while seeing this project through I have even been accused by my peers of not being a computer scientist! 
% As an avid coder, and a person who has long understood things by implementing them, this 
%
% Fortunately, I have something that might 
% To these people, I present the PDG python library, 
% What these people may not be aware of, is that I have been 
%
%
% I am still avoiding the deeper question, so let me ask it again.
% Is any of this practical? Can it help solve real problems? Could it be used to improve somebody's life? 
% These questions haunt me because they are clearly important, and I believe the answer to them is probably yes---but I been too invested in theory to investigate them with the energy they demand.  
% Conspicuously absent in this thesis are solutions to important real-world problems. 
% But solving important problems is difficult and takes time. 
% The theory will have to suffice for now. 
%
%
% But the deeper question---of whether or not this theory could ultimately help humanity---remains the most important open question of all.
The deeper question---of whether or not this theory will ultimately help humanity---remains open.
% But it has promise. We are 
But there is promise. Humanity is already building powerful artificial agents that are reshaping our world; no doubt one of the biggest problems of our time is to get a handle on how we want AI systems to work in the future.  
The theory described in this thesis has the potential to be a key element of that future.

% First, this theory contributes to interoperability. 
% One of the biggest complaints about neural networks is that they are 
Useful as they are, modern neural-network based systems have significant drawbacks:
their behavior can be difficult to understand, 
and their development requires lots tedious fiddling seemingly ad-hoc choices.
To a critical eye, this makes them very difficult to trust.
% difficult to understand and motivate, and that using them requires ad-hoc choices. 
The present theory helps to explain why these systems work, at an intuitive level.
It can help practitioners make or defend these choices in a principled manner, and it provides an intuitive visual calculus for describing AI systems and reasoning about their relationships. 
% The potential impact may be even larger.
Yet the impact may be even larger, considering the current context. 

% The principle question 
% A fundamental question about the future of 
At the moment, the most important unsolved problem in
    artificial intelligence is arguably the \emph{alignment problem}
\citep{wiener-alignment1960,alignment-zhuang-2020-NeurIPS,christian2020alignment}:
what values should we give to AI systems? 
A key feature of a machine learning system is an explicit optimization objective that the system seeks to minimize. 
But as AI becomes increasingly capable, choosing an optimization objective 
% feels increasingly like using a monkey paw:
    feels increasingly dangerous:
% do we really want some simple metric of profit or engagement or haziness to be maximized by a ``psychopathic god''? 
% can we really trust 
do we really want
an inhumanly clever psychopath to maximize some metric of profit, productivity, or happiness? 
% The concern stems from 
% Are there natural, universal values?
% According to the standard microeconomic theory, the answer is no: an agent is entitled to its own preference, morals, goals, and values. 
According to standard economic theory, an agent is entitled to its own preferences
    \newmaterial{(in the form of a utility function)}.
Unfortunately, with deft implementation and taken to an extreme, most 
    utility functions would be catastrophic for humans \citep{bostrom-superintelligence}. 
% Unfortunately most values, implemented deftly and taken to an extreme, would be catastrophic for humans.
It seems that we need to align the AI to values of its users;
    % current practice is therefore to fine-tune trained models to imbue them
    hence the effort to imbue models with 
    ``human preferences'' \citep{christiano2017deep}.
% But this begs a question: why are the original trained models not so bad?
% According to the standard microeconomic theory, the answer is no: an agent is entitled to its own preference, morals, goals, and values. 
% But is it really a good idea
%
% But what if there's something wrong about 
% But do we really 
% what if there's something wrong about the way we think about value?
% But what if our very understanding of value was flawed.
But is this fair?
Will it privilege ideals such as truth?
% Do we really want to entrust the enormous responsibility of selecting AI values to the users who provide the most feedback?
Do we really want to model AI values on the preferences of users who most actively provide feedback?
% The outlook appears bleak.
Our prospects of finding the ``right values'' appear bleak.

Yet, in light of what we have seen in this thesis, there may be another way to approach the problem.
It is easier to think critically about beliefs than values.
While beliefs can be 
    tested by reality and supported by argument,
    % it is difficult 
    % in general to take a principled stand in favor of a value.
    the same is not true of preferences or values in general. 
% it is difficult in general to take a principled stand in favor of a value.
Yet \emph{the desire to hold
    consistent beliefs} is a uniquely principled kind of value,
    held by nearly everyone and
    supported by centuries of argument.
%
%
% Moreover, much of the current practice of building AI systems can be done with this value alone. 
Moreover, by appealing only to beliefs (which are subject to audit, analysis, and testing)
    and this one particularly palatable value, we can still 
    %  much of the current practice of artificial intelligence can be done 
    recover many of the core elements of modern artificial intelligence
    (including all manner of learning and inference procedures, as shown in \cref{chap:one-true-loss,chap:LIR}). 
%
%
% So perhaps our AIs do not need to take a mathematically undefended stand in the space of values at all. 
So perhaps ``value alignment'' is the wrong way to think about the problem: maybe AI does not require
% (mathematically undefended)
utilities at all.  
% take a mathematically undefended stand in the space of at all. 
% While 
Perhaps it could be safer to build AI systems primarily using 
    trustworthy or testable (if possibly inconsistent)
    beliefs and a single \emph{universal} objective: 
    the pursuit of self-consistency.


\commentout{
This unified theory of probabilistic modeling and epistemic conflict has the potential to be a key element of that future.
% Universal 
For one, it could provide students and researchers with a principled approach to understanding and designing these systems---even the powerful modern ones which are seldom fully consistent. 
For another, it may help to resolve questions of alignment, as it provides a principled way of pursuing a universal value: self-consistency. 
Indeed, the entire theory is based only on truth and confidence---analogues of ``utility'' appear only ephemeral intermediates in this process. 
There is also a case to be made that universal constructions promote diversity and fairness.
%joe3: "I have no clue what you have in mind here"
Perhaps in this moment, 
% even more important than solving a real-world problem better than anyone else
what's most important
is to develop a clearer and more mature understanding
    of cognition---both for ourselves,
    and for the generations of powerful AI systems to come.
%joe3: What does this last sentence have to do with what came before? Last paragraph must be completely rewritten. 
}%
% For one, it 


% For one, it could provide students and researchers with a principled approach to understanding and designing these systems---even the powerful modern ones which are seldom fully consistent. 
% For another, it may help to resolve questions of alignment, as it provides a principled way of pursuing a universal value: self-consistency. 
% Indeed, the entire theory is based only on truth and confidence.
% While analogues of preferences and utilities are not exempt from criticism, but rather (often questionable) probabilistic modeling choices. 
%  % ``utility'' appear only ephemeral intermediates in this process. 
% There is also a case to be made that universal constructions promote diversity and fairness.
% % Arguably, discriminating  is the very definition of fairness.
% Perhaps in this moment, 
%     the most important application of all is to figure out how to build AI s





% So perhaps the real applications can come later. 
% Perhaps what's needed at the moment are theoretical and conceptual foundations for AI systems. 
% Perhaps it is better to position ourselves to tackle the biggest problems that loom on the horizon of AI systems, than it is to possibly find ourselves with a toolkit overfit to small ones. 
% For now, what is important is thinking clearly, and flexibly. 
