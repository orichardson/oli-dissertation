@STRING{aaai94	= {Proc.~Eleventh National Conference on Artificial
		  Intelligence (AAAI '94)} }
@STRING{mk	= "Morgan Kaufmann" }
@STRING{sf	= "San Francisco" }

@Misc{1219753,
  title={conditioning reduces mutual information},
  year={2015},
  author={leonbloy},
  howpublished={Mathematics Stack Exchange},
  note={URL:https://math.stackexchange.com/q/1219753 (version: 2015-04-04)},
  eprint={https://math.stackexchange.com/q/1219753},
  url={https://math.stackexchange.com/q/1219753}
}

@Book{abiteboul1995foundations,
  title={Foundations of Databases},
  author={Abiteboul, Serge and Hull, Richard and Vianu, Victor},
  volume={8},
  year={1995},
  publisher={Addison-Wesley Reading}
}

@Article{agrawal2018rewriting,
  author={Agrawal, Akshay and Verschueren, Robin and Diamond, Steven and
Boyd, Stephen},
  title={A Rewriting System for Convex Optimization Problems},
  journal={Journal of Control and Decision},
  year={2018},
  volume={5},
  number={1},
  pages={42--60}
}

@Article{aji2000gendistriblaw,
  author={Aji, S.M. and McEliece, R.J.},
  journal={IEEE Transactions on Information Theory},
  title={The generalized distributive law},
  year={2000},
  volume={46},
  number={2},
  pages={325-343},
  doi={10.1109/18.825794}
}

@InProceedings{alignment-zhuang-2020-NeurIPS,
  author={Zhuang, Simon and Hadfield-Menell, Dylan},
  booktitle={Advances in Neural Information Processing Systems},
  editor={H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H.
Lin},
  pages={15763--15773},
  publisher={Curran Associates, Inc.},
  title={Consequences of Misaligned AI},
  url={https://proceedings.neurips.cc/paper_files/paper/2020/file/b607ba543ad05417b8507ee86c54fcb7-Paper.pdf},
  volume={33},
  year={2020}
}

@Article{badenbroek2021algorithm,
  title={An Algorithm for Nonsymmetric Conic Optimization Inspired by Mosek},
  author={Badenbroek, Riley and Dahl, Joachim},
  journal={Optimization Methods and Software},
  pages={1--38},
  year={2021},
  publisher={Taylor \& Francis}
}

@Misc{baez2014bayesiancharacterizationrelativeentropy,
  title={A Bayesian Characterization of Relative Entropy},
  author={John C. Baez and Tobias Fritz},
  year={2014},
  eprint={1402.3067},
  archiveprefix={arXiv},
  primaryclass={cs.IT},
  url={https://arxiv.org/abs/1402.3067}
}

@InCollection{Baier_2022,
  doi={10.1007/978-3-031-22337-2_17},
  url={https://doi.org/10.1007%2F978-3-031-22337-2_17},
  year=2022,
  publisher={Springer Nature Switzerland},
  pages={343--363},
  author={Christel Baier and Clemens Dubslaff and Holger Hermanns and Nikolai
Käfer},
  title={On the Foundations of Cycles in Bayesian Networks},
  booktitle={Lecture Notes in Computer Science}
}

@Misc{beckers2023causal,
  title={Causal Models with Constraints},
  author={Sander Beckers and Joseph Y. Halpern and Christopher Hitchcock},
  year={2023},
  eprint={2301.06845},
  archiveprefix={arXiv},
  primaryclass={cs.AI}
}

@Book{bertele1972nonserial,
  title={Nonserial dynamic programming},
  author={Bertele, Umberto and Brioschi, Francesco},
  year={1972},
  publisher={Academic Press, Inc.}
}

@InBook{Bertossi2005,
  author="Bertossi, Leopoldo and Hunter, Anthony and Schaub, Torsten",
  title="Introduction to Inconsistency Tolerance",
  booktitle="Inconsistency Tolerance",
  year="2005",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="1--14",
  abstract="Inconsistency arises in many areas in advanced computing.
Examples include: Merging information from heterogeneous sources; Negotiation
in multi-agent systems; Understanding natural language dialogues; and
Commonsense reasoning in robotics. Often inconsistency is unwanted, for
example, in the specification for a plan, or in sensor fusion in robotics.
But sometimes inconsistency is useful, e.g. when lawyers look for
inconsistencies in an opposition case, or in a brainstorming session in
research collaboration. Whether inconsistency is unwanted or useful, there is
a need to develop tolerance to inconsistency in application technologies such
as databases, knowledgebases, and software systems. To address this,
inconsistency tolerance is being built on foundational technologies for
identifying and analysing inconsistency in information, for representing and
reasoning with inconsistent information, for resolving inconsistent
information, and for merging inconsistent information. In this introductory
chapter, we consider the need and role for inconsistency tolerance, and
briefly review some of the foundational technologies for inconsistency
tolerance.",
  isbn="978-3-540-30597-2",
  doi="10.1007/978-3-540-30597-2_1",
  url="https://doi.org/10.1007/978-3-540-30597-2_1"
}

@InCollection{biggio2013advattk,
  doi={10.1007/978-3-642-40994-3_25},
  url={https://doi.org/10.1007%2F978-3-642-40994-3_25},
  year=2013,
  publisher={Springer Berlin Heidelberg},
  pages={387--402},
  author={Battista Biggio and Igino Corona and Davide Maiorca and Blaine
Nelson and Nedim {\v{S} }rndi{\'{c}} and Pavel Laskov and Giorgio Giacinto
and Fabio Roli},
  title={Evasion Attacks against Machine Learning at Test Time},
  booktitle={Advanced Information Systems Engineering}
}

@Article{blei2017variational,
  title={Variational Inference: A Review for Statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis}
}

@InProceedings{bodlaender1993linear,
  title={A Linear Time Algorithm for Finding Tree-Decompositions of Small
Treewidth},
  author={Bodlaender, Hans L},
  booktitle={Proceedings of the twenty-fifth annual ACM symposium on Theory
of computing},
  pages={226--234},
  year={1993}
}

@Book{bostrom-superintelligence,
  author={Bostrom, Nick},
  title={Superintelligence: paths, dangers, strategies},
  publisher={Oxford University Press},
  year={2014},
  isbn={9780199678112}
}

@Book{boyd2004convex,
  title={Convex Optimization},
  author={Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge University Press},
  pages={87--88}
}

@Conference{BP94,
  author={A. Balke and J. Pearl},
  title={Probabilistic evaluation of counterfactual queries},
  booktitle=aaai94,
  year={1994},
  pages={200--207}
}

@Article{chandrasekaran2012complexity,
  title={Complexity of Inference in Graphical Models},
  author={Chandrasekaran, Venkat and Srebro, Nathan and Harsha, Prahladh},
  journal={arXiv preprint arXiv:1206.3240},
  year={2012}
}

@Article{chickering-equiv-bns,
  author={David Maxwell Chickering},
  title={A Transformational Characterization of Equivalent Bayesian Network
Structures},
  journal={CoRR},
  volume={abs/1302.4938},
  year={2013},
  url={http://arxiv.org/abs/1302.4938},
  eprinttype={arXiv},
  eprint={1302.4938},
  timestamp={Mon, 13 Aug 2018 16:47:19 +0200},
  biburl={https://dblp.org/rec/journals/corr/abs-1302-4938.bib},
  bibsource={dblp computer science bibliography, https://dblp.org}
}

@Article{chipot2007free,
  title={Free Energy Calculations},
  author={Chipot, Christophe and Pohorille, Andrew},
  journal={Springer Series in Chemical Physics},
  volume={86},
  pages={159--184},
  year={2007},
  publisher={Springer}
}

@Book{christian2020alignment,
  title={The Alignment Problem: Machine Learning and Human Values},
  author={Christian, Brian},
  isbn={9780393635829},
  year={2020},
  publisher={WW Norton}
}

@Article{christiano2017deep,
  title={Deep Reinforcement Learning from Human Preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan
and Legg, Shane and Amodei, Dario},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@Article{chu1965shortest,
  title={On the Shortest Arborescence of a Directed Graph},
  author={Chu, Yoeng-Jin},
  journal={Scientia Sinica},
  volume={14},
  pages={1396--1400},
  year={1965}
}

@Article{cichocki2010families,
  title={Families of Alpha Beta and Gamma Divergences: Flexible and Robust
Measures of Similarities},
  author={Cichocki, Andrzej and Amari, Shun-ichi},
  journal={Entropy},
  volume={12},
  number={6},
  pages={1532--1568},
  year={2010},
  publisher={Molecular Diversity Preservation International}
}

@Article{courcelle1990,
  title={The Monadic Second-order Logic of Graphs. I. Recognizable Sets of
Finite Graphs},
  journal={Information and Computation},
  volume={85},
  number={1},
  pages={12-75},
  year={1990},
  issn={0890-5401},
  doi={https://doi.org/10.1016/0890-5401(90)90043-H},
  url={https://www.sciencedirect.com/science/article/pii/089054019090043H},
  author={Bruno Courcelle},
  abstract={The notion of a recognizable set of finite graphs is introduced.
Every set of finite graphs, that is definable in monadic second-order logic
is recognizable, but not vice versa. The monadic second-order theory of a
context-free set of graphs is decidable.}
}

@Book{CoverThomas,
  title={Elements of Information Theory},
  publisher={Wiley},
  year={1991},
  author={T. M. Cover and J. A. Thomas},
  address={New York}
}

@Article{critique-maxent,
  title={A critique of Jaynes' maximum entropy principle},
  journal={Advances in Applied Mathematics},
  volume={2},
  number={2},
  pages={172-211},
  year={1981},
  issn={0196-8858},
  doi={https://doi.org/10.1016/0196-8858(81)90003-8},
  url={https://www.sciencedirect.com/science/article/pii/0196885881900038},
  author={Penha Maria {Cardoso Dias} and Abner Shimony},
  abstract={Friedman and Shimony exhibited an anomaly in Jaynes' maximum
entropy prescription: that if a certain unknown parameter is assumed to be
characterized a priori by a normalizable probability measure, then the prior
and posterior probabilities computed by means of the prescription are
consistent with probability theory only if this measure assigns probability 1
to a single value of the parameter and probability 0 to the entire range of
other values. We strengthen this result by deriving the same conclusion using
only the assumption that the probability measure is σ-finite. We also show
that when the hypothesis and evidence to which the prescription is applied
are expressed in certain rather simple languages, then the maximum entropy
prescription yields probability evaluation in agreement with one of Carnap's
λ-continuum of inductive methods, namely λ = ∞. We conclude that the
maximum entropy prescription is correct only under special circumstances,
which are essentially those in which it is appropriate to use λ = ∞.}
}

@InProceedings{CycleGAN2017,
  title={Unpaired Image-to-Image Translation using Cycle-Consistent
Adversarial Networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei
A},
  booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},
  year={2017}
}

@Article{Dagum-Luby-approximate,
  title={An optimal approximation algorithm for Bayesian inference},
  journal={Artificial Intelligence},
  volume={93},
  number={1},
  pages={1-27},
  year={1997},
  issn={0004-3702},
  doi={https://doi.org/10.1016/S0004-3702(97)00013-1},
  url={https://www.sciencedirect.com/science/article/pii/S0004370297000131},
  author={Paul Dagum and Michael Luby},
  keywords={Bayesian inference, Approximation, Belief networks},
  abstract={Approximating the inference probability Pr[X = x | E = e] in any
sense, even for a single evidence node E, is NP-hard. This result holds for
belief networks that are allowed to contain extreme conditional
probabilities—that is, conditional probabilities arbitrarily close to 0.
Nevertheless, all previous approximation algorithms have failed to
approximate efficiently many inferences, even for belief networks without
extreme conditional probabilities. We prove that we can approximate
efficiently probabilistic inference in belief networks without extreme
conditional probabilities. We construct a randomized approximation
algorithm—the bounded-variance algorithm—that is a variant of the known
likelihood-weighting algorithm. The bounded-variance algorithm is the first
algorithm with provably fast inference approximation on all belief networks
without extreme conditional probabilities. From the bounded-variance
algorithm, we construct a deterministic approximation algorithm using current
advances in the theory of pseudorandom generators. In contrast to the
exponential worst-case behavior of all previous deterministic approximations,
the deterministic bounded-variance algorithm approximates inference
probabilities in worst-case time that is subexponential 2(log n) d, for some
integer d that is a linear function of the depth of the belief network.}
}

@Article{dahl2022primal,
  title={A Primal-Dual Interior-Point Algorithm For Nonsymmetric
Exponential-Cone Optimization},
  author={Dahl, Joachim and Andersen, Erling D},
  journal={Mathematical Programming},
  volume={194},
  number={1},
  pages={341--370},
  year={2022},
  publisher={Springer}
}

@Article{dawid1982well,
  title={The Well-Calibrated Bayesian},
  author={Dawid, A Philip},
  journal={Journal of the American Statistical Association},
  volume={77},
  number={379},
  pages={605--610},
  year={1982},
  publisher={Taylor \& Francis}
}

@PhDThesis{dcp-thesis,
  author={Michael Charles Grant},
  title={Disciplined Convex Programming},
  school={Stanfor University},
  year={2004},
  month={December},
  url={https://web.stanford.edu/~boyd/papers/pdf/mcg_thesis.pdf}
}

@Article{de-gustibus-non-est-disputandum77stigler,
  issn={00028282},
  url={http://www.jstor.org/stable/1807222},
  author={George J. Stigler and Gary S. Becker},
  journal={The American Economic Review},
  number={2},
  pages={76--90},
  publisher={American Economic Association},
  title={De Gustibus Non Est Disputandum},
  urldate={2024-08-08},
  volume={67},
  year={1977}
}

@Article{dean1989model,
  title={A Model for Reasoning about Persistence and Causation},
  author={Dean, Thomas and Kanazawa, Keiji},
  journal={Computational Intelligence},
  volume={5},
  number={2},
  pages={142--150},
  year={1989},
  publisher={Wiley Online Library}
}

@Misc{deepgennotes,
  author={Grover, Aditya and Ermon, Stefano},
  title={Lecture notes in Deep Generative Models},
  year={2018},
  publisher={Stanford University},
  volume={CS236},
  howpublished={\url{deepgenerativemodels.github.io/notes/}}
}

@Misc{descartes,
  title={The Discourse on Method},
  author={Descartes, Ren{\'e}},
  year={1637}
}

@Article{diamond2016cvxpy,
  author={Steven Diamond and Stephen Boyd},
  title={{CVXPY}: {A} {P}ython-Embedded Modeling Language for Convex
Optimization},
  journal={Journal of Machine Learning Research},
  year={2016},
  volume={17},
  number={83},
  pages={1--5}
}

@Misc{dit-stumble,
  title={(Stumbling Blocks) on the Road to Understanding Multivariate
Information Theory},
  author={James, Ryan},
  year={2018},
  howpublished={Discrete Information Theory package documentation},
  url={https://dit.readthedocs.io/en/latest/stumbling.html}
}

@Article{duan2022faster,
  title={Faster Matrix Multiplication via Asymmetric Hashing},
  author={Duan, Ran and Wu, Hongxun and Zhou, Renfei},
  journal={arXiv preprint},
  doi={10.48550/ARXIV.2210.10173},
  url={https://arxiv.org/abs/2210.10173},
  year={2022}
}

@InProceedings{ECOS,
  author={Domahidi, Alexander and Chu, Eric and Boyd, Stephen},
  booktitle={2013 European Control Conference (ECC)},
  title={ECOS: An SOCP solver for embedded systems},
  year={2013},
  volume={},
  number={},
  pages={3071-3076},
  doi={10.23919/ECC.2013.6669541}
}

@Book{elts_stat_learn2009,
  title={The Elements of Statistical Learning: Data Mining, Inference, and
Prediction},
  publisher={Springer},
  year={2009},
  author={Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  edition={Second}
}

@Article{fadeev1957begriff,
  title={Zum Begriff der Entropie einer endlichen
Wahrscheinlichkeitsschemas},
  author={Fadeev, DK},
  journal={Arbeiten zur Informationstheorie I. Deutscher Verlag der
Wissenschaften},
  pages={85--90},
  year={1957}
}

@InProceedings{fagin1986theory,
  title={The Theory of Data Dependencies: A Survey},
  author={Fagin, Ronald and Vardi, Moshe Y},
  booktitle={Mathematics of Information Processing: Proceedings of Symposia
in Applied Mathematics},
  volume={34},
  pages={19--71},
  year={1986},
  organization={Amer. Math. Soc.}
}

@Article{festinger1962cognitive,
  title={Cognitive dissonance},
  author={Festinger, Leon},
  journal={Scientific American},
  volume={207},
  number={4},
  pages={93--106},
  year={1962},
  publisher={JSTOR}
}

@Article{finocchiaro1981fallacies,
  title={Fallacies and the Evaluation of Reasoning},
  author={Finocchiaro, Maurice A},
  journal={American Philosophical Quarterly},
  volume={18},
  number={1},
  pages={13--22},
  year={1981},
  publisher={JSTOR}
}

@Book{fletcher2013practical,
  title={Practical methods of optimization},
  author={Fletcher, Roger},
  year={2013},
  publisher={John Wiley \& Sons}
}

@InProceedings{FNNS,
  title={Fixed Neural Network Steganography: Train the images, not the
network},
  author={Kishore, Varsha and Chen, Xiangyu and Wang, Yan and Li, Boyi and
Weinberger, Kilian Q},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@Article{frey2012extending,
  title={Extending Factor Graphs so as to Unify Directed and Undirected
Graphical Models},
  author={Frey, Brendan J},
  journal={arXiv preprint arXiv:1212.2486},
  year={2012}
}

@Article{friedman1971jaynes,
  title={Jaynes's Maximum Entropy Prescription and Probability Theory},
  author={Friedman, Kenneth and Shimony, Abner},
  journal={Journal of Statistical Physics},
  volume={3},
  pages={381--384},
  year={1971},
  publisher={Springer}
}

@Article{friston2009free,
  title={The Free-Energy Principle: a Rough Guide to the Brain?},
  author={Friston, Karl},
  journal={Trends in Cognitive Sciences},
  volume={13},
  number={7},
  pages={293--301},
  year={2009},
  publisher={Elsevier}
}

@Misc{ftrl-lecturenotes1,
  author={Brendan McMahan},
  title={Follow-The-Regularized-Leader},
  month={March},
  year={2014},
  note={[Lecture Notes; accessed online July 2024]},
  howpublished={\url{https://courses.cs.washington.edu/courses/cse599s/14sp/scribes/lecture3/lecture3.pdf}}
}

@Misc{ftrl-lecturenotes2,
  author={Roi Livini},
  title={Follow The Regulerized Leader},
  year={2017},
  note={[Lecture notes; accessed online July 2024]},
  howpublished={\url{https://www.cs.princeton.edu/~rlivni/cos511/lectures/lect21.pdf}}
}

@Article{gallo-dirhypergraphs1993,
  title={Directed Hypergraphs and Applications},
  journal={Discrete Applied Mathematics},
  volume={42},
  number={2},
  pages={177-201},
  year={1993},
  issn={0166-218X},
  doi={https://doi.org/10.1016/0166-218X(93)90045-P},
  url={https://www.sciencedirect.com/science/article/pii/0166218X9390045P},
  author={Giorgio Gallo and Giustino Longo and Stefano Pallottino and Sang
Nguyen},
  abstract={We deal with directed hypergraphs as a tool to model and solve
some classes of problems arising in operations research and in computer
science. Concepts such as connectivity, paths and cuts are defined. An
extension of the main duality results to a special class of hypergraphs is
presented. Algorithms to perform visits of hypergraphs and to find optimal
paths are studied in detail. Some applications arising in propositional
logic, And-Or graphs, relational databases and transportation analysis are
presented.}
}

@Article{geiger-pearl-d-separation,
  author={Geiger, Dan and Verma, Thomas and Pearl, Judea},
  title={Identifying Independence in Bayesian Networks},
  journal={Networks},
  volume={20},
  number={5},
  pages={507-534},
  doi={https://doi.org/10.1002/net.3230200504},
  url={https://onlinelibrary.wiley.com/doi/abs/10.1002/net.3230200504},
  eprint={https://onlinelibrary.wiley.com/doi/pdf/10.1002/net.3230200504},
  abstract={Abstract An important feature of Bayesian networks is that they
facilitate explicit encoding of information about independencies in the
domain, information that is indispensable for efficient inferencing. This
article characterizes all independence assertions that logically follow from
the topology of a network and develops a linear time algorithm that
identifies these assertions. The algorithm's correctness is based on the
soundness of a graphical criterion, called d-separation, and its optimality
stems from the completeness of d-separation. An enhanced version of
d-separation, called D-separation, is defined, extending the algorithm to
networks that encode functional dependencies. Finally, the algorithm is shown
to work for a broad class of nonprobabilistic independencies.},
  year={1990}
}

@Article{girosi1995regularization,
  title={Regularization Theory and Neural Networks Architectures},
  author={Girosi, Federico and Jones, Michael and Poggio, Tomaso},
  journal={Neural computation},
  volume={7},
  number={2},
  pages={219--269},
  year={1995},
  publisher={MIT Press}
}

@Misc{goodfellow2014explaining,
  title={Explaining and Harnessing Adversarial Examples},
  author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
  year={2014},
  eprint={1412.6572},
  archiveprefix={arXiv},
  primaryclass={stat.ML}
}

@Article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu,
Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and
Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@InProceedings{Grove1997ProbabilityUC,
  title={Probability Update: Conditioning vs. Cross-Entropy},
  author={Adam J. Grove and Joseph Y. Halpern},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={1997},
  url={https://api.semanticscholar.org/CorpusID:14707750}
}

@Article{Hall1935,
  title={On Representatives of Subsets},
  author={Peter Hall},
  journal={Journal of The London Mathematical Society-second Series},
  year={1935},
  pages={26-30},
  url={https://api.semanticscholar.org/CorpusID:23252557}
}

@Article{halpern-2000,
  title={Axiomatizing Causal Reasoning},
  author={Halpern, Joseph Y},
  journal={Journal of Artificial Intelligence Research},
  volume={12},
  pages={317--337},
  year={2000}
}

@Book{halpern-RAU,
  title={Reasoning About Uncertainty},
  author={Halpern, Joseph Y},
  year={2017},
  publisher={MIT press}
}

@Article{heckerman2000dependency,
  title={Dependency networks for inference, collaborative filtering, and data
visualization},
  author={Heckerman, David and Chickering, David Maxwell and Meek,
Christopher and Rounthwaite, Robert and Kadie, Carl},
  journal={Journal of Machine Learning Research},
  volume={1},
  number={Oct},
  pages={49--75},
  year={2000}
}

@Article{higgins2016beta,
  title={Beta-VAE: Learning Basic visual concepts with a constrained
variational framework},
  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess,
Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and
Lerchner, Alexander},
  year={2016}
}

@Article{HL12,
  author={J.~Y. Halpern and S. Leung},
  title={Weighted sets of probabilities and minimax weighted expected regret:
new approaches for representing uncertainty and making decisions},
  journal={Theory and Decision},
  year={2015},
  volume={79},
  number={3},
  pages={415--450}
}

@Article{ho2020denoising,
  title={Denoising Diffusion Probabilistic Models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@Article{influencediagrams,
  title={Influence Diagrams},
  author={Howard, Ronald A., James E. Matheson},
  year={1983},
  journal={Readings on the Principles and Applications of Decision Analysis},
  publisher={Strategic Decisions Group},
  pages={719-763}
}

@InProceedings{jadon2020survey,
  title={A Survey of Loss Functions for Semantic Segmentation},
  author={Jadon, Shruti},
  booktitle={2020 IEEE Conference on Computational Intelligence in
Bioinformatics and Computational Biology (CIBCB)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@Article{jaynes1957information,
  title={Information Theory and Statistical Mechanics},
  author={Jaynes, Edwin T},
  journal={Physical review},
  volume={106},
  number={4},
  pages={620},
  year={1957},
  publisher={APS}
}

@InCollection{Jeffrey68,
  author={R.~C. Jeffrey},
  title={Probable knowledge},
  booktitle={International Colloquium in the Philosophy of Science: The
Problem of Inductive Logic},
  editor={I. Lakatos},
  year=1968,
  pages={157--185},
  address={Amsterdam},
  publisher={North-Holland}
}

@InBook{Kaminski_Katoen_Matheja_2020,
  place={Cambridge},
  title={Expected Runtime Analyis by Program Verification},
  booktitle={Foundations of Probabilistic Programming},
  publisher={Cambridge University Press},
  author={Kaminski, Benjamin Lucien and Katoen, Joost-Pieter and Matheja,
Christoph},
  editor={Barthe, Gilles and Katoen, Joost-Pieter and Silva, Alexandra},
  year={2020},
  pages={185–220}
}

@InProceedings{karmarkar1984new,
  title={A New Polynomial-Time Algorithm for Linear Programming},
  author={Karmarkar, Narendra},
  booktitle={Proceedings of the Sixteenth Annual ACM Symposium on Theory of
Computing},
  pages={302--311},
  year={1984}
}

@Article{karpukhin2020dense,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and
Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih,
Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@Article{kasangian1990duality,
  title={The Duality Between Flow Charts and Circuits},
  author={Kasangian, S and Walters, RFC},
  journal={Bulletin of the Australian Mathematical Society},
  volume={42},
  number={1},
  pages={71--79},
  year={1990},
  publisher={Cambridge University Press}
}

@Book{KF09,
  author={D. Koller and N. Friedman},
  title={Probabilistic Graphical Models},
  year={2009},
  publisher={MIT Press},
  address={Cambridge, MA}
}

@Article{kingma2013autoencoding,
  title={Auto-Encoding Variational Bayes},
  author={Diederik P Kingma and Max Welling},
  journal={Proceedings of the International Conference on Learning
Representations (ICLR)},
  year={2014},
  eprint={1312.6114},
  archiveprefix={arXiv},
  primaryclass={stat.ML}
}

@Article{kingma2014adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@Article{Kobyzev_2021,
  doi={10.1109/tpami.2020.2992934},
  url={https://doi.org/10.1109%2Ftpami.2020.2992934},
  year=2021,
  month={nov},
  publisher={Institute of Electrical and Electronics Engineers ({IEEE})},
  volume={43},
  number={11},
  pages={3964--3979},
  author={Ivan Kobyzev and Simon J.D. Prince and Marcus A. Brubaker},
  title={Normalizing Flows: An Introduction and Review of Current Methods},
  journal={{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
}

@Article{kschischang2001factor,
  title={Factor graphs and the sum-product algorithm},
  author={Kschischang, Frank R and Frey, Brendan J and Loeliger, H-A},
  journal={IEEE Transactions on information theory},
  volume={47},
  number={2},
  pages={498--519},
  year={2001},
  publisher={IEEE}
}

@Article{kschischang2001sumproduct,
  author={F. R. {Kschischang} and B. J. {Frey} and H. -. {Loeliger}},
  journal={IEEE Transactions on Information Theory},
  title={Factor Graphs and the Sum-product Algorithm},
  year={2001},
  volume={47},
  number={2},
  pages={498-519}
}

@Article{lauritzen-dag-indeps,
  author={Lauritzen, S. L. and Dawid, A. P. and Larsen, B. N. and Leimer,
H.-G.},
  title={Independence properties of directed markov fields},
  journal={Networks},
  volume={20},
  number={5},
  pages={491-505},
  doi={https://doi.org/10.1002/net.3230200503},
  url={https://onlinelibrary.wiley.com/doi/abs/10.1002/net.3230200503},
  eprint={https://onlinelibrary.wiley.com/doi/pdf/10.1002/net.3230200503},
  abstract={Abstract We investigate directed Markov fields over finite graphs
without positivity assumptions on the densities involved. A criterion for
conditional independence of two groups of variables given a third is given
and named as the directed, global Markov property. We give a simple proof of
the fact that the directed, local Markov property and directed, global Markov
property are equivalent and – in the case of absolute continuity w. r. t. a
product measure – equivalent to the recursive factorization of densities.
It is argued that our criterion is easy to use, it is sharper than that given
by Kiiveri, Speed, and Carlin and equivalent to that of Pearl. It follows
that our criterion cannot be sharpened.},
  year={1990}
}

@Article{lauritzen1988local,
  title={Local computations with probabilities on graphical structures and
their application to expert systems},
  author={Lauritzen, Steffen L and Spiegelhalter, David J},
  journal={Journal of the Royal Statistical Society: Series B
(Methodological)},
  volume={50},
  number={2},
  pages={157--194},
  year={1988},
  publisher={Wiley Online Library}
}

@InProceedings{learning-loc-glob-consistency,
  author={Zhou, Dengyong and Bousquet, Olivier and Lal, Thomas and Weston,
Jason and Sch\"{o}lkopf, Bernhard},
  booktitle={Advances in Neural Information Processing Systems},
  editor={S. Thrun and L. Saul and B. Sch\"{o}lkopf},
  pages={},
  publisher={MIT Press},
  title={Learning with Local and Global Consistency},
  url={https://proceedings.neurips.cc/paper_files/paper/2003/file/87682805257e619d49b8e0dfdc14affa-Paper.pdf},
  volume={16},
  year={2003}
}

@Misc{leinster2017shortcharacterizationrelativeentropy,
  title={A Short Characterization of Relative Entropy},
  author={Tom Leinster},
  year={2017},
  eprint={1712.04903},
  archiveprefix={arXiv},
  primaryclass={cs.IT},
  url={https://arxiv.org/abs/1712.04903}
}

@Book{leinster2021entropy,
  title={Entropy and Diversity: the Axiomatic Approach},
  author={Leinster, Tom},
  year={2021},
  publisher={Cambridge University Press}
}

@Misc{LIR,
  title={The Local Inconsistency Resolution Algorithm (workshop version)},
  author={Oliver E Richardson},
  note={ICML `23 Workshops: Local Learning Workshop (LLW) and Structured
Prediction in Generative Modeling (SPIGM)},
  year={2023}
}

@InProceedings{ma2013estimating,
  title={Estimating the Partition Function of Graphical Models using Langevin
Importance Sampling},
  author={Ma, Jianzhu and Peng, Jian and Wang, Sheng and Xu, Jinbo},
  booktitle={Artificial Intelligence and Statistics},
  pages={433--441},
  year={2013},
  organization={PMLR}
}

@Book{mackay2003information,
  title={Information Theory, Inference and Learning Algorithms},
  author={MacKay, David J. C.},
  year={2003},
  publisher={Cambridge University Press}
}

@Article{MENENDEZ1997307,
  title={The Jensen-Shannon divergence},
  journal={Journal of the Franklin Institute},
  volume={334},
  number={2},
  pages={307-318},
  year={1997},
  issn={0016-0032},
  doi={https://doi.org/10.1016/S0016-0032(96)00063-4},
  url={https://www.sciencedirect.com/science/article/pii/S0016003296000634},
  author={M.L. Menéndez and J.A. Pardo and L. Pardo and M.C. Pardo},
  abstract={In this paper we investigate the Jensen-Shannon parametric
divergence for testing goodness-of-fit for point estimation. Most of the work
presented is an analytical study of the asymptotic differences between
different members of the family proposed in goodness of fit, together with an
examination of closer approximations to the exact distribution of these
statistics than the commonly used chi-squared distribution. Finally the
minimum Jensen-Shannon divergence estimates are introduced and compared with
other well-known estimators by computer simulation.}
}

@Book{mezard2009information,
  title={Information, physics, and computation},
  author={Mezard, Marc and Montanari, Andrea},
  year={2009},
  publisher={Oxford University Press}
}

@TechReport{minka2005divergence,
  title={Divergence Measures and Message Passing},
  author={Minka, Tom},
  year={2005},
  number={MSR-TR-2005–173},
  institution={Microsoft Research},
  address={Cambridge, U.K.}
}

@Book{mitra-neural-info-retrieval,
  author={Mitra, Bhaskar and Craswell, Nick},
  booktitle={An Introduction to Neural Information Retrieval},
  year={2018},
  doi={10.1561/1500000061}
}

@Manual{mosek,
  author="MOSEK ApS",
  title="MOSEK Optimizer API for Python 10.0.25",
  year=2022,
  url="https://docs.mosek.com/10.0/pythonapi/index.html"
}

@Article{multivar-beyondshannon17,
  author={James, Ryan G. and Crutchfield, James P.},
  title={Multivariate Dependence beyond Shannon Information},
  journal={Entropy},
  volume={19},
  year={2017},
  number={10},
  article-number={531},
  url={https://www.mdpi.com/1099-4300/19/10/531},
  issn={1099-4300},
  abstract={Accurately determining dependency structure is critical to
understanding a complex system’s organization. We recently showed that the
transfer entropy fails in a key aspect of this—measuring information
flow—due to its conflation of dyadic and polyadic relationships. We extend
this observation to demonstrate that Shannon information measures (entropy
and mutual information, in their conditional and multivariate forms) can fail
to accurately ascertain multivariate dependencies due to their conflation of
qualitatively different relations among variables. This has broad
implications, particularly when employing information to express the
organization and mechanisms embedded in complex systems, including the
burgeoning efforts to combine complex network theory with information theory.
Here, we do not suggest that any aspect of information theory is wrong.
Rather, the vast majority of its informational measures are simply inadequate
for determining the meaningful relationships among variables within joint
probability distributions. We close by demonstrating that such distributions
exist across an arbitrary set of variables.},
  doi={10.3390/e19100531}
}

@Article{myung2003tutorial,
  title={Tutorial on Maximum Likelihood Estimation},
  author={Myung, In Jae},
  journal={Journal of mathematical Psychology},
  volume={47},
  number={1},
  pages={90--100},
  year={2003},
  publisher={Elsevier}
}

@Misc{naumov2013re,
  title={R.E. Axiomatization of Conditional Independence},
  author={Pavel Naumov and Brittany Nicholls},
  year={2013},
  eprint={1310.6430},
  archiveprefix={arXiv},
  primaryclass={cs.LO}
}

@InCollection{neal1998view,
  title={A view of the EM algorithm that justifies incremental, sparse, and
other variants},
  author={Neal, Radford M and Hinton, Geoffrey E},
  booktitle={Learning in Graphical Models},
  pages={355--368},
  year={1998},
  publisher={Springer}
}

@Book{nesterov1994book,
  title={Interior-Point Polynomial Algorithms in Convex Programming},
  author={Nesterov, Yurii and Nemirovskii, Arkadii},
  year={1994},
  publisher={SIAM}
}

@TechReport{nesterov1996infeasible,
  title={Infeasible-Start Primal-Dual Methods and Infeasibility Detectors for
Nonlinear Programming Problems},
  author={Nesterov, Yu E and Todd, Michael J and Ye, Yinyu},
  year={1999},
  journal={Mathematical Programming},
  volume={84},
  pages={227--267},
  doi={https://doi.org/10.1007/s10107980009a}
}

@Article{nielsen2011chernoff,
  title={Chernoff Information of Exponential Families},
  author={Nielsen, Frank},
  journal={arXiv preprint arXiv:1102.2684},
  year={2011}
}

@Article{nikodym1930generalisation,
  title={Sur une g{\'e}n{\'e}ralisation des int{\'e}grales de MJ Radon},
  author={Nikodym, Otton},
  journal={Fundamenta Mathematicae},
  volume={15},
  number={1},
  pages={131--179},
  year={1930}
}

@Article{one-true-loss,
  title={Loss as the Inconsistency of a Probabilistic Dependency Graph:
Choose Your Model, Not Your Loss Function},
  author={Oliver E Richardson},
  journal={AISTATS '22},
  year={2022},
  eprint={2202.11862},
  archiveprefix={arXiv},
  primaryclass={cs.AI},
  series={Proceedings of Machine Learning Research},
  volume={151},
  publisher={PMLR}
}

@Article{patil1986structure,
  title={On the structure of k-trees},
  author={Patil, HP},
  journal={Journal of Combinatorics, Information and System Sciences},
  volume={11},
  number={2-4},
  pages={57--64},
  year={1986}
}

@Article{pdg-aaai,
  title={Probabilistic Dependency Graphs},
  author={Oliver E Richardson and Joseph Y Halpern},
  journal={AAAI '21},
  year={2021},
  eprint={2012.10800},
  archiveprefix={arXiv},
  primaryclass={cs.AI}
}

@Article{pdg-infer,
  title={Inference in Probabilistic Dependency Graphs},
  author={Oliver E Richardson and Joseph Y Halpern and Christopher {De Sa}},
  journal={UAI '23},
  year={2023}
}

@Book{Pearl,
  author={J. Pearl},
  title={Probabilistic Reasoning in Intelligent Systems},
  publisher=mk,
  address=sf,
  year=1988
}

@Misc{pearl1987graphoids,
  title={Graphoids: A Graph-Based Logic for Reasoning about Relevance
Relations},
  journal={Advances in Artificial Intelligence},
  vol={2},
  author={Pearl, J and Paz, A},
  year={1987},
  publisher={North-Holland}
}

@Book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}

@Book{pearl:2k,
  title={Causality: Models, Reasoning, and Inference},
  publisher={Cambridge University Press},
  year={2000},
  author={Pearl, J.},
  address={New York}
}

@Book{pinsker-inequality,
  author={Tsybakov, Alexandre},
  year={2009},
  title={Introduction to Nonparametric Estimation},
  publisher={Springer},
  pages={132},
  isbn={9780387790527}
}

@InProceedings{pmlr-v37-sohl-dickstein15,
  title={Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru
and Ganguli, Surya},
  booktitle={Proceedings of the 32nd International Conference on Machine
Learning},
  pages={2256--2265},
  year={2015},
  editor={Bach, Francis and Blei, David},
  volume={37},
  series={Proceedings of Machine Learning Research},
  address={Lille, France},
  month={07--09 Jul},
  publisher={PMLR},
  pdf={http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
  url={https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract={A central problem in machine learning involves modeling complex
data-sets using highly flexible families of probability distributions in
which learning, sampling, inference, and evaluation are still analytically or
computationally tractable. Here, we develop an approach that simultaneously
achieves both flexibility and tractability. The essential idea, inspired by
non-equilibrium statistical physics, is to systematically and slowly destroy
structure in a data distribution through an iterative forward diffusion
process. We then learn a reverse diffusion process that restores structure in
data, yielding a highly flexible and tractable generative model of the data.
This approach allows us to rapidly learn, sample from, and evaluate
probabilities in deep generative models with thousands of layers or time
steps, as well as to compute conditional and posterior probabilities under
the learned model. We additionally release an open source reference
implementation of the algorithm.}
}

@Book{probTuring,
  author={Sipser, Michael},
  year={2006},
  title={Introduction to the Theory of Computation (2nd ed.)},
  edition={Second},
  publisher={Thomson Course Technology.},
  pages={368},
  isbn={978-0-534-95097-2}
}

@Misc{pytorch,
  doi={10.48550/ARXIV.1912.01703},
  url={https://arxiv.org/abs/1912.01703},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam
and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming
and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf,
Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani,
Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai,
Junjie and Chintala, Soumith},
  keywords={Machine Learning (cs.LG), Mathematical Software (cs.MS), Machine
Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and
information sciences},
  title={PyTorch: An Imperative Style, High-Performance Deep Learning
Library},
  publisher={arXiv},
  year={2019},
  copyright={arXiv.org perpetual, non-exclusive license}
}

@Article{qim,
  title={Qualitative Mechanism Independence},
  author={Richardson, Oliver E and Peters, Spencer and Halpern, Joseph Y},
  year={2024},
  note={In Submission: for NeurIPS 2024}
}

@Article{rennie2003l2,
  title={On l2-norm regularization and the Gaussian prior},
  author={Rennie, Jason},
  year={2003},
  publisher={Citeseer}
}

@InProceedings{renyi1961measures,
  title={On Measures of Entropy and Information},
  author={R{\'e}nyi, Alfr{\'e}d},
  booktitle={Proceedings of the Fourth Berkeley Symposium on Mathematical
Statistics and Probability, Volume 1: Contributions to the Theory of
Statistics},
  pages={547--561},
  year={1961},
  organization={University of California Press}
}

@InProceedings{rezende2014stochastic,
  title={Stochastic backpropagation and approximate inference in deep
generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle={International conference on machine learning},
  pages={1278--1286},
  year={2014},
  organization={PMLR}
}

@Article{roth-hardness-1996,
  title={On the hardness of approximate reasoning},
  journal={Artificial Intelligence},
  volume={82},
  number={1},
  pages={273-302},
  year={1996},
  issn={0004-3702},
  doi={https://doi.org/10.1016/0004-3702(94)00092-1},
  url={https://www.sciencedirect.com/science/article/pii/0004370294000921},
  author={Dan Roth},
  abstract={Many AI problems, when formalized, reduce to evaluating the
probability that a propositional expression is true. In this paper we show
that this problem is computationally intractable even in surprisingly
restricted cases and even if we settle for an approximation to this
probability. We consider various methods used in approximate reasoning such
as computing degree of belief and Bayesian belief networks, as well as
reasoning techniques such as constraint satisfaction and knowledge
compilation, that use approximation to avoid computational difficulties, and
reduce them to model-counting problems over a propositional domain. We prove
that counting satisfying assignments of propositional languages is
intractable even for Horn and monotone formulae, and even when the size of
clauses and number of occurrences of the variables are extremely limited.
This should be contrasted with the case of deductive reasoning, where Horn
theories and theories with binary clauses are distinguished by the existence
of linear time satisfiability algorithms. What is even more surprising is
that, as we show, even approximating the number of satisfying assignments
(i.e., “approximating” approximate reasoning), is intractable for most of
these restricted theories. We also identify some restricted classes of
propositional formulae for which efficient algorithms for counting satisfying
assignments can be given.}
}

@Article{Rubin74,
  author={D. B. Rubin},
  title={Estimating causal effects of treatments in randomized and
nonrandomized studies},
  journal={Journal of Educational Psychology},
  year={1974},
  volume={66},
  number={5},
  pages={688--701}
}

@Article{russell1902letter,
  title={Letter to Frege},
  author={Russell, Bertrand},
  journal={From Frege to G{\"o}del},
  volume={6},
  pages={124--125},
  year={1902},
  publisher={Harvard University Press Cambridge, UK}
}

@Article{santambrogio2015optimal,
  title={Optimal Transport for Applied Mathematicians},
  author={Santambrogio, Filippo},
  journal={Birk{\"a}user, NY},
  volume={55},
  number={58-63},
  pages={94},
  year={2015},
  publisher={Springer}
}

@Book{Savage,
  author={L.~J. Savage},
  title={Foundations of Statistics},
  publisher={Wiley},
  address={New York},
  year=1954
}

@Misc{segal-law,
  year=1930,
  publisher={{San Diego Union}},
  author={{San Diego Union}},
  journal={{San Diego Union}},
  date={September 20, 1930},
  note={Quote Page 4, Column 1},
  howpublished={\url{https://quoteinvestigator.com/2022/07/04/watch/#f+441634+1+1}}
}

@Article{seidenfeld1986entropy,
  title={Entropy and Uncertainty},
  author={Seidenfeld, Teddy},
  journal={Philosophy of Science},
  volume={53},
  number={4},
  pages={467--491},
  year={1986},
  publisher={Cambridge University Press}
}

@Article{selman1996generating,
  title={Generating hard satisfiability problems},
  author={Selman, Bart and Mitchell, David G and Levesque, Hector J},
  journal={Artificial intelligence},
  volume={81},
  number={1-2},
  pages={17--29},
  year={1996},
  publisher={Elsevier}
}

@InCollection{sep-causal-models,
  author={Hitchcock, Christopher},
  title={{Causal Models}},
  booktitle={The {Stanford} Encyclopedia of Philosophy},
  editor={Edward N. Zalta and Uri Nodelman},
  howpublished={\url{https://plato.stanford.edu/archives/sum2024/entries/causal-models/}},
  year={2024},
  edition={{S}ummer 2024},
  publisher={Metaphysics Research Lab, Stanford University}
}

@InCollection{sep-dutch-book,
  author={Vineberg, Susan},
  title={{Dutch Book Arguments}},
  booktitle={The {Stanford} Encyclopedia of Philosophy},
  editor={Edward N. Zalta and Uri Nodelman},
  howpublished={\url{https://plato.stanford.edu/archives/fall2022/entries/dutch-book/}},
  year={2022},
  edition={{F}all 2022},
  publisher={Metaphysics Research Lab, Stanford University}
}

@Article{serenity-prayer,
  author={Niebuhr, Reinhold},
  editor={Wygal, Winnifred},
  publisher={Santa Cruz Sentinel},
  year={1933},
  date={15 March 1933},
  pages={1}
}

@Book{shafer1976mathematical,
  title={A Mathematical Theory of Evidence},
  author={Shafer, Glenn},
  volume={42},
  year={1976},
  publisher={Princeton university press}
}

@Article{shafer1990probability,
  title={Probability propagation},
  author={Shafer, Glenn R and Shenoy, Prakash P},
  journal={Annals of mathematics and Artificial Intelligence},
  volume={2},
  pages={327--351},
  year={1990},
  publisher={Springer}
}

@Article{skajaa2015homogeneous,
  title={A Homogeneous Interior-Point Algorithm for Nonsymmetric Convex Conic
Optimization},
  author={Skajaa, Anders and Ye, Yinyu},
  journal={Mathematical Programming},
  volume={150},
  number={2},
  pages={391--422},
  year={2015},
  publisher={Springer}
}

@Book{suciu2011probabilistic,
  title={Probabilistic Databases},
  author={Suciu, Dan and Olteanu, Dan and R{\'e}, Christopher and Koch,
Christoph},
  journal={Synthesis lectures on data management},
  volume={3},
  number={2},
  pages={1--180},
  year={2011},
  publisher={Morgan \& Claypool Publishers}
}

@Article{tabak2010density,
  title={Density Estimation by Dual Ascent of the Log-Likelihood},
  author={Tabak, Esteban G and Vanden-Eijnden, Eric},
  journal={Communications in Mathematical Sciences},
  volume={8},
  number={1},
  pages={217--233},
  year={2010},
  publisher={International Press of Boston}
}

@InProceedings{temp-cycle-consist-2019CVPR,
  author={Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and
Sermanet, Pierre and Zisserman, Andrew},
  title={Temporal Cycle-Consistency Learning},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)},
  month={June},
  year={2019}
}

@Article{tribus1961information,
  title={Information Theory as the Basis for Thermostatics and
Thermodynamics},
  author={Tribus, Myron},
  year={1961}
}

@Misc{trinary-search,
  title={Ternary Search},
  year={2023},
  howpublished={\url{https://cp-algorithms.com/num_methods/ternary_search.html}},
  note={[appears to be folklore; accessed online July 2024]}
}

@InProceedings{two-scale-GAN-Heusel2017,
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and
Nessler, Bernhard and Hochreiter, Sepp},
  booktitle={Advances in Neural Information Processing Systems},
  editor={I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R.
Fergus and S. Vishwanathan and R. Garnett},
  pages={},
  publisher={Curran Associates, Inc.},
  title={GANs Trained by a Two Time-Scale Update Rule Converge to a Local
Nash Equilibrium},
  url={https://proceedings.neurips.cc/paper_files/paper/2017/file/8a1d694707eb0fefe65871369074926d-Paper.pdf},
  volume={30},
  year={2017}
}

@Article{van2014renyi,
  title={R{\'e}nyi Divergence and Kullback-Leibler divergence},
  author={Van Erven, Tim and Harremos, Peter},
  journal={IEEE Transactions on Information Theory},
  volume={60},
  number={7},
  pages={3797--3820},
  year={2014},
  publisher={IEEE}
}

@InProceedings{vaswani-attn,
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit,
Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and
Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  editor={I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R.
Fergus and S. Vishwanathan and R. Garnett},
  pages={},
  publisher={Curran Associates, Inc.},
  title={Attention is All you Need},
  url={https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  volume={30},
  year={2017}
}

@Book{VnMR44theory-of-games-eb,
  isbn={9780691130613},
  url={http://www.jstor.org/stable/j.ctt1r2gkx},
  abstract={This is the classic work upon which modern-day game theory is
based. What began more than sixty years ago as a modest proposal that a
mathematician and an economist write a short paper together blossomed, in
1944, when Princeton University Press publishedTheory of Games and Economic
Behavior. In it, John von Neumann and Oskar Morgenstern conceived a
groundbreaking mathematical theory of economic and social organization, based
on a theory of games of strategy. Not only would this revolutionize
economics, but the entirely new field of scientific inquiry it yielded--game
theory--has since been widely used to analyze a host of real-world phenomena
from arms races to optimal policy choices of presidential candidates, from
vaccination policy to major league baseball salary negotiations. And it is
today established throughout both the social sciences and a wide range of
other sciences.This sixtieth anniversary edition includes not only the
original text but also an introduction by Harold Kuhn, an afterword by Ariel
Rubinstein, and reviews and articles on the book that appeared at the time of
its original publication in the New York Times, ttheAmerican Economic Review,
and a variety of other publications. Together, these writings provide readers
a matchless opportunity to more fully appreciate a work whose influence will
yet resound for generations to come.},
  author={John von Neumann and Oskar Morgenstern and Ariel Rubinstein},
  publisher={Princeton University Press},
  title={Theory of Games and Economic Behavior (60th Anniversary
Commemorative Edition)},
  urldate={2024-08-08},
  year={1944}
}

@Article{wainwright2003tree,
  title={Tree-based reparameterization framework for analysis of sum-product
and related algorithms},
  author={Wainwright, Martin J and Jaakkola, Tommi S and Willsky, Alan S},
  journal={IEEE Transactions on information theory},
  volume={49},
  number={5},
  pages={1120--1146},
  year={2003},
  publisher={IEEE}
}

@Article{wainwright2008graphical,
  title={Graphical Models, Exponential Families, and Variational Inference},
  author={Wainwright, Martin J and Jordan, Michael I and others},
  journal={Foundations and Trends{} in Machine Learning},
  volume={1},
  number={1--2},
  pages={1--305},
  year={2008},
  publisher={Now Publishers, Inc.}
}

@Book{Walley1991-SRIP,
  author={Peter Walley},
  editor={},
  publisher={Chapman \& Hall},
  journal={Monographs on Statistic aand Applied Probability},
  title={Statistical Reasoning with Imprecise Probabilities},
  year={1991},
  vol={42}
}

@Article{wang2020comprehensive,
  title={A Comprehensive Survey of Loss Functions in Machine Learning},
  author={Wang, Qi and Ma, Yue and Zhao, Kun and Tian, Yingjie},
  journal={Annals of Data Science},
  pages={1--26},
  year={2020},
  publisher={Springer}
}

@Article{why-be-consistent-sugden,
  issn={00130427, 14680335},
  url={http://www.jstor.org/stable/2554418},
  author={Robert Sugden},
  journal={Economica},
  number={206},
  pages={167--183},
  publisher={[London School of Economics, Wiley, London School of Economics
and Political Science, Suntory and Toyota International Centres for Economics
and Related Disciplines]},
  title={Why be Consistent? A Critical Analysis of Consistency Requirements
in Choice Theory},
  urldate={2024-08-08},
  volume={52},
  year={1985}
}

@InProceedings{wiegerinck-fracbp,
  author={Wiegerinck, Wim and Heskes, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  editor={S. Becker and S. Thrun and K. Obermayer},
  pages={},
  publisher={MIT Press},
  title={Fractional Belief Propagation},
  url={https://proceedings.neurips.cc/paper_files/paper/2002/file/35936504a37d53e03abdfbc7318d9ec7-Paper.pdf},
  volume={15},
  year={2002}
}

@Article{wiener-alignment1960,
  author={Norbert Wiener},
  title={Some Moral and Technical Consequences of Automation},
  journal={Science},
  volume={131},
  number={3410},
  pages={1355-1358},
  year={1960},
  doi={10.1126/science.131.3410.1355},
  url={https://www.science.org/doi/abs/10.1126/science.131.3410.1355},
  eprint={https://www.science.org/doi/pdf/10.1126/science.131.3410.1355}
}

@Article{williams1995bayesian,
  title={Bayesian regularization and pruning using a Laplace prior},
  author={Williams, Peter M},
  journal={Neural Computation},
  volume={7},
  number={1},
  pages={117--143},
  year={1995},
  publisher={MIT Press}
}

@Misc{williams2010nonnegative,
  title={Nonnegative Decomposition of Multivariate Information},
  author={Paul L. Williams and Randall D. Beer},
  year={2010},
  eprint={1004.2515},
  archiveprefix={arXiv},
  primaryclass={cs.IT}
}

@InCollection{williamson2001foundations,
  title={Foundations for Bayesian networks},
  author={Williamson, Jon},
  booktitle={Foundations of Bayesianism},
  pages={75--115},
  year={2001},
  publisher={Springer}
}

@InProceedings{yedida-genbp,
  author={Yedidia, Jonathan S and Freeman, William and Weiss, Yair},
  booktitle={Advances in Neural Information Processing Systems},
  editor={T. Leen and T. Dietterich and V. Tresp},
  pages={},
  publisher={MIT Press},
  title={Generalized Belief Propagation},
  url={https://proceedings.neurips.cc/paper_files/paper/2000/file/61b1fb3f59e28c67f3925f3c79be81a1-Paper.pdf},
  volume={13},
  year={2000}
}

@Article{yuille2003concave,
  title={The Concave-Convex Procedure},
  author={Yuille, Alan L and Rangarajan, Anand},
  journal={Neural computation},
  volume={15},
  number={4},
  pages={915--936},
  year={2003},
  publisher={MIT Press}
}

@incollection{ramsey1926truth,
  title={Truth and Probability},
  author={Ramsey, Frank P},
  booktitle={The Foundations of Mathematics and other Logical Essays},
  pages={156--198},
  chapter={VII},
  year={1926},
  editor={R.B. Braithwaite},
  address={London},
  publisher={Kegan, Paul, Trench, Trubner \& Co.},
  note={1999 electronic edition}
}

@ARTICLE{Savage51,
  author = {L. J. Savage},
  title = {The theory of statistical decision},
  journal = {Journal of the American Statistical Association},
  year = {1951},
  volume = {46},
  pages = {55--67}
}
@misc{clifford1971markov,
  title={Markov Fields on Finite Graphs and Lattices},
  author={Clifford, P and Hammersley, JM},
  year={1971},
  note={Unpublished Manuscript},
  publisher={University of Oxford}
}
@book{lee.smooth-manifolds,
  title={Introduction to Smooth Manifolds},
  author={John M. Lee},
  doi={https://doi.org/10.1007/978-1-4419-9982-5},
  publisher={Springer New York, NY},
  isbn={978-1-4419-9982-5},
  year={2012},
  edition={2},
}