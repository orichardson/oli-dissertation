@STRING{aaai94	= {Proc.~Eleventh National Conference on Artificial
		  Intelligence (AAAI '94)} }
@STRING{mk	= "Morgan Kaufmann" }
@STRING{sf	= "San Francisco" }

@Misc{1219753,
  title={conditioning reduces mutual information},
  year={2015},
  author={leonbloy},
  howpublished={Mathematics Stack Exchange},
  note={URL:https://math.stackexchange.com/q/1219753 (version: 2015-04-04)},
  eprint={https://math.stackexchange.com/q/1219753},
  url={https://math.stackexchange.com/q/1219753}
}

@Misc{baez2014bayesiancharacterizationrelativeentropy,
  title={A Bayesian Characterization of Relative Entropy},
  author={John C. Baez and Tobias Fritz},
  year={2014},
  eprint={1402.3067},
  archiveprefix={arXiv},
  primaryclass={cs.IT},
  url={https://arxiv.org/abs/1402.3067}
}

@InCollection{Baier_2022,
  doi={10.1007/978-3-031-22337-2_17},
  url={https://doi.org/10.1007%2F978-3-031-22337-2_17},
  year=2022,
  publisher={Springer Nature Switzerland},
  pages={343--363},
  author={Christel Baier and Clemens Dubslaff and Holger Hermanns and Nikolai
Käfer},
  title={On the Foundations of Cycles in Bayesian Networks},
  booktitle={Lecture Notes in Computer Science}
}

@Misc{beckers2023causal,
  title={Causal Models with Constraints},
  author={Sander Beckers and Joseph Y. Halpern and Christopher Hitchcock},
  year={2023},
  eprint={2301.06845},
  archiveprefix={arXiv},
  primaryclass={cs.AI}
}

@InBook{Bertossi2005,
  author="Bertossi, Leopoldo and Hunter, Anthony and Schaub, Torsten",
  editor="Bertossi, Leopoldo and Hunter, Anthony and Schaub, Torsten",
  title="Introduction to Inconsistency Tolerance",
  booktitle="Inconsistency Tolerance",
  year="2005",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="1--14",
  abstract="Inconsistency arises in many areas in advanced computing.
Examples include: Merging information from heterogeneous sources; Negotiation
in multi-agent systems; Understanding natural language dialogues; and
Commonsense reasoning in robotics. Often inconsistency is unwanted, for
example, in the specification for a plan, or in sensor fusion in robotics.
But sometimes inconsistency is useful, e.g. when lawyers look for
inconsistencies in an opposition case, or in a brainstorming session in
research collaboration. Whether inconsistency is unwanted or useful, there is
a need to develop tolerance to inconsistency in application technologies such
as databases, knowledgebases, and software systems. To address this,
inconsistency tolerance is being built on foundational technologies for
identifying and analysing inconsistency in information, for representing and
reasoning with inconsistent information, for resolving inconsistent
information, and for merging inconsistent information. In this introductory
chapter, we consider the need and role for inconsistency tolerance, and
briefly review some of the foundational technologies for inconsistency
tolerance.",
  isbn="978-3-540-30597-2",
  doi="10.1007/978-3-540-30597-2_1",
  url="https://doi.org/10.1007/978-3-540-30597-2_1"
}

@Conference{BP94,
  author={A. Balke and J. Pearl},
  title={Probabilistic evaluation of counterfactual queries},
  booktitle=aaai94,
  year={1994},
  pages={200--207}
}

@Book{CoverThomas,
  title={Elements of Information Theory},
  publisher={Wiley},
  year={1991},
  author={T. M. Cover and J. A. Thomas},
  address={New York}
}

@Article{critique-maxent,
  title={A critique of Jaynes' maximum entropy principle},
  journal={Advances in Applied Mathematics},
  volume={2},
  number={2},
  pages={172-211},
  year={1981},
  issn={0196-8858},
  doi={https://doi.org/10.1016/0196-8858(81)90003-8},
  url={https://www.sciencedirect.com/science/article/pii/0196885881900038},
  author={Penha Maria {Cardoso Dias} and Abner Shimony},
  abstract={Friedman and Shimony exhibited an anomaly in Jaynes' maximum
entropy prescription: that if a certain unknown parameter is assumed to be
characterized a priori by a normalizable probability measure, then the prior
and posterior probabilities computed by means of the prescription are
consistent with probability theory only if this measure assigns probability 1
to a single value of the parameter and probability 0 to the entire range of
other values. We strengthen this result by deriving the same conclusion using
only the assumption that the probability measure is σ-finite. We also show
that when the hypothesis and evidence to which the prescription is applied
are expressed in certain rather simple languages, then the maximum entropy
prescription yields probability evaluation in agreement with one of Carnap's
λ-continuum of inductive methods, namely λ = ∞. We conclude that the
maximum entropy prescription is correct only under special circumstances,
which are essentially those in which it is appropriate to use λ = ∞.}
}

@InProceedings{CycleGAN2017,
  title={Unpaired Image-to-Image Translation using Cycle-Consistent
Adversarial Networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei
A},
  booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},
  year={2017}
}

@Article{dean1989model,
  title={A Model for Reasoning about Persistence and Causation},
  author={Dean, Thomas and Kanazawa, Keiji},
  journal={Computational Intelligence},
  volume={5},
  number={2},
  pages={142--150},
  year={1989},
  publisher={Wiley Online Library}
}

@Misc{deepgennotes,
  author={Grover, Aditya and Ermon, Stefano},
  title={Lecture notes in Deep Generative Models},
  year={2018},
  publisher={Stanford University},
  volume={CS236},
  howpublished={\url{deepgenerativemodels.github.io/notes/}}
}

@Misc{descartes,
  title={The Discourse on Method},
  author={Descartes, Ren{\'e}},
  year={1637}
}

@Misc{dit-stumble,
  title={(Stumbling Blocks) on the Road to Understanding Multivariate
Information Theory},
  author={James, Ryan},
  year={2018},
  howpublished={Discrete Information Theory package documentation},
  url={https://dit.readthedocs.io/en/latest/stumbling.html}
}

@Book{elts_stat_learn2009,
  title={The Elements of Statistical Learning: Data Mining, Inference, and
Prediction},
  publisher={Springer},
  year={2009},
  author={Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  edition={Second}
}

@Article{fadeev1957begriff,
  title={Zum Begriff der Entropie einer endlichen
Wahrscheinlichkeitsschemas},
  author={Fadeev, DK},
  journal={Arbeiten zur Informationstheorie I. Deutscher Verlag der
Wissenschaften},
  pages={85--90},
  year={1957}
}

@Article{finocchiaro1981fallacies,
  title={Fallacies and the Evaluation of Reasoning},
  author={Finocchiaro, Maurice A},
  journal={American Philosophical Quarterly},
  volume={18},
  number={1},
  pages={13--22},
  year={1981},
  publisher={JSTOR}
}

@Article{frey2012extending,
  title={Extending Factor Graphs so as to Unify Directed and Undirected
Graphical Models},
  author={Frey, Brendan J},
  journal={arXiv preprint arXiv:1212.2486},
  year={2012}
}

@Article{friedman1971jaynes,
  title={Jaynes's Maximum Entropy Prescription and Probability Theory},
  author={Friedman, Kenneth and Shimony, Abner},
  journal={Journal of Statistical Physics},
  volume={3},
  pages={381--384},
  year={1971},
  publisher={Springer}
}

@Misc{ftrl-lecturenotes1,
  author={Brendan McMahan},
  title={Follow-The-Regularized-Leader},
  month={March},
  year={2014},
  note={[Lecture Notes; accessed online July 2024]},
  howpublished={\url{https://courses.cs.washington.edu/courses/cse599s/14sp/scribes/lecture3/lecture3.pdf}}
}

@Misc{ftrl-lecturenotes2,
  author={Roi Livini},
  title={Follow The Regulerized Leader},
  year={2017},
  note={[Lecture notes; accessed online July 2024]},
  howpublished={\url{https://www.cs.princeton.edu/~rlivni/cos511/lectures/lect21.pdf}}
}

@Article{gallo-dirhypergraphs1993,
  title={Directed Hypergraphs and Applications},
  journal={Discrete Applied Mathematics},
  volume={42},
  number={2},
  pages={177-201},
  year={1993},
  issn={0166-218X},
  doi={https://doi.org/10.1016/0166-218X(93)90045-P},
  url={https://www.sciencedirect.com/science/article/pii/0166218X9390045P},
  author={Giorgio Gallo and Giustino Longo and Stefano Pallottino and Sang
Nguyen},
  abstract={We deal with directed hypergraphs as a tool to model and solve
some classes of problems arising in operations research and in computer
science. Concepts such as connectivity, paths and cuts are defined. An
extension of the main duality results to a special class of hypergraphs is
presented. Algorithms to perform visits of hypergraphs and to find optimal
paths are studied in detail. Some applications arising in propositional
logic, And-Or graphs, relational databases and transportation analysis are
presented.}
}

@Article{geiger-pearl-d-separation,
  author={Geiger, Dan and Verma, Thomas and Pearl, Judea},
  title={Identifying Independence in Bayesian Networks},
  journal={Networks},
  volume={20},
  number={5},
  pages={507-534},
  doi={https://doi.org/10.1002/net.3230200504},
  url={https://onlinelibrary.wiley.com/doi/abs/10.1002/net.3230200504},
  eprint={https://onlinelibrary.wiley.com/doi/pdf/10.1002/net.3230200504},
  abstract={Abstract An important feature of Bayesian networks is that they
facilitate explicit encoding of information about independencies in the
domain, information that is indispensable for efficient inferencing. This
article characterizes all independence assertions that logically follow from
the topology of a network and develops a linear time algorithm that
identifies these assertions. The algorithm's correctness is based on the
soundness of a graphical criterion, called d-separation, and its optimality
stems from the completeness of d-separation. An enhanced version of
d-separation, called D-separation, is defined, extending the algorithm to
networks that encode functional dependencies. Finally, the algorithm is shown
to work for a broad class of nonprobabilistic independencies.},
  year={1990}
}

@Article{girosi1995regularization,
  title={Regularization Theory and Neural Networks Architectures},
  author={Girosi, Federico and Jones, Michael and Poggio, Tomaso},
  journal={Neural computation},
  volume={7},
  number={2},
  pages={219--269},
  year={1995},
  publisher={MIT Press}
}

@InProceedings{Grove1997ProbabilityUC,
  title={Probability Update: Conditioning vs. Cross-Entropy},
  author={Adam J. Grove and Joseph Y. Halpern},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={1997},
  url={https://api.semanticscholar.org/CorpusID:14707750}
}

@Article{Hall1935,
  title={On Representatives of Subsets},
  author={Peter Hall},
  journal={Journal of The London Mathematical Society-second Series},
  year={1935},
  pages={26-30},
  url={https://api.semanticscholar.org/CorpusID:23252557}
}

@Article{halpern-2000,
  title={Axiomatizing Causal Reasoning},
  author={Halpern, Joseph Y},
  journal={Journal of Artificial Intelligence Research},
  volume={12},
  pages={317--337},
  year={2000}
}

@Book{halpern-RAU,
  title={Reasoning About Uncertainty},
  author={Halpern, Joseph Y},
  year={2017},
  publisher={MIT press}
}

@Article{HL12,
  author={J.~Y. Halpern and S. Leung},
  title={Weighted sets of probabilities and minimax weighted expected regret:
new approaches for representing uncertainty and making decisions},
  journal={Theory and Decision},
  year={2015},
  volume={79},
  number={3},
  pages={415--450}
}

@InProceedings{jadon2020survey,
  title={A Survey of Loss Functions for Semantic Segmentation},
  author={Jadon, Shruti},
  booktitle={2020 IEEE Conference on Computational Intelligence in
Bioinformatics and Computational Biology (CIBCB)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@Article{jaynes1957information,
  title={Information Theory and Statistical Mechanics},
  author={Jaynes, Edwin T},
  journal={Physical review},
  volume={106},
  number={4},
  pages={620},
  year={1957},
  publisher={APS}
}

@InCollection{Jeffrey68,
  author={R.~C. Jeffrey},
  title={Probable knowledge},
  booktitle={International Colloquium in the Philosophy of Science: The
Problem of Inductive Logic},
  editor={I. Lakatos},
  year=1968,
  pages={157--185},
  address={Amsterdam},
  publisher={North-Holland}
}

@InBook{Kaminski_Katoen_Matheja_2020,
  place={Cambridge},
  title={Expected Runtime Analyis by Program Verification},
  booktitle={Foundations of Probabilistic Programming},
  publisher={Cambridge University Press},
  author={Kaminski, Benjamin Lucien and Katoen, Joost-Pieter and Matheja,
Christoph},
  editor={Barthe, Gilles and Katoen, Joost-Pieter and Silva, Alexandra},
  year={2020},
  pages={185–220}
}

@Article{kasangian1990duality,
  title={The Duality Between Flow Charts and Circuits},
  author={Kasangian, S and Walters, RFC},
  journal={Bulletin of the Australian Mathematical Society},
  volume={42},
  number={1},
  pages={71--79},
  year={1990},
  publisher={Cambridge University Press}
}

@Book{KF09,
  author={D. Koller and N. Friedman},
  title={Probabilistic Graphical Models},
  year={2009},
  publisher={MIT Press},
  address={Cambridge, MA}
}

@Article{kingma2013autoencoding,
  title={Auto-Encoding Variational Bayes},
  author={Diederik P Kingma and Max Welling},
  journal={Proceedings of the International Conference on Learning
Representations (ICLR)},
  year={2014},
  eprint={1312.6114},
  archiveprefix={arXiv},
  primaryclass={stat.ML}
}

@Article{Kobyzev_2021,
  doi={10.1109/tpami.2020.2992934},
  url={https://doi.org/10.1109%2Ftpami.2020.2992934},
  year=2021,
  month={nov},
  publisher={Institute of Electrical and Electronics Engineers ({IEEE})},
  volume={43},
  number={11},
  pages={3964--3979},
  author={Ivan Kobyzev and Simon J.D. Prince and Marcus A. Brubaker},
  title={Normalizing Flows: An Introduction and Review of Current Methods},
  journal={{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
}

@Article{kschischang2001sumproduct,
  author={F. R. {Kschischang} and B. J. {Frey} and H. -. {Loeliger}},
  journal={IEEE Transactions on Information Theory},
  title={Factor Graphs and the Sum-product Algorithm},
  year={2001},
  volume={47},
  number={2},
  pages={498-519}
}

@Article{lauritzen-dag-indeps,
  author={Lauritzen, S. L. and Dawid, A. P. and Larsen, B. N. and Leimer,
H.-G.},
  title={Independence properties of directed markov fields},
  journal={Networks},
  volume={20},
  number={5},
  pages={491-505},
  doi={https://doi.org/10.1002/net.3230200503},
  url={https://onlinelibrary.wiley.com/doi/abs/10.1002/net.3230200503},
  eprint={https://onlinelibrary.wiley.com/doi/pdf/10.1002/net.3230200503},
  abstract={Abstract We investigate directed Markov fields over finite graphs
without positivity assumptions on the densities involved. A criterion for
conditional independence of two groups of variables given a third is given
and named as the directed, global Markov property. We give a simple proof of
the fact that the directed, local Markov property and directed, global Markov
property are equivalent and – in the case of absolute continuity w. r. t. a
product measure – equivalent to the recursive factorization of densities.
It is argued that our criterion is easy to use, it is sharper than that given
by Kiiveri, Speed, and Carlin and equivalent to that of Pearl. It follows
that our criterion cannot be sharpened.},
  year={1990}
}

@InProceedings{learning-loc-glob-consistency,
  author={Zhou, Dengyong and Bousquet, Olivier and Lal, Thomas and Weston,
Jason and Sch\"{o}lkopf, Bernhard},
  booktitle={Advances in Neural Information Processing Systems},
  editor={S. Thrun and L. Saul and B. Sch\"{o}lkopf},
  pages={},
  publisher={MIT Press},
  title={Learning with Local and Global Consistency},
  url={https://proceedings.neurips.cc/paper_files/paper/2003/file/87682805257e619d49b8e0dfdc14affa-Paper.pdf},
  volume={16},
  year={2003}
}

@Misc{leinster2017shortcharacterizationrelativeentropy,
  title={A Short Characterization of Relative Entropy},
  author={Tom Leinster},
  year={2017},
  eprint={1712.04903},
  archiveprefix={arXiv},
  primaryclass={cs.IT},
  url={https://arxiv.org/abs/1712.04903}
}

@Misc{LIR,
  title={The Local Inconsistency Resolution Algorithm (workshop version)},
  author={Oliver E Richardson},
  note={ICML `23 Workshops: Local Learning Workshop (LLW) and Structured
Prediction in Generative Modeling (SPIGM)},
  year={2023}
}

@Book{mackay2003information,
  title={Information Theory, Inference and Learning Algorithms},
  author={MacKay, David J. C.},
  year={2003},
  publisher={Cambridge University Press}
}

@Book{mezard2009information,
  title={Information, physics, and computation},
  author={Mezard, Marc and Montanari, Andrea},
  year={2009},
  publisher={Oxford University Press}
}

@Article{multivar-beyondshannon17,
  author={James, Ryan G. and Crutchfield, James P.},
  title={Multivariate Dependence beyond Shannon Information},
  journal={Entropy},
  volume={19},
  year={2017},
  number={10},
  article-number={531},
  url={https://www.mdpi.com/1099-4300/19/10/531},
  issn={1099-4300},
  abstract={Accurately determining dependency structure is critical to
understanding a complex system’s organization. We recently showed that the
transfer entropy fails in a key aspect of this—measuring information
flow—due to its conflation of dyadic and polyadic relationships. We extend
this observation to demonstrate that Shannon information measures (entropy
and mutual information, in their conditional and multivariate forms) can fail
to accurately ascertain multivariate dependencies due to their conflation of
qualitatively different relations among variables. This has broad
implications, particularly when employing information to express the
organization and mechanisms embedded in complex systems, including the
burgeoning efforts to combine complex network theory with information theory.
Here, we do not suggest that any aspect of information theory is wrong.
Rather, the vast majority of its informational measures are simply inadequate
for determining the meaningful relationships among variables within joint
probability distributions. We close by demonstrating that such distributions
exist across an arbitrary set of variables.},
  doi={10.3390/e19100531}
}

@Article{myung2003tutorial,
  title={Tutorial on Maximum Likelihood Estimation},
  author={Myung, In Jae},
  journal={Journal of mathematical Psychology},
  volume={47},
  number={1},
  pages={90--100},
  year={2003},
  publisher={Elsevier}
}

@Misc{naumov2013re,
  title={R.E. Axiomatization of Conditional Independence},
  author={Pavel Naumov and Brittany Nicholls},
  year={2013},
  eprint={1310.6430},
  archiveprefix={arXiv},
  primaryclass={cs.LO}
}

@Article{nikodym1930generalisation,
  title={Sur une g{\'e}n{\'e}ralisation des int{\'e}grales de MJ Radon},
  author={Nikodym, Otton},
  journal={Fundamenta Mathematicae},
  volume={15},
  number={1},
  pages={131--179},
  year={1930}
}

@Article{one-true-loss,
  title={Loss as the Inconsistency of a Probabilistic Dependency Graph:
Choose Your Model, Not Your Loss Function},
  author={Oliver E Richardson},
  journal={AISTATS '22},
  year={2022},
  eprint={2202.11862},
  archiveprefix={arXiv},
  primaryclass={cs.AI},
  series={Proceedings of Machine Learning Research},
  volume={151},
  publisher={PMLR}
}

@Article{pdg-aaai,
  title={Probabilistic Dependency Graphs},
  author={Oliver E Richardson and Joseph Y Halpern},
  journal={AAAI '21},
  year={2021},
  eprint={2012.10800},
  archiveprefix={arXiv},
  primaryclass={cs.AI}
}

@Article{pdg-infer,
  title={Inference in Probabilistic Dependency Graphs},
  author={Oliver E Richardson and Joseph Y Halpern and Christopher {De Sa}},
  journal={UAI '23},
  year={2023}
}

@Book{Pearl,
  author={J. Pearl},
  title={Probabilistic Reasoning in Intelligent Systems},
  publisher=mk,
  address=sf,
  year=1988
}

@Misc{pearl1987graphoids,
  title={Graphoids: A Graph-Based Logic for Reasoning about Relevance
Relations},
  journal={Advances in Artificial Intelligence},
  vol={2},
  author={Pearl, J and Paz, A},
  year={1987},
  publisher={North-Holland}
}

@Book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}

@Book{pearl:2k,
  title={Causality: Models, Reasoning, and Inference},
  publisher={Cambridge University Press},
  year={2000},
  author={Pearl, J.},
  address={New York}
}

@Book{probTuring,
  author={Sipser, Michael},
  year={2006},
  title={Introduction to the Theory of Computation (2nd ed.)},
  edition={Second},
  publisher={Thomson Course Technology.},
  pages={368},
  isbn={978-0-534-95097-2}
}

@Article{qim,
  title={Qualitative Mechanism Independence},
  author={Richardson, Oliver E and Peters, Spencer and Halpern, Joseph Y},
  year={2024},
  note={In Submission: for NeurIPS 2024}
}

@InProceedings{renyi1961measures,
  title={On Measures of Entropy and Information},
  author={R{\'e}nyi, Alfr{\'e}d},
  booktitle={Proceedings of the Fourth Berkeley Symposium on Mathematical
Statistics and Probability, Volume 1: Contributions to the Theory of
Statistics},
  pages={547--561},
  year={1961},
  organization={University of California Press}
}

@Article{Rubin74,
  author={D. B. Rubin},
  title={Estimating causal effects of treatments in randomized and
nonrandomized studies},
  journal={Journal of Educational Psychology},
  year={1974},
  volume={66},
  number={5},
  pages={688--701}
}

@Article{russell1902letter,
  title={Letter to Frege},
  author={Russell, Bertrand},
  journal={From Frege to G{\"o}del},
  volume={6},
  pages={124--125},
  year={1902},
  publisher={Harvard University Press Cambridge, UK}
}

@Article{santambrogio2015optimal,
  title={Optimal Transport for Applied Mathematicians},
  author={Santambrogio, Filippo},
  journal={Birk{\"a}user, NY},
  volume={55},
  number={58-63},
  pages={94},
  year={2015},
  publisher={Springer}
}

@Book{Savage,
  author={L.~J. Savage},
  title={Foundations of Statistics},
  publisher={Wiley},
  address={New York},
  year=1954
}

@Misc{segal-law,
  year=1930,
  publisher={{San Diego Union}},
  author={{San Diego Union}},
  journal={{San Diego Union}},
  date={September 20, 1930},
  note={Quote Page 4, Column 1},
  howpublished={\url{https://quoteinvestigator.com/2022/07/04/watch/#f+441634+1+1}}
}

@Article{seidenfeld1986entropy,
  title={Entropy and Uncertainty},
  author={Seidenfeld, Teddy},
  journal={Philosophy of Science},
  volume={53},
  number={4},
  pages={467--491},
  year={1986},
  publisher={Cambridge University Press}
}

@InCollection{sep-causal-models,
  author={Hitchcock, Christopher},
  title={{Causal Models}},
  booktitle={The {Stanford} Encyclopedia of Philosophy},
  editor={Edward N. Zalta and Uri Nodelman},
  howpublished={\url{https://plato.stanford.edu/archives/sum2024/entries/causal-models/}},
  year={2024},
  edition={{S}ummer 2024},
  publisher={Metaphysics Research Lab, Stanford University}
}

@InCollection{sep-dutch-book,
  author={Vineberg, Susan},
  title={{Dutch Book Arguments}},
  booktitle={The {Stanford} Encyclopedia of Philosophy},
  editor={Edward N. Zalta and Uri Nodelman},
  howpublished={\url{https://plato.stanford.edu/archives/fall2022/entries/dutch-book/}},
  year={2022},
  edition={{F}all 2022},
  publisher={Metaphysics Research Lab, Stanford University}
}

@Book{shafer1976mathematical,
  title={A Mathematical Theory of Evidence},
  author={Shafer, Glenn},
  volume={42},
  year={1976},
  publisher={Princeton university press}
}

@Article{shafer1990probability,
  title={Probability propagation},
  author={Shafer, Glenn R and Shenoy, Prakash P},
  journal={Annals of mathematics and Artificial Intelligence},
  volume={2},
  pages={327--351},
  year={1990},
  publisher={Springer}
}

@Article{tabak2010density,
  title={Density Estimation by Dual Ascent of the Log-Likelihood},
  author={Tabak, Esteban G and Vanden-Eijnden, Eric},
  journal={Communications in Mathematical Sciences},
  volume={8},
  number={1},
  pages={217--233},
  year={2010},
  publisher={International Press of Boston}
}

@InProceedings{temp-cycle-consist-2019CVPR,
  author={Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and
Sermanet, Pierre and Zisserman, Andrew},
  title={Temporal Cycle-Consistency Learning},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)},
  month={June},
  year={2019}
}

@Article{tribus1961information,
  title={Information Theory as the Basis for Thermostatics and
Thermodynamics},
  author={Tribus, Myron},
  year={1961}
}

@Article{wainwright2003tree,
  title={Tree-based reparameterization framework for analysis of sum-product
and related algorithms},
  author={Wainwright, Martin J and Jaakkola, Tommi S and Willsky, Alan S},
  journal={IEEE Transactions on information theory},
  volume={49},
  number={5},
  pages={1120--1146},
  year={2003},
  publisher={IEEE}
}

@Article{wainwright2008graphical,
  title={Graphical Models, Exponential Families, and Variational Inference},
  author={Wainwright, Martin J and Jordan, Michael I and others},
  journal={Foundations and Trends{} in Machine Learning},
  volume={1},
  number={1--2},
  pages={1--305},
  year={2008},
  publisher={Now Publishers, Inc.}
}

@Book{Walley1991-SRIP,
  author={Peter Walley},
  editor={},
  publisher={Chapman \& Hall},
  journal={Monographs on Statistic aand Applied Probability},
  title={Statistical Reasoning with Imprecise Probabilities},
  year={1991},
  vol={42}
}

@Article{wang2020comprehensive,
  title={A Comprehensive Survey of Loss Functions in Machine Learning},
  author={Wang, Qi and Ma, Yue and Zhao, Kun and Tian, Yingjie},
  journal={Annals of Data Science},
  pages={1--26},
  year={2020},
  publisher={Springer}
}

@Article{why-be-consistent-sugden,
  issn={00130427, 14680335},
  url={http://www.jstor.org/stable/2554418},
  author={Robert Sugden},
  journal={Economica},
  number={206},
  pages={167--183},
  publisher={[London School of Economics, Wiley, London School of Economics
and Political Science, Suntory and Toyota International Centres for Economics
and Related Disciplines]},
  title={Why be Consistent? A Critical Analysis of Consistency Requirements
in Choice Theory},
  urldate={2024-08-08},
  volume={52},
  year={1985}
}

@Misc{williams2010nonnegative,
  title={Nonnegative Decomposition of Multivariate Information},
  author={Paul L. Williams and Randall D. Beer},
  year={2010},
  eprint={1004.2515},
  archiveprefix={arXiv},
  primaryclass={cs.IT}
}

@InCollection{williamson2001foundations,
  title={Foundations for Bayesian networks},
  author={Williamson, Jon},
  booktitle={Foundations of Bayesianism},
  pages={75--115},
  year={2001},
  publisher={Springer}
}

@article{de-gustibus-non-est-disputandum77stigler,
 ISSN = {00028282},
 URL = {http://www.jstor.org/stable/1807222},
 author = {George J. Stigler and Gary S. Becker},
 journal = {The American Economic Review},
 number = {2},
 pages = {76--90},
 publisher = {American Economic Association},
 title = {De Gustibus Non Est Disputandum},
 urldate = {2024-08-08},
 volume = {67},
 year = {1977}
}

@book{VnMR44theory-of-games-eb,
 ISBN = {9780691130613},
 URL = {http://www.jstor.org/stable/j.ctt1r2gkx},
 abstract = {This is the classic work upon which modern-day game theory is based. What began more than sixty years ago as a modest proposal that a mathematician and an economist write a short paper together blossomed, in 1944, when Princeton University Press publishedTheory of Games and Economic Behavior. In it, John von Neumann and Oskar Morgenstern conceived a groundbreaking mathematical theory of economic and social organization, based on a theory of games of strategy. Not only would this revolutionize economics, but the entirely new field of scientific inquiry it yielded--game theory--has since been widely used to analyze a host of real-world phenomena from arms races to optimal policy choices of presidential candidates, from vaccination policy to major league baseball salary negotiations. And it is today established throughout both the social sciences and a wide range of other sciences.This sixtieth anniversary edition includes not only the original text but also an introduction by Harold Kuhn, an afterword by Ariel Rubinstein, and reviews and articles on the book that appeared at the time of its original publication in the New York Times, ttheAmerican Economic Review, and a variety of other publications. Together, these writings provide readers a matchless opportunity to more fully appreciate a work whose influence will yet resound for generations to come.},
 author = {John von Neumann and Oskar Morgenstern and Ariel Rubinstein},
 publisher = {Princeton University Press},
 title = {Theory of Games and Economic Behavior (60th Anniversary Commemorative Edition)},
 urldate = {2024-08-08},
 year = {1944}
}
